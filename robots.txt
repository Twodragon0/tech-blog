# robots.txt for Twodragon's Tech Blog
# https://www.robotstxt.org/robotstxt.html
# DevSecOps, Cloud Security, Kubernetes Security - Technical Blog

User-agent: *
Allow: /

# Disallow admin and private areas
Disallow: /_site/
Disallow: /_posts/
Disallow: /_layouts/
Disallow: /_includes/
Disallow: /_sass/
Disallow: /_data/
Disallow: /scripts/
Disallow: /vendor/
Disallow: /node_modules/
Disallow: /api/

# Allow important files
Allow: /feed.xml
Allow: /sitemap.xml
Allow: /assets/
Allow: /posts/

# AI Crawlers - Allow for AI training and discovery
# GPTBot (OpenAI)
User-agent: GPTBot
Allow: /

# Google-Extended (Google Bard/Gemini)
User-agent: Google-Extended
Allow: /

# ClaudeBot (Anthropic)
User-agent: Claude-Web
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: anthropic-ai
Allow: /

# CCBot (Common Crawl)
User-agent: CCBot
Allow: /

# PerplexityBot
User-agent: PerplexityBot
Allow: /

# Crawl-delay for respectful crawling
User-agent: *
Crawl-delay: 1

# Sitemap location
Sitemap: https://tech.2twodragon.com/sitemap.xml

# Host preference
Host: https://tech.2twodragon.com
