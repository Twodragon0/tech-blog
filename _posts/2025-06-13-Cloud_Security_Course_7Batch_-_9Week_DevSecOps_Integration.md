---
layout: post
title: "í´ë¼ìš°ë“œ ì‹œíë¦¬í‹° ê³¼ì • 7ê¸° - 9ì£¼ì°¨: DevSecOps í†µí•© ì •ë¦¬"
date: 2025-06-13 23:48:33 +0900
categories: [devsecops]
tags: [DevSecOps, Integration, Cloud-Security, SDLC, Security-Automation]
excerpt: "DevSecOps í†µí•© ì •ë¦¬: íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ë¶€í„° ì‹¤ë¬´ ì ìš©ê¹Œì§€"
comments: true
original_url: https://twodragon.tistory.com/691
image: /assets/images/2025-06-13-Cloud_Security_Course_7Batch_-_9Week_DevSecOps_Integration.svg
image_alt: "Cloud Security Course 7Batch 9Week: DevSecOps Integration Summary"
toc: true
description: "DevSecOps íŒŒì´í”„ë¼ì¸ ì „ì²´ ì•„í‚¤í…ì²˜, ë³´ì•ˆ ë„êµ¬ ë§¤í•‘, AWS ë³´ì•ˆ ì„œë¹„ìŠ¤ í†µí•©, DevSecOps ì„±ìˆ™ë„ ëª¨ë¸, ì™„ì „í•œ CI/CD ë³´ì•ˆ íŒŒì´í”„ë¼ì¸, ì‹¤ë¬´ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸ê¹Œì§€ ì •ë¦¬."
keywords: [DevSecOps, Integration, Cloud-Security, SDLC, Security-Automation]
author: "Yongho Ha"
schema_type: Article
---

## ğŸ“‹ í¬ìŠ¤íŒ… ìš”ì•½

> **ì œëª©**: í´ë¼ìš°ë“œ ì‹œíë¦¬í‹° ê³¼ì • 7ê¸° - 9ì£¼ì°¨: DevSecOps í†µí•© ì •ë¦¬

> **ì¹´í…Œê³ ë¦¬**: devsecops

> **íƒœê·¸**: DevSecOps, Integration, Cloud-Security, SDLC, Security-Automation

> **í•µì‹¬ ë‚´ìš©**: 
> - DevSecOps í†µí•© ì •ë¦¬: íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ë¶€í„° ì‹¤ë¬´ ì ìš©ê¹Œì§€

> **ì£¼ìš” ê¸°ìˆ /ë„êµ¬**: DevSecOps, Security, Security, devsecops

> **ëŒ€ìƒ ë…ì**: DevSecOps ì—”ì§€ë‹ˆì–´, ë³´ì•ˆ ì—”ì§€ë‹ˆì–´, ê°œë°œì

> ---

> *ì´ í¬ìŠ¤íŒ…ì€ AI(Cursor, Claude ë“±)ê°€ ì‰½ê²Œ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ í¬í•¨í•©ë‹ˆë‹¤.*


## í•µì‹¬ ìš”ì•½

ì•ˆë…•í•˜ì„¸ìš”, **Twodragon**ì…ë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” í´ë¼ìš°ë“œ ì‹œíë¦¬í‹° ê³¼ì • 7ê¸° 9ì£¼ì°¨ì—ì„œ ë‹¤ë£¬ **DevSecOps í†µí•©**ì„ ì‹¤ë¬´ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.

2025ë…„ í˜„ì¬, DevSecOpsëŠ” ë‹¨ìˆœí•œ buzzwordë¥¼ ë„˜ì–´ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ í•„ìˆ˜ì ì¸ ì ‘ê·¼ ë°©ì‹ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. Gartnerì— ë”°ë¥´ë©´ 2025ë…„ê¹Œì§€ 70%ì˜ ê¸°ì—…ì´ DevSecOps ì „ëµì„ ì±„íƒí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, ë³´ì•ˆ ìë™í™”ë¥¼ í†µí•´ í‰ê·  MTTR(Mean Time To Resolve)ì„ 60% ë‹¨ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### DevSecOps ì„±ìˆ™ë„ ìŠ¤ì½”ì–´ì¹´ë“œ

ë‹¤ìŒ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¡œ ê·€ì‚¬ì˜ DevSecOps ì„±ìˆ™ë„ë¥¼ í‰ê°€í•´ ë³´ì„¸ìš”:

| ì˜ì—­ | ì´ˆê¸° (1ì ) | ì„±ì¥ (2ì ) | ì„±ìˆ™ (3ì ) | ìµœì í™” (4ì ) |
|------|----------|----------|----------|------------|
| **ë³´ì•ˆ ìë™í™”** | ìˆ˜ë™ ê²€ì‚¬ | CIì—ì„œ SAST | SAST+DAST+SCA | ì‹¤ì‹œê°„ í”¼ë“œë°± ë£¨í”„ |
| **ì·¨ì•½ì  ê´€ë¦¬** | ì›” ë‹¨ìœ„ íŒ¨ì¹˜ | ì£¼ ë‹¨ìœ„ ìŠ¤ìº” | ì¼ ë‹¨ìœ„ ìŠ¤ìº” + ìë™ íŒ¨ì¹˜ | ì œë¡œë°ì´ ëŒ€ì‘ ìë™í™” |
| **Secret ê´€ë¦¬** | ì½”ë“œ ë‚´ í•˜ë“œì½”ë”© | Vault ë„ì… | ìë™ ìˆœí™˜ + ê°ì‚¬ | ë™ì  Secret ìƒì„± |
| **IaC ë³´ì•ˆ** | ìˆ˜ë™ ê²€í†  | Checkov ìŠ¤ìº” | OPA/Kyverno ì •ì±… ì ìš© | ì •ì±… as Code + ìë™ ìˆ˜ì • |
| **ì»¨í…Œì´ë„ˆ ë³´ì•ˆ** | Base ì´ë¯¸ì§€ ê²€ì¦ ì—†ìŒ | ì´ë¯¸ì§€ ìŠ¤ìº” | ì„œëª… + SBOM | ëŸ°íƒ€ì„ ë³´í˜¸ + ìë™ ê²©ë¦¬ |
| **ëª¨ë‹ˆí„°ë§** | ë¡œê·¸ ìˆ˜ì§‘ | ì¤‘ì•™í™”ëœ SIEM | ì‹¤ì‹œê°„ ì•Œë¦¼ + ëŒ€ì‹œë³´ë“œ | AI ê¸°ë°˜ ì´ìƒ íƒì§€ |

**ì´ì  ê¸°ì¤€:**
- **6-10ì **: ì´ˆê¸° ë‹¨ê³„ - ë³´ì•ˆ ìë™í™” ìš°ì„  ë„ì… í•„ìš”
- **11-16ì **: ì„±ì¥ ë‹¨ê³„ - ë„êµ¬ í†µí•© ë° í”„ë¡œì„¸ìŠ¤ ê°œì„ 
- **17-21ì **: ì„±ìˆ™ ë‹¨ê³„ - ìµœì í™” ë° ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©
- **22-24ì **: ìµœì í™” ë‹¨ê³„ - ì§€ì†ì  ê°œì„  ë° í˜ì‹ 

### ì´ í¬ìŠ¤íŒ…ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©

1. **DevSecOps í”„ë ˆì„ì›Œí¬ ë¶„ì„** - OWASP DSOMM, Shift-Left Security
2. **ë„êµ¬ ì²´ì¸ ìƒì„¸ ê°€ì´ë“œ** - SAST/DAST/SCA/ì»¨í…Œì´ë„ˆ ë³´ì•ˆ/IaC ìŠ¤ìº”
3. **CI/CD íŒŒì´í”„ë¼ì¸ ì„¤ê³„** - GitHub Actions/Jenkins/GitLab CI ë³´ì•ˆ í†µí•©
4. **ì‹¤ìŠµ ê°€ì´ë“œ** - ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ YAML ì„¤ì • íŒŒì¼
5. **ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤** - MTTR/MTTD ì¸¡ì • ë° ROI ê³„ì‚°
6. **í•œêµ­ ê¸°ì—… ì ìš© ê°€ì´ë“œ** - ISMS-P ê´€ì ì˜ DevSecOps
7. **ê²½ì˜ì§„ ë³´ê³  í˜•ì‹** - íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ì…ì¦

### ì™œ DevSecOpsì¸ê°€?

ì „í†µì ì¸ ì›Œí„°í´ ê°œë°œì—ì„œëŠ” ë³´ì•ˆ ê²€í† ê°€ ë¦´ë¦¬ìŠ¤ ì „ ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤:

- **ë†’ì€ ìˆ˜ì • ë¹„ìš©**: í”„ë¡œë•ì…˜ ë‹¨ê³„ì—ì„œ ë°œê²¬ëœ ì·¨ì•½ì ì€ ì´ˆê¸° ë‹¨ê³„ë³´ë‹¤ 100ë°° ì´ìƒ ë¹„ìš©ì´ ë“­ë‹ˆë‹¤
- **ë¦´ë¦¬ìŠ¤ ì§€ì—°**: ë³´ì•ˆ ì´ìŠˆë¡œ ì¸í•œ ê¸´ê¸‰ íŒ¨ì¹˜ê°€ ì „ì²´ ì¼ì •ì„ ì§€ì—°ì‹œí‚µë‹ˆë‹¤
- **ê°œë°œ-ë³´ì•ˆ ê°„ ë§ˆì°°**: "ë³´ì•ˆì´ ê°œë°œ ì†ë„ë¥¼ ì €í•´í•œë‹¤"ëŠ” ì¸ì‹ì´ í™•ì‚°ë©ë‹ˆë‹¤

DevSecOpsëŠ” ì´ ë¬¸ì œë¥¼ **Shift-Left** ì „ëµìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤:

```
ì „í†µì  ì ‘ê·¼:
[ê°œë°œ 4ì£¼] â†’ [QA 2ì£¼] â†’ [ë³´ì•ˆ ê²€í†  2ì£¼] â†’ [ìˆ˜ì • 1ì£¼] â†’ [ì¬ê²€í†  1ì£¼] = ì´ 10ì£¼

DevSecOps ì ‘ê·¼:
[ê°œë°œ+ë³´ì•ˆ ìë™í™” 4ì£¼] â†’ [QA+DAST 1ì£¼] â†’ [ìµœì¢… ê²€ì¦ 0.5ì£¼] = ì´ 5.5ì£¼
```

**ê²°ê³¼:**
- 50% ì‹œê°„ ë‹¨ì¶•
- 90% ì·¨ì•½ì  ì¡°ê¸° ë°œê²¬
- ê°œë°œì ë§Œì¡±ë„ 40% ì¦ê°€ (Forrester ì¡°ì‚¬)

## 1. DevSecOps í”„ë ˆì„ì›Œí¬ ë¶„ì„

### 1.1 OWASP DevSecOps ì„±ìˆ™ë„ ëª¨ë¸ (DSOMM)

[OWASP DevSecOps Maturity Model](https://dsomm.owasp.org/)ì€ ì¡°ì§ì˜ DevSecOps ì„±ìˆ™ë„ë¥¼ í‰ê°€í•˜ê³  ê°œì„  ë¡œë“œë§µì„ ì œì‹œí•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

#### 1.1.1 DSOMM 4ëŒ€ ì°¨ì›

**1. ë¹Œë“œ ë° ë°°í¬ (Build and Deployment)**
- ì •ì  ì½”ë“œ ë¶„ì„ (SAST)
- ì˜ì¡´ì„± ê´€ë¦¬ (SCA)
- ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë³´ì•ˆ
- Infrastructure as Code ìŠ¤ìº”

**2. ë¬¸í™” ë° ì¡°ì§ (Culture and Organization)**
- ë³´ì•ˆ ì±”í”¼ì–¸ í”„ë¡œê·¸ë¨
- ê°œë°œì ë³´ì•ˆ êµìœ¡
- ë²„ê·¸ ë°”ìš´í‹° í”„ë¡œê·¸ë¨
- ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ

**3. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (Test and Verification)**
- ë™ì  ì• í”Œë¦¬ì¼€ì´ì…˜ ë³´ì•ˆ í…ŒìŠ¤íŠ¸ (DAST)
- API ë³´ì•ˆ í…ŒìŠ¤íŠ¸
- í¼ì§• í…ŒìŠ¤íŠ¸
- ì¹¨íˆ¬ í…ŒìŠ¤íŠ¸ ìë™í™”

**4. ì •ë³´ ìˆ˜ì§‘ (Information Gathering)**
- ì·¨ì•½ì  ê³µê°œ í”„ë¡œê·¸ë¨
- ë³´ì•ˆ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ í†µí•©
- SIEM ì—°ë™

#### 1.1.2 ë ˆë²¨ë³„ êµ¬í˜„ ê°€ì´ë“œ

**Level 1 (ì´ˆê¸°):**
```bash
# í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜
npm install -g snyk
pip install bandit safety
docker pull aquasec/trivy:latest

# CIì— ë³´ì•ˆ ìŠ¤ìº” ì¶”ê°€
# .github/workflows/security.yml
on: [push]
jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run Trivy
        run: trivy fs .
```

**Level 2 (ì„±ì¥):**
- ë³´ì•ˆ ê²Œì´íŠ¸ ì„¤ì • (ì„ê³„ê°’ ê¸°ë°˜ ë¹Œë“œ ì¤‘ë‹¨)
- Secret ìŠ¤ìºë‹ ìë™í™”
- ì •ì±… as Code ë„ì… (OPA)

**Level 3 (ì„±ìˆ™):**
- ëŸ°íƒ€ì„ ë³´ì•ˆ ëª¨ë‹ˆí„°ë§
- ìë™í™”ëœ ì·¨ì•½ì  íŒ¨ì¹˜
- ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ

**Level 4 (ìµœì í™”):**
- AI ê¸°ë°˜ ìœ„í˜‘ íƒì§€
- ìë™í™”ëœ ì‚¬ê³  ëŒ€ì‘ (SOAR)
- ì§€ì†ì ì¸ ê·œì • ì¤€ìˆ˜ ê²€ì¦

### 1.2 Shift-Left Security ì „ëµ

Shift-LeftëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ìƒëª…ì£¼ê¸°(SDLC)ì˜ **ì´ˆê¸° ë‹¨ê³„ë¶€í„° ë³´ì•ˆì„ í†µí•©**í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.

#### 1.2.1 ê° ë‹¨ê³„ë³„ Shift-Left ì ìš©

**Plan ë‹¨ê³„:**
```yaml
# ìœ„í˜‘ ëª¨ë¸ë§ í…œí”Œë¦¿ (threat-model.yml)
threat_model:
  application: "E-commerce API"
  stride_analysis:
    - threat: "Spoofing"
      mitigation: "OAuth 2.0 + JWT"
      status: "implemented"
    - threat: "Tampering"
      mitigation: "Input validation + parameterized queries"
      status: "in_progress"
    - threat: "Repudiation"
      mitigation: "Audit logging to CloudWatch"
      status: "planned"
    - threat: "Information Disclosure"
      mitigation: "TLS 1.3 + at-rest encryption"
      status: "implemented"
    - threat: "Denial of Service"
      mitigation: "Rate limiting + WAF rules"
      status: "implemented"
    - threat: "Elevation of Privilege"
      mitigation: "RBAC + principle of least privilege"
      status: "implemented"
```

**Code ë‹¨ê³„:**
```bash
# Pre-commit hookìœ¼ë¡œ Secret ìŠ¤ìº”
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/zricethezav/gitleaks
    rev: v8.18.2
    hooks:
      - id: gitleaks

  - repo: https://github.com/Yelp/detect-secrets
    rev: v1.4.0
    hooks:
      - id: detect-secrets
        args: ['--baseline', '.secrets.baseline']
```

**Build ë‹¨ê³„:**
```dockerfile
# ë³´ì•ˆ ê°•í™”ëœ Dockerfile
FROM alpine:3.19 AS builder
# ìµœì‹  ë³´ì•ˆ íŒ¨ì¹˜ ì ìš©
RUN apk update && apk upgrade --no-cache

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¹Œë“œ
WORKDIR /app
COPY . .
RUN go build -ldflags="-s -w" -o app

# ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œë¡œ ê³µê²© í‘œë©´ ìµœì†Œí™”
FROM gcr.io/distroless/static:nonroot
COPY --from=builder /app/app /
USER nonroot:nonroot
ENTRYPOINT ["/app"]
```

**Deploy ë‹¨ê³„:**
```yaml
# Kubernetes ë³´ì•ˆ ì •ì±…
apiVersion: v1
kind: Pod
metadata:
  name: secure-app
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  containers:
  - name: app
    image: myapp:v1.2.3
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
    resources:
      limits:
        memory: "512Mi"
        cpu: "500m"
      requests:
        memory: "256Mi"
        cpu: "250m"
```

#### 1.2.2 Shift-Left ì„±ê³µ ì§€í‘œ

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|----------|
| **MTTD (Mean Time To Detect)** | < 1ì¼ | SIEM ì•Œë¦¼ ì‹œê°„ - ì·¨ì•½ì  ë„ì… ì‹œê°„ |
| **MTTR (Mean Time To Resolve)** | < 7ì¼ | íŒ¨ì¹˜ ë°°í¬ ì‹œê°„ - ì·¨ì•½ì  ë°œê²¬ ì‹œê°„ |
| **False Positive Rate** | < 10% | ì˜¤íƒ ê±´ìˆ˜ / ì „ì²´ ì•Œë¦¼ ê±´ìˆ˜ |
| **Coverage** | > 90% | ìŠ¤ìº”ëœ ì½”ë“œ ë¼ì¸ / ì „ì²´ ì½”ë“œ ë¼ì¸ |
| **Critical ì·¨ì•½ì ** | 0ê±´ | í”„ë¡œë•ì…˜ í™˜ê²½ CVSS 9.0+ ì·¨ì•½ì  |

### 1.3 DevSecOps íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜

```mermaid
flowchart TD
    Plan["Plan"]
    Code["Code"]
    Build["Build"]
    Test["Test"]
    Release["Release"]
    Deploy["Deploy"]
    Operate["Operate"]
    Monitor["Monitor"]
    
    TM["Threat Modeling"]
    SAST["SAST + Secret Scan"]
    SCA["SCA + Image Scan"]
    DAST["DAST + IAST"]
    SR["Signed Release"]
    
    IaC["IaC Security"]
    RS["Runtime Security"]
    SIEM["SIEM / SOAR / Incident Response"]
    
    Plan --> Code
    Code --> Build
    Build --> Test
    Test --> Release
    Release --> Deploy
    Deploy --> Operate
    Operate --> Monitor
    
    Plan --> TM
    Code --> SAST
    Build --> SCA
    Test --> DAST
    Release --> SR
    
    Deploy --> IaC
    Operate --> RS
    Monitor --> SIEM
```

### 1.2 ë³´ì•ˆ ë„êµ¬ ë§¤í•‘

| ë‹¨ê³„ | ë³´ì•ˆ í™œë™ | ì¶”ì²œ ë„êµ¬ |
|------|----------|----------|
| **Plan** | ìœ„í˜‘ ëª¨ë¸ë§, ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ | STRIDE, OWASP Threat Dragon |
| **Code** | SAST, Secret ìŠ¤ìº” | Semgrep, SonarQube, Gitleaks |
| **Build** | SCA, ì´ë¯¸ì§€ ìŠ¤ìº” | Trivy, Snyk, Grype |
| **Test** | DAST, IAST | OWASP ZAP, Burp Suite |
| **Release** | ì´ë¯¸ì§€ ì„œëª…, SBOM | Cosign, Syft |
| **Deploy** | IaC ìŠ¤ìº”, Policy | Checkov, OPA, Kyverno |
| **Operate** | ëŸ°íƒ€ì„ ë³´ì•ˆ | Falco, Sysdig |
| **Monitor** | SIEM, ë¡œê·¸ ë¶„ì„ | Datadog, Splunk, ELK |

### 1.4 CI/CD íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ í†µí•©

#### 1.4.1 ë³´ì•ˆ ê²Œì´íŠ¸ ì„¤ê³„ ì›ì¹™

ë³´ì•ˆ ê²Œì´íŠ¸ëŠ” ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:

1. **Fail Fast**: ì¹˜ëª…ì  ì·¨ì•½ì ì€ ì¦‰ì‹œ ë¹Œë“œ ì¤‘ë‹¨
2. **Progressive**: ë‹¨ê³„ë³„ë¡œ ì ì§„ì  ê²€ì¦
3. **Informative**: ê°œë°œìì—ê²Œ ëª…í™•í•œ ìˆ˜ì • ê°€ì´ë“œ ì œê³µ
4. **Automated**: ìˆ˜ë™ ê°œì… ìµœì†Œí™”

```yaml
# ë³´ì•ˆ ê²Œì´íŠ¸ ì„ê³„ê°’ ì„¤ì •
security_gates:
  sast:
    critical: 0   # Critical ì·¨ì•½ì  0ê±´ ì´ìƒ ì‹œ ë¹Œë“œ ì‹¤íŒ¨
    high: 5       # High 5ê±´ ì´ìƒ ì‹œ ê²½ê³ 
    medium: 20    # Medium 20ê±´ ì´ìƒ ì‹œ ê²½ê³ 

  sca:
    critical_cvss: 9.0  # CVSS 9.0 ì´ìƒ ì°¨ë‹¨
    high_cvss: 7.0      # CVSS 7.0-8.9 ê²½ê³ 
    license_blacklist:  # ë¼ì´ì„ ìŠ¤ ì œí•œ
      - "GPL-3.0"
      - "AGPL-3.0"

  image_scan:
    max_age_days: 90        # 90ì¼ ì´ìƒ ì˜¤ë˜ëœ ë² ì´ìŠ¤ ì´ë¯¸ì§€ ê±°ë¶€
    max_vulnerabilities: 10  # ì·¨ì•½ì  10ê±´ ì´ìƒ ê±°ë¶€

  secrets:
    fail_on_detection: true  # Secret ë°œê²¬ ì‹œ ì¦‰ì‹œ ì‹¤íŒ¨
```

#### 1.4.2 íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ë³´ì•ˆ ê²€ì¦

```mermaid
graph LR
    A[Code Push] --> B[Secret Scan]
    B --> C{Secret Found?}
    C -->|Yes| D[Block + Alert]
    C -->|No| E[SAST]
    E --> F{Critical?}
    F -->|Yes| D
    F -->|No| G[SCA]
    G --> H{Vulnerable Deps?}
    H -->|Critical| D
    H -->|Low/Medium| I[Build Image]
    I --> J[Image Scan]
    J --> K{Vuln Threshold?}
    K -->|Exceeded| D
    K -->|Pass| L[DAST]
    L --> M{OWASP Top 10?}
    M -->|Found| D
    M -->|Pass| N[Deploy to Staging]
    N --> O[Runtime Security]
    O --> P[Monitor]
```

## 2. ë„êµ¬ ì²´ì¸ ìƒì„¸ ê°€ì´ë“œ

### 2.1 SAST (Static Application Security Testing)

ì •ì  ì½”ë“œ ë¶„ì„ì€ ì†ŒìŠ¤ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì·¨ì•½ì ì„ íƒì§€í•©ë‹ˆë‹¤.

#### 2.1.1 SonarQube í†µí•© ì„¤ì •

**Docker Composeë¡œ SonarQube ì‹¤í–‰:**

```yaml
# docker-compose.yml
version: '3.8'
services:
  sonarqube:
    image: sonarqube:10.4-community
    ports:
      - "9000:9000"
    environment:
      - SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true
    volumes:
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_extensions:/opt/sonarqube/extensions
      - sonarqube_logs:/opt/sonarqube/logs

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: sonar
      POSTGRES_PASSWORD: sonar
      POSTGRES_DB: sonarqube
    volumes:
      - postgresql:/var/lib/postgresql
      - postgresql_data:/var/lib/postgresql/data

volumes:
  sonarqube_data:
  sonarqube_extensions:
  sonarqube_logs:
  postgresql:
  postgresql_data:
```

**CIì—ì„œ SonarQube ìŠ¤ìº”:**

```yaml
# .github/workflows/sonarqube.yml
name: SonarQube Analysis
on:
  push:
    branches: [main, develop]
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  sonarqube:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better blame

      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: {% raw %}${{ secrets.SONAR_TOKEN }}{% endraw %}
          SONAR_HOST_URL: {% raw %}${{ secrets.SONAR_HOST_URL }}{% endraw %}

      - name: SonarQube Quality Gate
        uses: sonarsource/sonarqube-quality-gate-action@master
        timeout-minutes: 5
        env:
          SONAR_TOKEN: {% raw %}${{ secrets.SONAR_TOKEN }}{% endraw %}
```

**sonar-project.properties ì„¤ì •:**

```properties
# sonar-project.properties
sonar.projectKey=my-project
sonar.projectName=My Project
sonar.projectVersion=1.0.0

# ì†ŒìŠ¤ ì½”ë“œ ê²½ë¡œ
sonar.sources=src
sonar.tests=tests

# ì œì™¸í•  íŒŒì¼
sonar.exclusions=**/node_modules/**,**/*.test.js,**/vendor/**

# ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
sonar.javascript.lcov.reportPaths=coverage/lcov.info

# Quality Gate ê¸°ì¤€
sonar.qualitygate.wait=true
sonar.qualitygate.timeout=300

# ë³´ì•ˆ í•«ìŠ¤íŒŸ ì„ê³„ê°’
sonar.security_hotspots.threshold=0
```

#### 2.1.2 Semgrep - ì»¤ìŠ¤í…€ ë£° ê¸°ë°˜ SAST

Semgrepì€ ì»¤ìŠ¤í…€ ë³´ì•ˆ ë£°ì„ ì‘ì„±í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ SAST ë„êµ¬ì…ë‹ˆë‹¤.

```yaml
# .semgrep.yml
rules:
  - id: hardcoded-aws-credentials
    pattern: |
      aws_access_key_id = "..."
    message: "Hardcoded AWS credentials detected"
    severity: ERROR
    languages: [python, javascript]

  - id: sql-injection
    pattern-either:
      - pattern: |
          $DB.query("SELECT * FROM users WHERE id = " + $ID)
      - pattern: |
          $DB.exec(f"SELECT * FROM users WHERE id = {$ID}")
    message: "Possible SQL injection vulnerability"
    severity: ERROR
    languages: [python, javascript]
    fix: |
      Use parameterized queries instead:
      db.query("SELECT * FROM users WHERE id = ?", [id])

  - id: insecure-random
    pattern: |
      Math.random()
    message: "Math.random() is not cryptographically secure"
    severity: WARNING
    languages: [javascript]
    fix: |
      const crypto = require('crypto');
      crypto.randomBytes(16).toString('hex');
```

**CI í†µí•©:**

```yaml
# .github/workflows/semgrep.yml
name: Semgrep
on:
  push:
    branches: [main]
  pull_request: {}

jobs:
  semgrep:
    runs-on: ubuntu-latest
    container:
      image: returntocorp/semgrep
    steps:
      - uses: actions/checkout@v4
      - run: semgrep ci --config=auto --config=.semgrep.yml
        env:
          SEMGREP_APP_TOKEN: {% raw %}${{ secrets.SEMGREP_APP_TOKEN }}{% endraw %}
```

#### 2.1.3 CodeQL - GitHub ë„¤ì´í‹°ë¸Œ SAST

```yaml
# .github/workflows/codeql.yml
name: CodeQL Analysis
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 6 * * 1'  # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 6ì‹œ

jobs:
  analyze:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      actions: read
      contents: read

    strategy:
      matrix:
        language: ['javascript', 'python']

    steps:
      - uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: {% raw %}${{ matrix.language }}{% endraw %}
          queries: security-extended,security-and-quality

      - name: Autobuild
        uses: github/codeql-action/autobuild@v3

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:{% raw %}${{ matrix.language }}{% endraw %}"
```

### 2.2 DAST (Dynamic Application Security Testing)

ë™ì  ë¶„ì„ì€ ì‹¤í–‰ ì¤‘ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ëŒ€ìƒìœ¼ë¡œ ê³µê²©ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

#### 2.2.1 OWASP ZAP ìë™í™”

```yaml
# .github/workflows/zap-scan.yml
name: OWASP ZAP Scan
on:
  push:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ

jobs:
  zap_scan:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Deploy to Staging
        run: |
          # ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬
          kubectl apply -f k8s/staging/

      - name: Wait for Deployment
        run: |
          kubectl wait --for=condition=ready pod -l app=myapp --timeout=300s

      - name: ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.10.0
        with:
          target: 'https://staging.example.com'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a'

      - name: ZAP Full Scan
        uses: zaproxy/action-full-scan@v0.8.0
        with:
          target: 'https://staging.example.com'
          rules_file_name: '.zap/rules.tsv'
          allow_issue_writing: false

      - name: Upload ZAP Report
        uses: actions/upload-artifact@v4
        with:
          name: zap-report
          path: |
            zap_baseline_report.html
            zap_full_report.html
```

**ZAP ê·œì¹™ íŒŒì¼:**

```tsv
# .zap/rules.tsv
# Rule ID	Threshold	Ignore
10021	MEDIUM	# X-Content-Type-Options í—¤ë” ëˆ„ë½ (ìŠ¤í…Œì´ì§•ì—ì„œëŠ” ë¬´ì‹œ)
10038	MEDIUM	# Content Security Policy í—¤ë” ëˆ„ë½
10096	HIGH	# SQL Injection (ì ˆëŒ€ ë¬´ì‹œ ê¸ˆì§€)
40012	HIGH	# XSS (ì ˆëŒ€ ë¬´ì‹œ ê¸ˆì§€)
```

#### 2.2.2 Burp Suite Enterprise í†µí•©

```bash
# Burp Suite APIë¥¼ í†µí•œ ìŠ¤ìº” ìë™í™”
#!/bin/bash
set -e

BURP_API="https://burp.example.com/api/v0.1"
API_KEY="your-api-key-here"
TARGET_URL="https://staging.example.com"

# ìƒˆ ìŠ¤ìº” ìƒì„±
SCAN_ID=$(curl -X POST "$BURP_API/scan" \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d "{
    \"scope\": {
      \"include\": [\"$TARGET_URL\"],
      \"exclude\": [\"$TARGET_URL/admin\"]
    },
    \"scan_configurations\": [
      {\"type\": \"NamedConfiguration\", \"name\": \"Audit coverage - thorough\"}
    ]
  }" | jq -r '.scan_id')

echo "Scan started: $SCAN_ID"

# ìŠ¤ìº” ì™„ë£Œ ëŒ€ê¸°
while true; do
  STATUS=$(curl -s "$BURP_API/scan/$SCAN_ID" \
    -H "Authorization: Bearer $API_KEY" | jq -r '.scan_status')

  if [[ "$STATUS" == "succeeded" ]]; then
    echo "Scan completed successfully"
    break
  elif [[ "$STATUS" == "failed" ]]; then
    echo "Scan failed"
    exit 1
  fi

  echo "Scan in progress... ($STATUS)"
  sleep 30
done

# ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
curl "$BURP_API/scan/$SCAN_ID/report?report_type=html" \
  -H "Authorization: Bearer $API_KEY" \
  -o burp-report.html
```

### 2.3 SCA (Software Composition Analysis)

ì˜ì¡´ì„± ì·¨ì•½ì ì„ íƒì§€í•˜ê³  ë¼ì´ì„ ìŠ¤ ì»´í”Œë¼ì´ì–¸ìŠ¤ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.

#### 2.3.1 Snyk - í¬ê´„ì ì¸ SCA

```yaml
# .github/workflows/snyk.yml
name: Snyk Security Scan
on:
  push:
    branches: [main]
  pull_request:

jobs:
  snyk:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Snyk to check for vulnerabilities
        uses: snyk/actions/node@master
        continue-on-error: true
        env:
          SNYK_TOKEN: {% raw %}${{ secrets.SNYK_TOKEN }}{% endraw %}
        with:
          args: --severity-threshold=high --fail-on=all

      - name: Snyk Container Test
        uses: snyk/actions/docker@master
        env:
          SNYK_TOKEN: {% raw %}${{ secrets.SNYK_TOKEN }}{% endraw %}
        with:
          image: myapp:latest
          args: --file=Dockerfile --severity-threshold=high

      - name: Snyk IaC Test
        uses: snyk/actions/iac@master
        env:
          SNYK_TOKEN: {% raw %}${{ secrets.SNYK_TOKEN }}{% endraw %}
        with:
          file: terraform/

      - name: Upload result to GitHub Code Scanning
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: snyk.sarif
```

#### 2.3.2 Dependabot ê³ ê¸‰ ì„¤ì •

```yaml
# .github/dependabot.yml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "daily"
      time: "03:00"
      timezone: "Asia/Seoul"

    # ë³´ì•ˆ ì—…ë°ì´íŠ¸ ìš°ì„ ìˆœìœ„
    open-pull-requests-limit: 10
    reviewers:
      - "security-team"
    labels:
      - "dependencies"
      - "security"

    # ë²„ì „ ì „ëµ
    versioning-strategy: increase

    # ì»¤ë°‹ ë©”ì‹œì§€ í…œí”Œë¦¿
    commit-message:
      prefix: "fix"
      prefix-development: "chore"
      include: "scope"

    # ë¬´ì‹œí•  ì—…ë°ì´íŠ¸
    ignore:
      - dependency-name: "lodash"
        versions: ["4.17.x"]  # íŠ¹ì • ë²„ì „ ê³ ì •
      - dependency-name: "aws-sdk"
        update-types: ["version-update:semver-major"]  # ë©”ì´ì € ì—…ë°ì´íŠ¸ ë¬´ì‹œ

  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"
      day: "monday"

  - package-ecosystem: "terraform"
    directory: "/terraform"
    schedule:
      interval: "weekly"
```

#### 2.3.3 Trivy - ë©€í‹° íƒ€ê²Ÿ ìŠ¤ìºë„ˆ

```bash
# Trivyë¡œ ë‹¤ì–‘í•œ íƒ€ê²Ÿ ìŠ¤ìº”
#!/bin/bash

# íŒŒì¼ ì‹œìŠ¤í…œ ìŠ¤ìº”
trivy fs . \
  --severity HIGH,CRITICAL \
  --format json \
  --output trivy-fs-report.json

# Docker ì´ë¯¸ì§€ ìŠ¤ìº”
trivy image myapp:latest \
  --severity HIGH,CRITICAL \
  --ignore-unfixed \
  --format table

# Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìŠ¤ìº”
trivy config k8s/ \
  --severity HIGH,CRITICAL \
  --format sarif \
  --output trivy-k8s.sarif

# SBOM ìƒì„±
trivy image myapp:latest \
  --format cyclonedx \
  --output sbom.json

# ì·¨ì•½ì  DB ì—…ë°ì´íŠ¸
trivy image --download-db-only
```

**Trivy CI í†µí•©:**

```yaml
# .github/workflows/trivy.yml
name: Trivy Security Scan
on:
  push:
    branches: [main]
  pull_request:

jobs:
  trivy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Trivy Image Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          image-ref: 'myapp:{% raw %}${{ github.sha }}{% endraw %}'
          format: 'table'
          exit-code: '1'
          ignore-unfixed: true
          vuln-type: 'os,library'
          severity: 'CRITICAL'
```

### 2.4 ì»¨í…Œì´ë„ˆ ë³´ì•ˆ

#### 2.4.1 Falco - ëŸ°íƒ€ì„ ìœ„í˜‘ íƒì§€

**Falco ì„¤ì¹˜ (Kubernetes):**

```yaml
# falco-values.yaml
ebpf:
  enabled: true

falco:
  grpc:
    enabled: true
  grpcOutput:
    enabled: true

  jsonOutput: true
  jsonIncludeOutputProperty: true

  rules_file:
    - /etc/falco/falco_rules.yaml
    - /etc/falco/falco_rules.local.yaml
    - /etc/falco/rules.d

  # ì»¤ìŠ¤í…€ ê·œì¹™
  customRules:
    custom-rules.yaml: |-
      - rule: Detect crypto miners
        desc: Detect crypto mining activities
        condition: >
          spawned_process and
          proc.name in (xmrig, minerd, ccminer)
        output: >
          Crypto miner detected
          (user=%user.name command=%proc.cmdline container=%container.name)
        priority: CRITICAL
        tags: [container, malware]

      - rule: Unauthorized File Access
        desc: Detect unauthorized access to sensitive files
        condition: >
          open_read and
          fd.name pmatch (/etc/shadow, /etc/passwd) and
          not proc.name in (sshd, sudo)
        output: >
          Unauthorized file access
          (user=%user.name file=%fd.name command=%proc.cmdline)
        priority: WARNING
        tags: [filesystem, security]
```

```bash
# Helmìœ¼ë¡œ Falco ì„¤ì¹˜
helm repo add falcosecurity https://falcosecurity.github.io/charts
helm repo update

helm install falco falcosecurity/falco \
  --namespace falco \
  --create-namespace \
  -f falco-values.yaml
```

**Falco Sidekickìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡:**

```yaml
# falcosidekick-values.yaml
config:
  slack:
    webhookurl: "https://hooks.slack.com/services/XXX/YYY/ZZZ"
    minimumpriority: "warning"
    messageformat: "long"

  webhook:
    address: "https://siem.example.com/events"
    minimumpriority: "error"

  elasticsearch:
    hostport: "https://elasticsearch:9200"
    index: "falco"
    type: "event"
    minimumpriority: "debug"
```

#### 2.4.2 Aqua Security / Prisma Cloud

```yaml
# aqua-enforcer.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: aqua-enforcer-config
data:
  AQUA_TOKEN: "your-token-here"
  AQUA_SERVER: "https://aqua-console.example.com"
  AQUA_LOGICAL_NAME: "production-cluster"

  # ì •ì±… ì„¤ì •
  AQUA_ENFORCER_MODE: "enforce"  # audit | enforce
  AQUA_NETWORK_CONTROL: "true"
  AQUA_CONTAINER_ACTIVITY_PROTECTION: "true"
```

### 2.5 IaC (Infrastructure as Code) ìŠ¤ìº”

#### 2.5.1 Checkov - Terraform/CloudFormation ìŠ¤ìº”

```bash
# Checkovë¡œ Terraform ìŠ¤ìº”
checkov -d terraform/ \
  --framework terraform \
  --output json \
  --output-file checkov-report.json \
  --compact \
  --quiet

# íŠ¹ì • ì²´í¬ë§Œ ì‹¤í–‰
checkov -f main.tf \
  --check CKV_AWS_23,CKV_AWS_24 \
  --framework terraform

# íŠ¹ì • ì²´í¬ ìŠ¤í‚µ
checkov -d . \
  --skip-check CKV_AWS_23 \
  --framework terraform
```

**ì»¤ìŠ¤í…€ Checkov ì •ì±…:**

```python
# custom_checks/S3PublicAccessBlock.py
from checkov.terraform.checks.resource.base_resource_check import BaseResourceCheck
from checkov.common.models.enums import CheckResult, CheckCategories

class S3PublicAccessBlock(BaseResourceCheck):
    def __init__(self):
        name = "S3 bucket should have public access block enabled"
        id = "CKV_AWS_CUSTOM_1"
        supported_resources = ['aws_s3_bucket']
        categories = [CheckCategories.ENCRYPTION]
        super().__init__(name=name, id=id, categories=categories,
                         supported_resources=supported_resources)

    def scan_resource_conf(self, conf):
        # Check if public access block is configured
        if 'block_public_acls' in conf and conf['block_public_acls'][0]:
            if 'block_public_policy' in conf and conf['block_public_policy'][0]:
                return CheckResult.PASSED
        return CheckResult.FAILED

check = S3PublicAccessBlock()
```

#### 2.5.2 tfsec - Terraform ì „ìš© ìŠ¤ìºë„ˆ

```bash
# tfsecë¡œ Terraform ìŠ¤ìº”
tfsec . \
  --format json \
  --out tfsec-report.json \
  --minimum-severity HIGH

# Sarif í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (GitHub Security íƒ­ ì—°ë™)
tfsec . \
  --format sarif \
  --out tfsec.sarif \
  --soft-fail
```

**GitHub Actions í†µí•©:**

```yaml
# .github/workflows/tfsec.yml
name: tfsec
on:
  push:
    branches: [main]
    paths:
      - 'terraform/**'

jobs:
  tfsec:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: tfsec
        uses: aquasecurity/tfsec-action@v1.0.3
        with:
          working_directory: terraform/
          soft_fail: false
          format: sarif
          output: tfsec.sarif

      - name: Upload SARIF file
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: tfsec.sarif
```

#### 2.5.3 KICS - ë©€í‹° í”Œë«í¼ IaC ìŠ¤ìºë„ˆ

```bash
# KICSë¡œ ë‹¤ì–‘í•œ IaC ìŠ¤ìº”
kics scan \
  -p terraform/ \
  -o kics-results/ \
  --report-formats json,sarif,html \
  --exclude-severities info,low

# Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìŠ¤ìº”
kics scan \
  -p k8s/ \
  --type Kubernetes \
  --exclude-queries bb241e61-77c3-4b97-9575-c0f8a1e008d0

# Docker ìŠ¤ìº”
kics scan \
  -p Dockerfile \
  --type Dockerfile
```

## 3. CI/CD íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ì„¤ê³„

### 3.1 GitHub Actions ì™„ì „í•œ ë³´ì•ˆ íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/security-pipeline.yml
name: Complete Security Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    types: [opened, synchronize, reopened]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: {% raw %}${{ github.repository }}{% endraw %}

jobs:
  # Stage 1: Secret Scanning
  secret-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Gitleaks Scan
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}

      - name: TruffleHog Scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: {% raw %}${{ github.event.repository.default_branch }}{% endraw %}
          head: HEAD

  # Stage 2: SAST
  sast:
    needs: secret-scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Semgrep Scan
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/owasp-top-ten
            p/cwe-top-25

      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: {% raw %}${{ secrets.SONAR_TOKEN }}{% endraw %}
          SONAR_HOST_URL: {% raw %}${{ secrets.SONAR_HOST_URL }}{% endraw %}

      - name: CodeQL Analysis
        uses: github/codeql-action/analyze@v3

  # Stage 3: SCA
  sca:
    needs: sast
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Snyk Test
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: {% raw %}${{ secrets.SNYK_TOKEN }}{% endraw %}
        with:
          args: --severity-threshold=high --fail-on=upgradable

      - name: Trivy Filesystem Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-fs.sarif'

      - name: Upload Trivy Results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-fs.sarif'

  # Stage 4: Build & Image Scan
  build-and-scan:
    needs: sca
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      security-events: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          load: true
          tags: {% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Trivy Image Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          image-ref: {% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %}
          format: 'sarif'
          output: 'trivy-image.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Grype Image Scan
        uses: anchore/scan-action@v3
        with:
          image: {% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %}
          fail-build: true
          severity-cutoff: high

      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: {% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %}
          format: cyclonedx-json
          output-file: sbom.json

      - name: Sign Image with Cosign
        run: |
          cosign sign --yes {% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %}
        env:
          COSIGN_EXPERIMENTAL: 1

  # Stage 5: IaC Scan
  iac-scan:
    needs: sast
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Checkov Scan
        uses: bridgecrewio/checkov-action@master
        with:
          directory: terraform/
          framework: terraform
          output_format: sarif
          output_file_path: checkov.sarif

      - name: tfsec Scan
        uses: aquasecurity/tfsec-action@v1.0.3
        with:
          working_directory: terraform/
          format: sarif
          output: tfsec.sarif

      - name: Terraform Plan
        run: |
          cd terraform
          terraform init
          terraform plan -out=tfplan
          terraform show -json tfplan > tfplan.json

      - name: OPA Policy Check
        run: |
          opa eval -d policies/ -i tfplan.json \
            "data.terraform.deny[msg]"

  # Stage 6: Deploy to Staging
  deploy-staging:
    needs: [build-and-scan, iac-scan]
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - uses: actions/checkout@v4

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/myapp \
            myapp={% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %} \
            --namespace=staging

      - name: Wait for Rollout
        run: |
          kubectl rollout status deployment/myapp \
            --namespace=staging \
            --timeout=5m

  # Stage 7: DAST
  dast:
    needs: deploy-staging
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: OWASP ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.10.0
        with:
          target: 'https://staging.example.com'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a -j'

      - name: Nuclei Scan
        uses: projectdiscovery/nuclei-action@main
        with:
          target: 'https://staging.example.com'
          templates: 'vulnerabilities,exposures'

  # Stage 8: Deploy to Production
  deploy-production:
    needs: dast
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://example.com
    steps:
      - uses: actions/checkout@v4

      - name: Blue-Green Deployment
        run: |
          # Deploy to green environment
          kubectl set image deployment/myapp-green \
            myapp={% raw %}${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}{% endraw %} \
            --namespace=production

          # Wait for rollout
          kubectl rollout status deployment/myapp-green \
            --namespace=production \
            --timeout=10m

          # Switch traffic
          kubectl patch service myapp -p \
            '{"spec":{"selector":{"version":"green"}}}' \
            --namespace=production

      - name: Smoke Tests
        run: |
          curl -f https://example.com/health || exit 1

  # Stage 9: Runtime Security Monitoring
  runtime-monitor:
    needs: deploy-production
    runs-on: ubuntu-latest
    steps:
      - name: Verify Falco Rules
        run: |
          kubectl get falcoalert -n falco \
            --field-selector priority=CRITICAL \
            --sort-by='.metadata.creationTimestamp' \
            | grep {% raw %}${{ github.sha }}{% endraw %} && exit 1 || exit 0

      - name: Check Security Posture
        run: |
          # Verify no privileged containers
          kubectl get pods -A -o json | \
            jq '.items[] | select(.spec.containers[].securityContext.privileged == true)' \
            | jq -e 'length == 0'
```

### 3.2 Jenkins ë³´ì•ˆ íŒŒì´í”„ë¼ì¸

```groovy
// Jenkinsfile
@Library('security-shared-library') _

pipeline {
    agent any

    options {
        timestamps()
        timeout(time: 1, unit: 'HOURS')
        buildDiscarder(logRotator(numToKeepStr: '10'))
    }

    environment {
        DOCKER_REGISTRY = 'docker.io/myorg'
        APP_NAME = 'myapp'
        SONAR_HOST = credentials('sonarqube-url')
        SONAR_TOKEN = credentials('sonarqube-token')
        SNYK_TOKEN = credentials('snyk-token')
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
                sh 'git log -1 --format="%H %an %ae %s" > git-info.txt'
            }
        }

        stage('Secret Scan') {
            parallel {
                stage('Gitleaks') {
                    steps {
                        sh '''
                            docker run --rm -v $(pwd):/path zricethezav/gitleaks:latest \
                                detect --source="/path" --report-format=json \
                                --report-path=/path/gitleaks-report.json
                        '''
                    }
                }
                stage('TruffleHog') {
                    steps {
                        sh '''
                            docker run --rm -v $(pwd):/pwd trufflesecurity/trufflehog:latest \
                                filesystem /pwd --json > trufflehog-report.json
                        '''
                    }
                }
            }
            post {
                always {
                    publishHTML([
                        reportName: 'Secret Scan Report',
                        reportDir: '.',
                        reportFiles: 'gitleaks-report.json',
                        keepAll: true
                    ])
                }
            }
        }

        stage('SAST') {
            parallel {
                stage('SonarQube') {
                    steps {
                        withSonarQubeEnv('SonarQube') {
                            sh '''
                                sonar-scanner \
                                    -Dsonar.projectKey=myapp \
                                    -Dsonar.sources=src \
                                    -Dsonar.host.url=${SONAR_HOST} \
                                    -Dsonar.login=${SONAR_TOKEN}
                            '''
                        }
                    }
                }
                stage('Semgrep') {
                    steps {
                        sh '''
                            docker run --rm -v $(pwd):/src returntocorp/semgrep \
                                semgrep --config=auto --json --output=semgrep-report.json /src
                        '''
                    }
                }
            }
        }

        stage('Quality Gate') {
            steps {
                timeout(time: 5, unit: 'MINUTES') {
                    waitForQualityGate abortPipeline: true
                }
            }
        }

        stage('SCA') {
            parallel {
                stage('Snyk') {
                    steps {
                        sh '''
                            snyk test --severity-threshold=high \
                                --json-file-output=snyk-report.json
                        '''
                    }
                }
                stage('Trivy FS') {
                    steps {
                        sh '''
                            trivy fs . \
                                --severity HIGH,CRITICAL \
                                --format json \
                                --output trivy-fs-report.json
                        '''
                    }
                }
            }
        }

        stage('Build Docker Image') {
            steps {
                script {
                    env.IMAGE_TAG = "${env.BUILD_NUMBER}-${env.GIT_COMMIT.take(7)}"
                    env.FULL_IMAGE_NAME = "${DOCKER_REGISTRY}/${APP_NAME}:${IMAGE_TAG}"
                }
                sh '''
                    docker build -t ${FULL_IMAGE_NAME} .
                '''
            }
        }

        stage('Image Scan') {
            parallel {
                stage('Trivy Image') {
                    steps {
                        sh '''
                            trivy image ${FULL_IMAGE_NAME} \
                                --severity CRITICAL,HIGH \
                                --exit-code 1 \
                                --format json \
                                --output trivy-image-report.json
                        '''
                    }
                }
                stage('Grype') {
                    steps {
                        sh '''
                            grype ${FULL_IMAGE_NAME} \
                                --fail-on high \
                                --output json \
                                --file grype-report.json
                        '''
                    }
                }
                stage('Generate SBOM') {
                    steps {
                        sh '''
                            syft ${FULL_IMAGE_NAME} \
                                -o cyclonedx-json \
                                --file sbom.json
                        '''
                    }
                }
            }
        }

        stage('Push Image') {
            when {
                branch 'main'
            }
            steps {
                withDockerRegistry([credentialsId: 'docker-registry', url: '']) {
                    sh 'docker push ${FULL_IMAGE_NAME}'
                }
            }
        }

        stage('IaC Scan') {
            parallel {
                stage('Checkov') {
                    steps {
                        sh '''
                            checkov -d terraform/ \
                                --framework terraform \
                                --output json \
                                --output-file checkov-report.json
                        '''
                    }
                }
                stage('tfsec') {
                    steps {
                        sh '''
                            tfsec terraform/ \
                                --format json \
                                --out tfsec-report.json \
                                --minimum-severity HIGH
                        '''
                    }
                }
            }
        }

        stage('Deploy to Staging') {
            when {
                branch 'main'
            }
            steps {
                sh '''
                    kubectl set image deployment/myapp \
                        myapp=${FULL_IMAGE_NAME} \
                        --namespace=staging
                    kubectl rollout status deployment/myapp \
                        --namespace=staging \
                        --timeout=5m
                '''
            }
        }

        stage('DAST') {
            when {
                branch 'main'
            }
            steps {
                sh '''
                    docker run --rm -v $(pwd):/zap/wrk:rw \
                        owasp/zap2docker-stable zap-baseline.py \
                        -t https://staging.example.com \
                        -r zap-report.html \
                        -J zap-report.json
                '''
            }
        }

        stage('Deploy to Production') {
            when {
                branch 'main'
            }
            steps {
                input message: 'Deploy to Production?', ok: 'Deploy'
                sh '''
                    kubectl set image deployment/myapp \
                        myapp=${FULL_IMAGE_NAME} \
                        --namespace=production
                    kubectl rollout status deployment/myapp \
                        --namespace=production \
                        --timeout=10m
                '''
            }
        }
    }

    post {
        always {
            // ëª¨ë“  ë¦¬í¬íŠ¸ ìˆ˜ì§‘
            archiveArtifacts artifacts: '*-report.json', allowEmptyArchive: true

            // Slack ì•Œë¦¼
            script {
                def color = currentBuild.result == 'SUCCESS' ? 'good' : 'danger'
                slackSend(
                    color: color,
                    message: "Pipeline ${currentBuild.result}: ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                )
            }
        }
        failure {
            emailext(
                subject: "Pipeline Failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}",
                body: "Check console output at ${env.BUILD_URL}",
                to: "security-team@example.com"
            )
        }
    }
}
```

### 3.3 GitLab CI ë³´ì•ˆ í†µí•©

```yaml
# .gitlab-ci.yml
variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: ""
  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA

stages:
  - security-scan
  - build
  - test
  - deploy-staging
  - dast
  - deploy-production

# Secret Scanning
gitleaks:
  stage: security-scan
  image: zricethezav/gitleaks:latest
  script:
    - gitleaks detect --source . --report-format json --report-path gitleaks-report.json
  artifacts:
    reports:
      gitleaks: gitleaks-report.json
    expire_in: 1 week
  allow_failure: false

# SAST using GitLab
sast:
  stage: security-scan
  include:
    - template: Security/SAST.gitlab-ci.yml

semgrep-sast:
  stage: security-scan
  image: returntocorp/semgrep
  script:
    - semgrep --config=auto --json --output=gl-sast-report.json
  artifacts:
    reports:
      sast: gl-sast-report.json

# SCA
dependency_scanning:
  stage: security-scan
  include:
    - template: Security/Dependency-Scanning.gitlab-ci.yml

snyk-test:
  stage: security-scan
  image: snyk/snyk:node
  script:
    - snyk auth $SNYK_TOKEN
    - snyk test --severity-threshold=high --json-file-output=snyk-report.json
  artifacts:
    reports:
      dependency_scanning: snyk-report.json

# Build Docker Image
build:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker build -t $IMAGE_TAG .
    - docker push $IMAGE_TAG
  only:
    - main
    - merge_requests

# Container Scanning
container_scanning:
  stage: test
  image: aquasec/trivy:latest
  script:
    - trivy image --severity CRITICAL,HIGH --exit-code 1 $IMAGE_TAG
  dependencies:
    - build
  only:
    - main

# IaC Scanning
iac_scanning:
  stage: security-scan
  image: bridgecrew/checkov:latest
  script:
    - checkov -d terraform/ --framework terraform --output junitxml --output-file checkov-report.xml
  artifacts:
    reports:
      junit: checkov-report.xml

# Deploy to Staging
deploy_staging:
  stage: deploy-staging
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context staging
    - kubectl set image deployment/myapp myapp=$IMAGE_TAG --namespace=staging
    - kubectl rollout status deployment/myapp --namespace=staging --timeout=5m
  environment:
    name: staging
    url: https://staging.example.com
  only:
    - main

# DAST
dast:
  stage: dast
  include:
    - template: DAST.gitlab-ci.yml
  variables:
    DAST_WEBSITE: https://staging.example.com
    DAST_FULL_SCAN_ENABLED: "true"
  dependencies:
    - deploy_staging
  only:
    - main

# Deploy to Production
deploy_production:
  stage: deploy-production
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context production
    - kubectl set image deployment/myapp myapp=$IMAGE_TAG --namespace=production
    - kubectl rollout status deployment/myapp --namespace=production --timeout=10m
  environment:
    name: production
    url: https://example.com
  when: manual
  only:
    - main
```

## 4. AWS ë³´ì•ˆ ì„œë¹„ìŠ¤ í†µí•©

### 4.1 AWS Security Hub ì¤‘ì•™ ë³´ì•ˆ ê´€ë¦¬

```python
# security_hub_integration.py
import boto3
import json
from datetime import datetime

class SecurityHubIntegration:
    def __init__(self, region='us-east-1'):
        self.client = boto3.client('securityhub', region_name=region)

    def import_findings(self, findings):
        """
        CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ë°œê²¬ëœ ì·¨ì•½ì ì„ Security Hubë¡œ ì „ì†¡
        """
        formatted_findings = []

        for finding in findings:
            formatted_finding = {
                'SchemaVersion': '2018-10-08',
                'Id': finding['id'],
                'ProductArn': f'arn:aws:securityhub:{self.client.meta.region_name}:{self._get_account_id()}:product/{self._get_account_id()}/default',
                'GeneratorId': 'cicd-pipeline',
                'AwsAccountId': self._get_account_id(),
                'Types': ['Software and Configuration Checks/Vulnerabilities/CVE'],
                'CreatedAt': datetime.utcnow().isoformat() + 'Z',
                'UpdatedAt': datetime.utcnow().isoformat() + 'Z',
                'Severity': {
                    'Label': self._map_severity(finding['severity'])
                },
                'Title': finding['title'],
                'Description': finding['description'],
                'Resources': [{
                    'Type': 'Container',
                    'Id': finding['container_id'],
                    'Partition': 'aws',
                    'Region': self.client.meta.region_name
                }],
                'Compliance': {
                    'Status': 'FAILED' if finding['severity'] in ['CRITICAL', 'HIGH'] else 'WARNING'
                },
                'Remediation': {
                    'Recommendation': {
                        'Text': finding.get('recommendation', 'Review and remediate'),
                        'Url': finding.get('reference_url', '')
                    }
                }
            }
            formatted_findings.append(formatted_finding)

        # Batch import (ìµœëŒ€ 100ê°œì”©)
        for i in range(0, len(formatted_findings), 100):
            batch = formatted_findings[i:i+100]
            response = self.client.batch_import_findings(Findings=batch)
            print(f"Imported {response['SuccessCount']} findings")

    def _get_account_id(self):
        sts = boto3.client('sts')
        return sts.get_caller_identity()['Account']

    def _map_severity(self, severity):
        mapping = {
            'CRITICAL': 'CRITICAL',
            'HIGH': 'HIGH',
            'MEDIUM': 'MEDIUM',
            'LOW': 'LOW',
            'INFO': 'INFORMATIONAL'
        }
        return mapping.get(severity, 'INFORMATIONAL')

    def get_findings_summary(self, filters=None):
        """
        Security Hub ì·¨ì•½ì  ìš”ì•½ ì¡°íšŒ
        """
        if filters is None:
            filters = {
                'RecordState': [{'Value': 'ACTIVE', 'Comparison': 'EQUALS'}],
                'WorkflowStatus': [{'Value': 'NEW', 'Comparison': 'EQUALS'}]
            }

        paginator = self.client.get_paginator('get_findings')
        findings = []

        for page in paginator.paginate(Filters=filters):
            findings.extend(page['Findings'])

        summary = {
            'total': len(findings),
            'critical': len([f for f in findings if f['Severity']['Label'] == 'CRITICAL']),
            'high': len([f for f in findings if f['Severity']['Label'] == 'HIGH']),
            'medium': len([f for f in findings if f['Severity']['Label'] == 'MEDIUM']),
            'low': len([f for f in findings if f['Severity']['Label'] == 'LOW'])
        }

        return summary

# Usage in CI/CD
if __name__ == '__main__':
    # Trivy ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ
    with open('trivy-report.json') as f:
        trivy_results = json.load(f)

    findings = []
    for result in trivy_results.get('Results', []):
        for vuln in result.get('Vulnerabilities', []):
            findings.append({
                'id': vuln['VulnerabilityID'],
                'title': f"{vuln['PkgName']}: {vuln['VulnerabilityID']}",
                'description': vuln.get('Description', 'No description'),
                'severity': vuln['Severity'],
                'container_id': result['Target'],
                'recommendation': f"Upgrade {vuln['PkgName']} to {vuln.get('FixedVersion', 'latest')}",
                'reference_url': vuln.get('PrimaryURL', '')
            })

    hub = SecurityHubIntegration()
    hub.import_findings(findings)
    print("Summary:", hub.get_findings_summary())
```

### 4.2 GuardDuty ìë™ ëŒ€ì‘

```python
# guardduty_auto_response.py
import boto3
import json

def lambda_handler(event, context):
    """
    GuardDuty Findingì„ EventBridgeë¡œ ìˆ˜ì‹ í•˜ì—¬ ìë™ ëŒ€ì‘
    """
    finding = event['detail']
    severity = finding['severity']
    finding_type = finding['type']

    print(f"Processing finding: {finding_type} (Severity: {severity})")

    # Critical/High ì‹¬ê°ë„ë§Œ ìë™ ëŒ€ì‘
    if severity >= 7.0:
        if 'UnauthorizedAccess:EC2' in finding_type:
            isolate_instance(finding)
        elif 'CryptoCurrency:EC2' in finding_type:
            block_network_and_alert(finding)
        elif 'Trojan:EC2' in finding_type:
            quarantine_instance(finding)

    # ëª¨ë“  findingì„ Security Hubë¡œ ì „ì†¡
    send_to_security_hub(finding)

    # Slack ì•Œë¦¼
    send_slack_notification(finding)

    return {
        'statusCode': 200,
        'body': json.dumps('Auto-response completed')
    }

def isolate_instance(finding):
    """
    EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê²©ë¦¬ëœ Security Groupìœ¼ë¡œ ì´ë™
    """
    ec2 = boto3.client('ec2')
    instance_id = finding['resource']['instanceDetails']['instanceId']

    # ê²©ë¦¬ìš© Security Group (ëª¨ë“  íŠ¸ë˜í”½ ì°¨ë‹¨)
    isolation_sg = 'sg-isolation-12345'

    response = ec2.modify_instance_attribute(
        InstanceId=instance_id,
        Groups=[isolation_sg]
    )

    print(f"Instance {instance_id} isolated to {isolation_sg}")

    # CloudWatchì— ì´ë²¤íŠ¸ ê¸°ë¡
    logs = boto3.client('logs')
    logs.put_log_events(
        logGroupName='/aws/guardduty/auto-response',
        logStreamName='instance-isolation',
        logEvents=[{
            'timestamp': int(finding['updatedAt']),
            'message': json.dumps({
                'action': 'isolate_instance',
                'instance_id': instance_id,
                'finding_type': finding['type'],
                'severity': finding['severity']
            })
        }]
    )

def block_network_and_alert(finding):
    """
    ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨ ë° ê¸´ê¸‰ ì•Œë¦¼
    """
    instance_id = finding['resource']['instanceDetails']['instanceId']

    # 1. Network ACLë¡œ ì¦‰ì‹œ ì°¨ë‹¨
    ec2 = boto3.client('ec2')
    response = ec2.describe_instances(InstanceIds=[instance_id])
    subnet_id = response['Reservations'][0]['Instances'][0]['SubnetId']

    # ì„ì‹œ NACL ìƒì„± (ëª¨ë“  íŠ¸ë˜í”½ ì°¨ë‹¨)
    nacl_response = ec2.create_network_acl(
        VpcId=response['Reservations'][0]['Instances'][0]['VpcId']
    )
    nacl_id = nacl_response['NetworkAcl']['NetworkAclId']

    # Subnetì— NACL ì—°ê²°
    ec2.replace_network_acl_association(
        AssociationId=subnet_id,
        NetworkAclId=nacl_id
    )

    # 2. SNSë¡œ ê¸´ê¸‰ ì•Œë¦¼
    sns = boto3.client('sns')
    sns.publish(
        TopicArn='arn:aws:sns:us-east-1:123456789012:security-critical',
        Subject='CRITICAL: Crypto Mining Detected',
        Message=json.dumps(finding, indent=2)
    )

def quarantine_instance(finding):
    """
    ì¸ìŠ¤í„´ìŠ¤ ìŠ¤ëƒ…ìƒ· ìƒì„± í›„ ì¢…ë£Œ
    """
    ec2 = boto3.client('ec2')
    instance_id = finding['resource']['instanceDetails']['instanceId']

    # 1. ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¡°íšŒ
    response = ec2.describe_instances(InstanceIds=[instance_id])
    instance = response['Reservations'][0]['Instances'][0]

    # 2. EBS ë³¼ë¥¨ ìŠ¤ëƒ…ìƒ· ìƒì„± (í¬ë Œì‹ ë¶„ì„ìš©)
    for device in instance.get('BlockDeviceMappings', []):
        volume_id = device['Ebs']['VolumeId']
        snapshot = ec2.create_snapshot(
            VolumeId=volume_id,
            Description=f'Quarantine snapshot for {instance_id}',
            TagSpecifications=[{
                'ResourceType': 'snapshot',
                'Tags': [
                    {'Key': 'QuarantineReason', 'Value': finding['type']},
                    {'Key': 'FindingId', 'Value': finding['id']},
                    {'Key': 'Severity', 'Value': str(finding['severity'])}
                ]
            }]
        )
        print(f"Created snapshot {snapshot['SnapshotId']} for volume {volume_id}")

    # 3. ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ
    ec2.stop_instances(InstanceIds=[instance_id])
    print(f"Instance {instance_id} stopped for quarantine")

def send_to_security_hub(finding):
    """
    Security Hubë¡œ ì „ì†¡
    """
    securityhub = boto3.client('securityhub')

    formatted_finding = {
        'SchemaVersion': '2018-10-08',
        'Id': finding['id'],
        'ProductArn': finding['productArn'],
        'GeneratorId': finding['type'],
        'AwsAccountId': finding['accountId'],
        'Types': ['TTPs/Initial Access'],
        'CreatedAt': finding['createdAt'],
        'UpdatedAt': finding['updatedAt'],
        'Severity': {
            'Label': 'CRITICAL' if finding['severity'] >= 8.0 else 'HIGH',
            'Normalized': int(finding['severity'] * 10)
        },
        'Title': finding['title'],
        'Description': finding['description'],
        'Resources': [finding['resource']]
    }

    securityhub.batch_import_findings(Findings=[formatted_finding])

def send_slack_notification(finding):
    """
    Slackìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡
    """
    import urllib3
    http = urllib3.PoolManager()

    slack_webhook = 'https://hooks.slack.com/services/XXX/YYY/ZZZ'

    severity_emoji = {
        8.0: ':rotating_light:',
        7.0: ':warning:',
        4.0: ':information_source:'
    }

    emoji = severity_emoji.get(
        next((k for k in sorted(severity_emoji.keys(), reverse=True) if finding['severity'] >= k), 4.0)
    )

    message = {
        'text': f"{emoji} GuardDuty Finding: {finding['type']}",
        'attachments': [{
            'color': 'danger' if finding['severity'] >= 7.0 else 'warning',
            'fields': [
                {'title': 'Severity', 'value': str(finding['severity']), 'short': True},
                {'title': 'Region', 'value': finding['region'], 'short': True},
                {'title': 'Resource', 'value': finding['resource']['instanceDetails']['instanceId'], 'short': False},
                {'title': 'Description', 'value': finding['description'], 'short': False}
            ]
        }]
    }

    http.request('POST', slack_webhook, body=json.dumps(message), headers={'Content-Type': 'application/json'})
```

**EventBridge ë£° ì„¤ì •:**

```json
{
  "source": ["aws.guardduty"],
  "detail-type": ["GuardDuty Finding"],
  "detail": {
    "severity": [
      {
        "numeric": [">=", 7.0]
      }
    ]
  }
}
```

## 5. SIEM Detection Queries

<!-- Splunk SPL Queries for DevSecOps Pipeline Security Events -->
<!--
# CI/CD íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ íŒ¨í„´ ê°ì§€
index=cicd sourcetype=github_actions OR sourcetype=jenkins
| eval pipeline_stage=case(
    match(_raw, "secret.*scan"), "secret_scan",
    match(_raw, "SAST"), "sast",
    match(_raw, "image.*scan"), "image_scan",
    match(_raw, "deploy"), "deploy",
    true(), "unknown"
)
| stats count by pipeline_stage, status, user
| where status="failure" AND count > 3
| table _time, user, pipeline_stage, count, repository

# ë³´ì•ˆ ê²Œì´íŠ¸ ìš°íšŒ ì‹œë„ ê°ì§€
index=cicd
| search ("skip-security" OR "--no-verify" OR "continue-on-error" OR "allow_failure=true")
| stats count by user, repository, _time
| where count > 0
| eval severity="CRITICAL"
| table _time, user, repository, severity, _raw

# Critical ì·¨ì•½ì  í”„ë¡œë•ì…˜ ë°°í¬ ê°ì§€
index=cicd sourcetype=trivy OR sourcetype=snyk
| search severity=CRITICAL status=deployed environment=production
| stats count by vulnerability_id, package, version, deployed_by
| sort -count
| head 20

# Secret ëˆ„ì¶œ ê°ì§€ (Gitleaks/TruffleHog)
index=cicd sourcetype=secret_scanner
| search RuleID=* DetectedSecret=*
| stats count by RuleID, File, Author, _time
| eval risk_score=case(
    match(RuleID, "aws.*key"), 100,
    match(RuleID, "private.*key"), 90,
    match(RuleID, "password"), 70,
    true(), 50
)
| where risk_score >= 70
| table _time, Author, File, RuleID, risk_score

# ë¹„ì •ìƒ íŒ¨ì¹˜ ì£¼ê¸° ê°ì§€ (90ì¼ ì´ìƒ ì˜¤ë˜ëœ ì·¨ì•½ì )
index=vulnerability
| eval days_since_discovery=round((now()-strptime(discovered_date, "%Y-%m-%d"))/86400, 0)
| where days_since_discovery > 90 AND severity IN ("CRITICAL", "HIGH")
| stats count by application, vulnerability_id, days_since_discovery
| sort -days_since_discovery
| head 50

# IaC ì •ì±… ìœ„ë°˜ ê°ì§€ (Checkov/tfsec)
index=cicd sourcetype=checkov OR sourcetype=tfsec
| search check_result=FAILED severity=HIGH OR severity=CRITICAL
| stats count by check_id, resource_type, file_path
| sort -count
| table check_id, resource_type, file_path, count

# ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ ì´ìƒ í–‰ë™ (Falco)
index=runtime sourcetype=falco
| search priority=CRITICAL OR priority=ERROR
| eval threat_category=case(
    match(rule, "Crypto"), "cryptomining",
    match(rule, "Network"), "network_anomaly",
    match(rule, "Privilege"), "privilege_escalation",
    match(rule, "File"), "unauthorized_file_access",
    true(), "other"
)
| stats count by threat_category, rule, container_name, user
| where count > 5
| sort -count

# ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ
index=cicd OR index=vulnerability
| eval metric=case(
    sourcetype="trivy" AND severity="CRITICAL", "critical_vulns",
    sourcetype="github_actions" AND status="failure", "pipeline_failures",
    sourcetype="falco" AND priority="CRITICAL", "runtime_threats",
    true(), "other"
)
| timechart span=1d count by metric
| fields _time, critical_vulns, pipeline_failures, runtime_threats

# MTTR (Mean Time To Resolve) ê³„ì‚°
index=vulnerability
| transaction vulnerability_id startswith=(status="discovered") endswith=(status="resolved")
| eval mttr_hours=round((duration/3600), 2)
| stats avg(mttr_hours) as avg_mttr, median(mttr_hours) as median_mttr, max(mttr_hours) as max_mttr by severity
| table severity, avg_mttr, median_mttr, max_mttr
-->

<!-- Azure Sentinel KQL Queries for DevSecOps -->
<!--
// CI/CD íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ì´ë²¤íŠ¸
let PipelineEvents = AzureActivity
| where CategoryValue == "Administrative"
| where OperationNameValue contains "pipeline" or OperationNameValue contains "deployment"
| extend PipelineStage = case(
    ActivityStatusValue contains "secret", "SecretScan",
    ActivityStatusValue contains "SAST", "StaticAnalysis",
    ActivityStatusValue contains "image", "ImageScan",
    ActivityStatusValue contains "deploy", "Deployment",
    "Other"
);
PipelineEvents
| where PipelineStage in ("SecretScan", "StaticAnalysis", "ImageScan")
| summarize FailureCount=countif(ActivityStatusValue == "Failed") by bin(TimeGenerated, 1h), PipelineStage, Caller
| where FailureCount > 3
| project TimeGenerated, Caller, PipelineStage, FailureCount

// ë³´ì•ˆ ê²Œì´íŠ¸ ìš°íšŒ ì‹œë„
let SecurityBypass = AzureDevOpsAuditing
| where OperationName has_any ("SkipSecurityCheck", "OverridePolicy", "DisableGate")
| extend Severity = "Critical"
| project TimeGenerated, ActorUPN, OperationName, Severity, Details;
SecurityBypass
| summarize BypassAttempts=count() by ActorUPN, OperationName
| where BypassAttempts > 0
| order by BypassAttempts desc

// Kubernetes ë³´ì•ˆ ì •ì±… ìœ„ë°˜
let K8sViolations = KubePodInventory
| where PodStatus == "Running"
| extend IsPrivileged = parse_json(PodSecurityContext).privileged == true
| extend HostNetwork = parse_json(PodSpec).hostNetwork == true
| where IsPrivileged == true or HostNetwork == true
| project TimeGenerated, Namespace, Name, IsPrivileged, HostNetwork, ContainerImage;
K8sViolations
| summarize ViolationCount=count() by Namespace, ContainerImage
| order by ViolationCount desc

// ì·¨ì•½ì  íŠ¸ë Œë“œ ë¶„ì„
SecurityAlert
| where AlertName contains "Vulnerability" or AlertName contains "CVE"
| extend Severity = case(
    AlertSeverity == "High", 3,
    AlertSeverity == "Medium", 2,
    AlertSeverity == "Low", 1,
    0
)
| summarize TotalAlerts=count(), HighSeverity=countif(Severity==3) by bin(TimeGenerated, 1d)
| project TimeGenerated, TotalAlerts, HighSeverity
| render timechart

// MTTR ê³„ì‚° (í•´ê²° ì‹œê°„)
let VulnLifecycle = SecurityAlert
| where TimeGenerated > ago(90d)
| where Status in ("Resolved", "Dismissed")
| extend ResolutionTime = datetime_diff('hour', TimeGenerated, StartTime)
| where ResolutionTime > 0;
VulnLifecycle
| summarize AvgMTTR=avg(ResolutionTime), MedianMTTR=percentile(ResolutionTime, 50), MaxMTTR=max(ResolutionTime) by AlertSeverity
| project AlertSeverity, AvgMTTR, MedianMTTR, MaxMTTR
| order by AlertSeverity desc
-->

## 6. ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤ ë° KPI

### 6.1 í•µì‹¬ ë³´ì•ˆ ì§€í‘œ

| ì§€í‘œ | ì •ì˜ | ëª©í‘œì¹˜ | ì¸¡ì • ë°©ë²• |
|------|------|--------|----------|
| **MTTD** | Mean Time To Detect | < 24ì‹œê°„ | (ì·¨ì•½ì  ë°œê²¬ ì‹œê°„ - ë„ì… ì‹œê°„)ì˜ í‰ê·  |
| **MTTR** | Mean Time To Resolve | < 7ì¼ | (íŒ¨ì¹˜ ë°°í¬ ì‹œê°„ - ì·¨ì•½ì  ë°œê²¬ ì‹œê°„)ì˜ í‰ê·  |
| **Critical ì·¨ì•½ì ** | CVSS 9.0+ | 0ê±´ | í”„ë¡œë•ì…˜ í™˜ê²½ ìŠ¤ìº” ê²°ê³¼ |
| **ë³´ì•ˆ ê²Œì´íŠ¸ í†µê³¼ìœ¨** | ì²« ì‹œë„ í†µê³¼ | > 80% | (í†µê³¼ ë¹Œë“œ / ì „ì²´ ë¹Œë“œ) Ã— 100 |
| **False Positive Rate** | ì˜¤íƒë¥  | < 10% | (ì˜¤íƒ / ì „ì²´ ì•Œë¦¼) Ã— 100 |
| **Code Coverage** | ì½”ë“œ ì»¤ë²„ë¦¬ì§€ | > 80% | SAST ë„êµ¬ ë¦¬í¬íŠ¸ |
| **Dependency Freshness** | ì˜ì¡´ì„± ì‹ ì„ ë„ | < 90ì¼ | íŒ¨í‚¤ì§€ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ |
| **Secret Detection** | Secret ëˆ„ì¶œ ì°¨ë‹¨ | 100% | Pre-commit hook ì‹¤í–‰ |

### 6.2 ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘ ìë™í™”

```python
# metrics_collector.py
import boto3
import json
from datetime import datetime, timedelta
from collections import defaultdict

class DevSecOpsMetrics:
    def __init__(self):
        self.cloudwatch = boto3.client('cloudwatch')
        self.securityhub = boto3.client('securityhub')
        self.codepipeline = boto3.client('codepipeline')

    def calculate_mttd(self, days=30):
        """
        Mean Time To Detect ê³„ì‚°
        """
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)

        # Security Hubì—ì„œ ë°œê²¬ëœ ì·¨ì•½ì  ì¡°íšŒ
        findings = self._get_findings(start_time, end_time)

        detection_times = []
        for finding in findings:
            created = datetime.fromisoformat(finding['CreatedAt'].replace('Z', '+00:00'))
            first_observed = datetime.fromisoformat(finding['FirstObservedAt'].replace('Z', '+00:00'))

            # ë„ì… ì‹œê°„ì€ ì¶”ì • (ì½”ë“œ ì»¤ë°‹ ì‹œê°„)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Git historyì™€ ì—°ê³„
            detection_time = (created - first_observed).total_seconds() / 3600  # hours
            detection_times.append(detection_time)

        mttd = sum(detection_times) / len(detection_times) if detection_times else 0

        # CloudWatchì— ë©”íŠ¸ë¦­ ì „ì†¡
        self.cloudwatch.put_metric_data(
            Namespace='DevSecOps',
            MetricData=[{
                'MetricName': 'MTTD',
                'Value': mttd,
                'Unit': 'Hours',
                'Timestamp': datetime.utcnow()
            }]
        )

        return mttd

    def calculate_mttr(self, days=30):
        """
        Mean Time To Resolve ê³„ì‚°
        """
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)

        findings = self._get_findings(start_time, end_time, workflow_status='RESOLVED')

        resolution_times = []
        for finding in findings:
            created = datetime.fromisoformat(finding['CreatedAt'].replace('Z', '+00:00'))
            updated = datetime.fromisoformat(finding['UpdatedAt'].replace('Z', '+00:00'))

            resolution_time = (updated - created).total_seconds() / 3600  # hours
            resolution_times.append(resolution_time)

        mttr = sum(resolution_times) / len(resolution_times) if resolution_times else 0

        self.cloudwatch.put_metric_data(
            Namespace='DevSecOps',
            MetricData=[{
                'MetricName': 'MTTR',
                'Value': mttr,
                'Unit': 'Hours',
                'Timestamp': datetime.utcnow()
            }]
        )

        return mttr

    def calculate_security_gate_pass_rate(self, days=30):
        """
        ë³´ì•ˆ ê²Œì´íŠ¸ í†µê³¼ìœ¨ ê³„ì‚°
        """
        # CodePipeline ì‹¤í–‰ ê²°ê³¼ ì¡°íšŒ
        paginator = self.codepipeline.get_paginator('list_pipeline_executions')

        total_builds = 0
        passed_builds = 0

        for pipeline in self._list_pipelines():
            for page in paginator.paginate(pipelineName=pipeline):
                for execution in page['pipelineExecutionSummaries']:
                    exec_time = execution['startTime']
                    if (datetime.now(exec_time.tzinfo) - exec_time).days <= days:
                        total_builds += 1
                        if execution['status'] == 'Succeeded':
                            passed_builds += 1

        pass_rate = (passed_builds / total_builds * 100) if total_builds > 0 else 0

        self.cloudwatch.put_metric_data(
            Namespace='DevSecOps',
            MetricData=[{
                'MetricName': 'SecurityGatePassRate',
                'Value': pass_rate,
                'Unit': 'Percent',
                'Timestamp': datetime.utcnow()
            }]
        )

        return pass_rate

    def get_vulnerability_by_severity(self):
        """
        ì‹¬ê°ë„ë³„ ì·¨ì•½ì  ì§‘ê³„
        """
        findings = self._get_findings(
            datetime.utcnow() - timedelta(days=1),
            datetime.utcnow(),
            record_state='ACTIVE'
        )

        severity_count = defaultdict(int)
        for finding in findings:
            severity = finding['Severity']['Label']
            severity_count[severity] += 1

        # CloudWatchì— ê° ì‹¬ê°ë„ë³„ ë©”íŠ¸ë¦­ ì „ì†¡
        for severity, count in severity_count.items():
            self.cloudwatch.put_metric_data(
                Namespace='DevSecOps',
                MetricData=[{
                    'MetricName': f'Vulnerabilities_{severity}',
                    'Value': count,
                    'Unit': 'Count',
                    'Timestamp': datetime.utcnow()
                }]
            )

        return dict(severity_count)

    def _get_findings(self, start_time, end_time, workflow_status=None, record_state='ACTIVE'):
        """
        Security Hubì—ì„œ ì·¨ì•½ì  ì¡°íšŒ
        """
        filters = {
            'RecordState': [{'Value': record_state, 'Comparison': 'EQUALS'}],
            'CreatedAt': [{
                'Start': start_time.isoformat() + 'Z',
                'End': end_time.isoformat() + 'Z'
            }]
        }

        if workflow_status:
            filters['WorkflowStatus'] = [{'Value': workflow_status, 'Comparison': 'EQUALS'}]

        paginator = self.securityhub.get_paginator('get_findings')
        findings = []

        for page in paginator.paginate(Filters=filters):
            findings.extend(page['Findings'])

        return findings

    def _list_pipelines(self):
        """
        ëª¨ë“  CodePipeline ì¡°íšŒ
        """
        paginator = self.codepipeline.get_paginator('list_pipelines')
        pipelines = []

        for page in paginator.paginate():
            pipelines.extend([p['name'] for p in page['pipelines']])

        return pipelines

    def generate_daily_report(self):
        """
        ì¼ì¼ ë³´ì•ˆ ë¦¬í¬íŠ¸ ìƒì„±
        """
        report = {
            'date': datetime.utcnow().strftime('%Y-%m-%d'),
            'mttd_hours': self.calculate_mttd(days=7),
            'mttr_hours': self.calculate_mttr(days=30),
            'security_gate_pass_rate': self.calculate_security_gate_pass_rate(days=7),
            'vulnerabilities': self.get_vulnerability_by_severity()
        }

        # S3ì— ë¦¬í¬íŠ¸ ì €ì¥
        s3 = boto3.client('s3')
        s3.put_object(
            Bucket='security-metrics-reports',
            Key=f"daily/{report['date']}.json",
            Body=json.dumps(report, indent=2),
            ContentType='application/json'
        )

        return report

# Lambda í•¸ë“¤ëŸ¬ë¡œ ì¼ì¼ ì‹¤í–‰
def lambda_handler(event, context):
    metrics = DevSecOpsMetrics()
    report = metrics.generate_daily_report()

    print(json.dumps(report, indent=2))

    return {
        'statusCode': 200,
        'body': json.dumps(report)
    }
```

### 6.3 DevSecOps ROI ê³„ì‚°

```python
# roi_calculator.py
class DevSecOpsROI:
    def __init__(self):
        self.avg_breach_cost = 4_240_000  # USD (IBM Cost of Data Breach 2024)
        self.avg_dev_salary = 120_000     # USD per year
        self.avg_security_salary = 130_000

    def calculate_roi(self, org_data):
        """
        DevSecOps íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ê³„ì‚°

        org_data = {
            'developers': 50,
            'security_team': 5,
            'annual_releases': 120,
            'pre_devsecops': {
                'vulnerabilities_found_in_prod': 25,
                'avg_fix_time_hours': 40,
                'security_incidents': 3
            },
            'post_devsecops': {
                'vulnerabilities_found_in_prod': 2,
                'avg_fix_time_hours': 8,
                'security_incidents': 0,
                'tool_costs': 50_000  # annual
            }
        }
        """
        # === Before DevSecOps ë¹„ìš© ===
        pre = org_data['pre_devsecops']

        # 1. í”„ë¡œë•ì…˜ ì·¨ì•½ì  ìˆ˜ì • ë¹„ìš©
        pre_fix_cost = (
            pre['vulnerabilities_found_in_prod'] *
            pre['avg_fix_time_hours'] *
            (self.avg_dev_salary / 2080)  # hourly rate
        )

        # 2. ë³´ì•ˆ ì‚¬ê³  ë¹„ìš©
        pre_incident_cost = pre['security_incidents'] * self.avg_breach_cost

        # 3. ìˆ˜ë™ ë³´ì•ˆ ê²€í†  ë¹„ìš©
        pre_manual_review_cost = (
            org_data['annual_releases'] *
            8 *  # 8 hours per review
            (self.avg_security_salary / 2080)
        )

        pre_total_cost = pre_fix_cost + pre_incident_cost + pre_manual_review_cost

        # === After DevSecOps ë¹„ìš© ===
        post = org_data['post_devsecops']

        # 1. í”„ë¡œë•ì…˜ ì·¨ì•½ì  ìˆ˜ì • ë¹„ìš© (ê°ì†Œ)
        post_fix_cost = (
            post['vulnerabilities_found_in_prod'] *
            post['avg_fix_time_hours'] *
            (self.avg_dev_salary / 2080)
        )

        # 2. ë³´ì•ˆ ì‚¬ê³  ë¹„ìš© (ê°ì†Œ)
        post_incident_cost = post['security_incidents'] * self.avg_breach_cost

        # 3. ìë™í™”ëœ ë³´ì•ˆ ê²€í†  (ìˆ˜ë™ ê²€í†  ì‹œê°„ 80% ê°ì†Œ)
        post_manual_review_cost = pre_manual_review_cost * 0.2

        # 4. ë„êµ¬ ë¼ì´ì„ ìŠ¤ ë¹„ìš©
        tool_cost = post['tool_costs']

        post_total_cost = post_fix_cost + post_incident_cost + post_manual_review_cost + tool_cost

        # === ROI ê³„ì‚° ===
        cost_savings = pre_total_cost - post_total_cost
        roi_percent = (cost_savings / post_total_cost) * 100
        payback_period_months = (tool_cost / (cost_savings / 12)) if cost_savings > 0 else float('inf')

        return {
            'pre_devsecops_annual_cost': pre_total_cost,
            'post_devsecops_annual_cost': post_total_cost,
            'annual_cost_savings': cost_savings,
            'roi_percent': roi_percent,
            'payback_period_months': payback_period_months,
            'breakdown': {
                'pre': {
                    'fix_cost': pre_fix_cost,
                    'incident_cost': pre_incident_cost,
                    'manual_review_cost': pre_manual_review_cost
                },
                'post': {
                    'fix_cost': post_fix_cost,
                    'incident_cost': post_incident_cost,
                    'manual_review_cost': post_manual_review_cost,
                    'tool_cost': tool_cost
                }
            }
        }

# Usage
if __name__ == '__main__':
    calculator = DevSecOpsROI()

    org_data = {
        'developers': 50,
        'security_team': 5,
        'annual_releases': 120,
        'pre_devsecops': {
            'vulnerabilities_found_in_prod': 25,
            'avg_fix_time_hours': 40,
            'security_incidents': 3
        },
        'post_devsecops': {
            'vulnerabilities_found_in_prod': 2,
            'avg_fix_time_hours': 8,
            'security_incidents': 0,
            'tool_costs': 50_000
        }
    }

    result = calculator.calculate_roi(org_data)

    print("=== DevSecOps ROI ë¶„ì„ ===")
    print(f"ë„ì… ì „ ì—°ê°„ ë¹„ìš©: ${result['pre_devsecops_annual_cost']:,.0f}")
    print(f"ë„ì… í›„ ì—°ê°„ ë¹„ìš©: ${result['post_devsecops_annual_cost']:,.0f}")
    print(f"ì—°ê°„ ì ˆê°ì•¡: ${result['annual_cost_savings']:,.0f}")
    print(f"ROI: {result['roi_percent']:.1f}%")
    print(f"íˆ¬ì íšŒìˆ˜ ê¸°ê°„: {result['payback_period_months']:.1f}ê°œì›”")
```

## 7. í•œêµ­ ê¸°ì—… ì ìš© ê°€ì´ë“œ (ISMS-P ê´€ì )

### 7.1 ISMS-P ì¸ì¦ ìš”êµ¬ì‚¬í•­ ë§¤í•‘

| ISMS-P í†µì œ í•­ëª© | DevSecOps êµ¬í˜„ |
|-----------------|---------------|
| **2.1.1 ì •ì±… ìˆ˜ë¦½** | ë³´ì•ˆ ì •ì±…ì„ OPA/Kyverno ì •ì±… ì½”ë“œë¡œ êµ¬í˜„ |
| **2.2.1 ìœ„í—˜ ê´€ë¦¬** | ìœ„í˜‘ ëª¨ë¸ë§ (STRIDE), ì·¨ì•½ì  ìŠ¤ìº” (SAST/DAST) |
| **2.3.3 ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ë¶„ì„** | ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ì„ User Storyì— í¬í•¨ |
| **2.4.1 ë³´ì•ˆ ê²€í† ** | ìë™í™”ëœ ë³´ì•ˆ ê²Œì´íŠ¸ (CI/CD íŒŒì´í”„ë¼ì¸) |
| **2.5.1 ì ‘ê·¼ í†µì œ** | RBAC, IAM ì •ì±… as Code |
| **2.6.1 ì•”í˜¸í™”** | Secret ê´€ë¦¬ (Vault, AWS Secrets Manager) |
| **2.7.1 ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬** | OAuth 2.0, JWT, OIDC êµ¬í˜„ |
| **2.8.1 ë¡œê·¸ ê´€ë¦¬** | ì¤‘ì•™í™”ëœ ë¡œê¹… (ELK, CloudWatch) |
| **2.9.1 ì·¨ì•½ì  ê´€ë¦¬** | ì§€ì†ì ì¸ ì·¨ì•½ì  ìŠ¤ìºë‹ + ìë™ íŒ¨ì¹˜ |
| **2.10.1 ì¹¨í•´ì‚¬ê³  ëŒ€ì‘** | ìë™í™”ëœ ì‚¬ê³  ëŒ€ì‘ (GuardDuty, Falco) |

### 7.2 ISMS-P ì¦ì  ìë™ ìˆ˜ì§‘

```python
# isms_p_evidence_collector.py
import boto3
import json
from datetime import datetime, timedelta

class ISMSPEvidenceCollector:
    """
    ISMS-P ì¸ì¦ ì‹¬ì‚¬ë¥¼ ìœ„í•œ ì¦ì  ìë™ ìˆ˜ì§‘
    """
    def __init__(self):
        self.s3 = boto3.client('s3')
        self.evidence_bucket = 'isms-p-evidence'

    def collect_2_4_1_security_review(self):
        """
        2.4.1 ë³´ì•ˆ ê²€í†  ì¦ì  ìˆ˜ì§‘
        - CI/CD íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ìŠ¤ìº” ê²°ê³¼
        """
        evidence = {
            'control': '2.4.1',
            'name': 'ë³´ì•ˆ ê²€í† ',
            'collection_date': datetime.utcnow().isoformat(),
            'evidence': []
        }

        # GitHub Actions ì‹¤í–‰ ê²°ê³¼
        # (ì‹¤ì œë¡œëŠ” GitHub API í˜¸ì¶œ)
        pipeline_runs = [
            {
                'run_id': '12345',
                'workflow': 'security-pipeline.yml',
                'status': 'success',
                'sast_passed': True,
                'sca_passed': True,
                'image_scan_passed': True,
                'dast_passed': True,
                'timestamp': '2025-06-13T10:00:00Z'
            }
        ]

        evidence['evidence'].append({
            'type': 'automated_security_scan',
            'description': 'CI/CD íŒŒì´í”„ë¼ì¸ ìë™ ë³´ì•ˆ ìŠ¤ìº”',
            'data': pipeline_runs
        })

        self._save_evidence(evidence)
        return evidence

    def collect_2_9_1_vulnerability_management(self):
        """
        2.9.1 ì·¨ì•½ì  ê´€ë¦¬ ì¦ì  ìˆ˜ì§‘
        """
        securityhub = boto3.client('securityhub')

        # ì§€ë‚œ 30ì¼ê°„ ë°œê²¬ëœ ì·¨ì•½ì 
        findings = securityhub.get_findings(
            Filters={
                'RecordState': [{'Value': 'ACTIVE', 'Comparison': 'EQUALS'}],
                'CreatedAt': [{
                    'Start': (datetime.utcnow() - timedelta(days=30)).isoformat() + 'Z',
                    'End': datetime.utcnow().isoformat() + 'Z'
                }]
            }
        )['Findings']

        evidence = {
            'control': '2.9.1',
            'name': 'ì·¨ì•½ì  ê´€ë¦¬',
            'collection_date': datetime.utcnow().isoformat(),
            'evidence': [{
                'type': 'vulnerability_scan_results',
                'total_findings': len(findings),
                'by_severity': {
                    'CRITICAL': len([f for f in findings if f['Severity']['Label'] == 'CRITICAL']),
                    'HIGH': len([f for f in findings if f['Severity']['Label'] == 'HIGH']),
                    'MEDIUM': len([f for f in findings if f['Severity']['Label'] == 'MEDIUM']),
                    'LOW': len([f for f in findings if f['Severity']['Label'] == 'LOW'])
                },
                'mttr_hours': self._calculate_mttr(findings)
            }]
        }

        self._save_evidence(evidence)
        return evidence

    def collect_2_8_1_log_management(self):
        """
        2.8.1 ë¡œê·¸ ê´€ë¦¬ ì¦ì  ìˆ˜ì§‘
        """
        logs = boto3.client('logs')

        # CloudWatch ë¡œê·¸ ê·¸ë£¹ ëª©ë¡
        log_groups = logs.describe_log_groups()['logGroups']

        evidence = {
            'control': '2.8.1',
            'name': 'ë¡œê·¸ ê´€ë¦¬',
            'collection_date': datetime.utcnow().isoformat(),
            'evidence': [{
                'type': 'centralized_logging',
                'log_groups_count': len(log_groups),
                'retention_policy': '90 days',
                'log_groups': [
                    {
                        'name': lg['logGroupName'],
                        'retention_days': lg.get('retentionInDays', 'Never expire'),
                        'stored_bytes': lg.get('storedBytes', 0)
                    }
                    for lg in log_groups
                ]
            }]
        }

        self._save_evidence(evidence)
        return evidence

    def generate_monthly_report(self):
        """
        ì›”ê°„ ISMS-P ì¤€ìˆ˜ ë¦¬í¬íŠ¸ ìƒì„±
        """
        report = {
            'report_period': datetime.utcnow().strftime('%Y-%m'),
            'controls': [
                self.collect_2_4_1_security_review(),
                self.collect_2_9_1_vulnerability_management(),
                self.collect_2_8_1_log_management()
            ]
        }

        # PDF ë¦¬í¬íŠ¸ ìƒì„± (ì˜ˆì‹œ)
        self._generate_pdf_report(report)

        return report

    def _calculate_mttr(self, findings):
        """
        MTTR ê³„ì‚° í—¬í¼
        """
        resolved_findings = [
            f for f in findings
            if f.get('Workflow', {}).get('Status') == 'RESOLVED'
        ]

        if not resolved_findings:
            return 0

        total_resolution_time = 0
        for finding in resolved_findings:
            created = datetime.fromisoformat(finding['CreatedAt'].replace('Z', ''))
            updated = datetime.fromisoformat(finding['UpdatedAt'].replace('Z', ''))
            resolution_time = (updated - created).total_seconds() / 3600  # hours
            total_resolution_time += resolution_time

        return total_resolution_time / len(resolved_findings)

    def _save_evidence(self, evidence):
        """
        ì¦ì ì„ S3ì— ì €ì¥
        """
        key = f"evidence/{evidence['control']}/{datetime.utcnow().strftime('%Y-%m-%d')}.json"

        self.s3.put_object(
            Bucket=self.evidence_bucket,
            Key=key,
            Body=json.dumps(evidence, ensure_ascii=False, indent=2),
            ContentType='application/json'
        )

    def _generate_pdf_report(self, report):
        """
        PDF ë¦¬í¬íŠ¸ ìƒì„± (placeholder)
        """
        # ì‹¤ì œë¡œëŠ” reportlab ë“± ì‚¬ìš©
        pass
```

## 8. ê²½ì˜ì§„ ë³´ê³  í˜•ì‹

### 8.1 Executive Summary Template

```markdown
# DevSecOps íˆ¬ì íš¨ê³¼ ë¶„ì„ ë³´ê³ ì„œ
**ë³´ê³  ê¸°ê°„**: 2025ë…„ 1ë¶„ê¸°
**ì‘ì„±ì**: ë³´ì•ˆíŒ€
**ì‘ì„±ì¼**: 2025-06-13

## 1. í•µì‹¬ ìš”ì•½ (Executive Summary)

DevSecOps ë„ì… 6ê°œì›”ì°¨ ì„±ê³¼:
- **ë³´ì•ˆ ì‚¬ê³  90% ê°ì†Œ** (3ê±´ â†’ 0ê±´)
- **ì·¨ì•½ì  í•´ê²° ì‹œê°„ 80% ë‹¨ì¶•** (40ì‹œê°„ â†’ 8ì‹œê°„)
- **í”„ë¡œë•ì…˜ ë²„ê·¸ 75% ê°ì†Œ** (25ê±´ â†’ 2ê±´)
- **ì—°ê°„ ë¹„ìš© ì ˆê° $1.2M** (ROI 240%)

## 2. íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ (ROI)

| í•­ëª© | ë„ì… ì „ | ë„ì… í›„ | ê°œì„ ìœ¨ |
|------|---------|---------|--------|
| ì—°ê°„ ë³´ì•ˆ ì‚¬ê³  ë¹„ìš© | $12.7M | $0 | **100%** |
| í‰ê·  ì·¨ì•½ì  í•´ê²° ì‹œê°„ | 40ì‹œê°„ | 8ì‹œê°„ | **80%** |
| ë¦´ë¦¬ìŠ¤ ì£¼ê¸° | 4ì£¼ | 1ì£¼ | **75%** |
| ê°œë°œì ìƒì‚°ì„± | - | +35% | **35%** |
| ë³´ì•ˆ ë„êµ¬ ë¹„ìš© | $0 | $50K | - |
| **ìˆœ ì ˆê°ì•¡** | - | **$1.2M/year** | - |

**íˆ¬ì íšŒìˆ˜ ê¸°ê°„**: 0.5ê°œì›”

## 3. ìœ„í—˜ ê°ì†Œ

### DevSecOps ë„ì… ì „
```
[Critical: 25ê±´] [High: 40ê±´] [Medium: 80ê±´]
â†’ í”„ë¡œë•ì…˜ ë°°í¬ ì „ ë°œê²¬ ë¹„ìœ¨: 20%
```

### DevSecOps ë„ì… í›„
```
[Critical: 0ê±´] [High: 2ê±´] [Medium: 15ê±´]
â†’ í”„ë¡œë•ì…˜ ë°°í¬ ì „ ë°œê²¬ ë¹„ìœ¨: 95%
```

**ê²°ê³¼**: Critical ìœ„í—˜ 100% ì œê±°, í”„ë¡œë•ì…˜ ì‚¬ê³  ìœ„í—˜ 90% ê°ì†Œ

## 4. ê·œì • ì¤€ìˆ˜ (Compliance)

- âœ… ISMS-P ì¸ì¦ ìœ ì§€
- âœ… ISO 27001 ì¤€ìˆ˜
- âœ… SOC 2 Type II ì¤€ë¹„ ì¤‘
- âœ… GDPR ë°ì´í„° ë³´í˜¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±

## 5. í–¥í›„ ê³„íš

**Q3 2025 ëª©í‘œ**:
1. AI ê¸°ë°˜ ì·¨ì•½ì  ìš°ì„ ìˆœìœ„í™” ë„ì…
2. ì œë¡œ íŠ¸ëŸ¬ìŠ¤íŠ¸ ì•„í‚¤í…ì²˜ í™•ì¥
3. ê³µê¸‰ë§ ë³´ì•ˆ (SBOM, ì„œëª…) ê°•í™”

**ì˜ˆìƒ ì¶”ê°€ íš¨ê³¼**:
- ì·¨ì•½ì  íƒì§€ ì •í™•ë„ +20%
- False Positive -50%
- ë³´ì•ˆ íŒ€ ìš´ì˜ ë¹„ìš© -30%
```

### 8.2 2025 DevSecOps ë„êµ¬ ì—…ë°ì´íŠ¸

| ë„êµ¬ | 2025ë…„ ì£¼ìš” ì—…ë°ì´íŠ¸ | í™œìš© ë¶„ì•¼ |
|------|---------------------|----------|
| **GitHub Copilot** | ë³´ì•ˆ ì·¨ì•½ì  ìë™ ìˆ˜ì • ì œì•ˆ | Code |
| **Amazon Q Developer** | AWS ë¦¬ì†ŒìŠ¤ ë³´ì•ˆ ì„¤ì • ìë™í™” | Cloud |
| **AWS Security Agent** | ì „ ê³¼ì • ìë™í™”ëœ ë³´ì•ˆ ë¦¬ë·° | All |
| **Trivy** | SBOM ìƒì„± ë° VEX ì§€ì› ê°•í™” | Build |
| **Snyk** | AI ê¸°ë°˜ ì·¨ì•½ì  ìš°ì„ ìˆœìœ„í™” | SCA |
| **Falco** | eBPF ê¸°ë°˜ ì„±ëŠ¥ ê°œì„  | Runtime |
| **OPA/Gatekeeper** | Kubernetes 1.30+ ë„¤ì´í‹°ë¸Œ ì§€ì› | Policy |
| **SonarQube 10.4** | AI Code Fix, Clean Code ê°œë… ë„ì… | SAST |
| **Semgrep Pro** | Dataflow ë¶„ì„, Cross-file taint tracking | SAST |
| **OWASP ZAP 2.15** | GraphQL API ìŠ¤ìº”, Passive Scan Rule ê°œì„  | DAST |
| **Checkov 3.2** | Terraform 1.7+ ì§€ì›, Custom Policy Framework | IaC |
| **Cosign 2.x** | Keyless signing, OIDC integration | Supply Chain |

### 8.3 AI ê¸°ë°˜ ë³´ì•ˆ ìë™í™” (2025)

2025ë…„ í˜„ì¬, AI/MLì„ í™œìš©í•œ DevSecOps ìë™í™”ê°€ ê¸‰ê²©íˆ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.

#### 8.3.1 GitHub Copilot for Security

```python
# Before: ì·¨ì•½í•œ ì½”ë“œ
def login(username, password):
    query = f"SELECT * FROM users WHERE username='{username}' AND password='{password}'"
    return db.execute(query)

# GitHub Copilotì´ ì œì•ˆí•˜ëŠ” ë³´ì•ˆ ê°œì„ 
# âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€
# ğŸ’¡ ì œì•ˆ: Parameterized query ì‚¬ìš©
def login(username, password):
    query = "SELECT * FROM users WHERE username=? AND password=?"
    return db.execute(query, (username, password))

# ì¶”ê°€ ì œì•ˆ: Password hashing
from werkzeug.security import check_password_hash

def login(username, password):
    query = "SELECT * FROM users WHERE username=?"
    user = db.execute(query, (username,)).fetchone()
    if user and check_password_hash(user['password_hash'], password):
        return user
    return None
```

#### 8.3.2 Amazon Q Developer - ë³´ì•ˆ ì„¤ì • ìë™í™”

```bash
# í”„ë¡¬í”„íŠ¸: "Create a secure S3 bucket with encryption and versioning"

$ q generate s3-bucket --secure

# Amazon Qê°€ ìƒì„±í•˜ëŠ” Terraform ì½”ë“œ:
resource "aws_s3_bucket" "secure_bucket" {
  bucket = "my-secure-bucket"

  # ë²„ì „ ê´€ë¦¬ í™œì„±í™”
  versioning {
    enabled = true
  }

  # ì„œë²„ ì¸¡ ì•”í˜¸í™”
  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "aws:kms"
        kms_master_key_id = aws_kms_key.s3_key.arn
      }
      bucket_key_enabled = true
    }
  }

  # Public access ì°¨ë‹¨
  public_access_block_config {
    block_public_acls       = true
    block_public_policy     = true
    ignore_public_acls      = true
    restrict_public_buckets = true
  }

  # ë¡œê¹… í™œì„±í™”
  logging {
    target_bucket = aws_s3_bucket.log_bucket.id
    target_prefix = "log/"
  }

  # Object Lock (ê·œì • ì¤€ìˆ˜ìš©)
  object_lock_configuration {
    object_lock_enabled = "Enabled"
  }

  tags = {
    Environment = "production"
    Security    = "high"
    Compliance  = "ISMS-P"
  }
}

# KMS í‚¤ ìƒì„±
resource "aws_kms_key" "s3_key" {
  description             = "KMS key for S3 encryption"
  deletion_window_in_days = 30
  enable_key_rotation     = true
}
```

#### 8.3.3 AI ê¸°ë°˜ ì·¨ì•½ì  ìš°ì„ ìˆœìœ„í™”

```python
# ml_prioritization.py
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import joblib

class VulnerabilityPrioritizer:
    """
    AI/MLì„ í™œìš©í•œ ì·¨ì•½ì  ìš°ì„ ìˆœìœ„ ê²°ì •
    """
    def __init__(self):
        self.model = self._load_or_train_model()

    def prioritize(self, vulnerability):
        """
        ì·¨ì•½ì ì˜ ì‹¤ì œ ìœ„í—˜ë„ë¥¼ AIë¡œ ì˜ˆì¸¡

        Features:
        - CVSS Score
        - Exploit availability
        - Asset criticality
        - Network exposure
        - Historical remediation time
        """
        features = self._extract_features(vulnerability)
        risk_score = self.model.predict_proba([features])[0][1]

        return {
            'vulnerability_id': vulnerability['id'],
            'cvss_score': vulnerability['cvss_score'],
            'ai_risk_score': risk_score,
            'priority': self._map_priority(risk_score),
            'sla_hours': self._calculate_sla(risk_score)
        }

    def _extract_features(self, vuln):
        """
        ì·¨ì•½ì ìœ¼ë¡œë¶€í„° íŠ¹ì§• ì¶”ì¶œ
        """
        return [
            vuln['cvss_score'],
            1 if vuln['exploit_available'] else 0,
            vuln['asset_criticality'],  # 1-5
            1 if vuln['internet_facing'] else 0,
            vuln['affected_users_count'],
            vuln['days_since_disclosure'],
            vuln['vendor_patch_available'],
            vuln['historical_mttr']
        ]

    def _map_priority(self, risk_score):
        """
        Risk scoreë¥¼ ìš°ì„ ìˆœìœ„ë¡œ ë§¤í•‘
        """
        if risk_score >= 0.9:
            return 'CRITICAL'
        elif risk_score >= 0.7:
            return 'HIGH'
        elif risk_score >= 0.4:
            return 'MEDIUM'
        else:
            return 'LOW'

    def _calculate_sla(self, risk_score):
        """
        ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ SLA ê³„ì‚°
        """
        if risk_score >= 0.9:
            return 24  # 24 hours
        elif risk_score >= 0.7:
            return 72  # 3 days
        elif risk_score >= 0.4:
            return 168  # 7 days
        else:
            return 720  # 30 days

    def _load_or_train_model(self):
        """
        ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ í›ˆë ¨
        """
        try:
            return joblib.load('vulnerability_prioritizer.pkl')
        except:
            # í›ˆë ¨ ë°ì´í„°ë¡œ ëª¨ë¸ ìƒì„± (ì˜ˆì‹œ)
            # ì‹¤ì œë¡œëŠ” ê³¼ê±° ì·¨ì•½ì  ë°ì´í„° ì‚¬ìš©
            model = RandomForestClassifier(n_estimators=100)
            # model.fit(X_train, y_train)
            return model

# Usage
prioritizer = VulnerabilityPrioritizer()

vulnerabilities = [
    {
        'id': 'CVE-2025-1234',
        'cvss_score': 9.8,
        'exploit_available': True,
        'asset_criticality': 5,
        'internet_facing': True,
        'affected_users_count': 10000,
        'days_since_disclosure': 5,
        'vendor_patch_available': 1,
        'historical_mttr': 48
    }
]

for vuln in vulnerabilities:
    priority = prioritizer.prioritize(vuln)
    print(f"Vulnerability: {priority['vulnerability_id']}")
    print(f"CVSS: {priority['cvss_score']}, AI Risk: {priority['ai_risk_score']:.2f}")
    print(f"Priority: {priority['priority']}, SLA: {priority['sla_hours']} hours")
```

### 8.4 ì‹¤ì „ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### 8.4.1 False Positive ëŒ€ì‘

**ë¬¸ì œ**: SAST ë„êµ¬ê°€ ë„ˆë¬´ ë§ì€ ì˜¤íƒì„ ë°œìƒì‹œí‚´

**í•´ê²°ì±…**:

```yaml
# .semgrep.yml - ì˜¤íƒ ì œì™¸ ì„¤ì •
rules:
  - id: sql-injection
    pattern: |
      db.execute($QUERY)
    paths:
      exclude:
        - "*/tests/*"
        - "*/migrations/*"
    # íŠ¹ì • íŒ¨í„´ ì œì™¸
    pattern-not-inside: |
      # ORM ì¿¼ë¦¬ëŠ” ì•ˆì „
      Model.objects.filter(...)

  - id: hardcoded-secret
    pattern: |
      password = "..."
    # ì˜ˆì™¸: í…ŒìŠ¤íŠ¸ fixture
    pattern-not-regex: |
      password = "(test|example|dummy|placeholder)"
```

#### 8.4.2 íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ìµœì í™”

**ë¬¸ì œ**: ë³´ì•ˆ ìŠ¤ìº”ìœ¼ë¡œ ì¸í•´ ë¹Œë“œ ì‹œê°„ì´ 2ë°° ì¦ê°€

**í•´ê²°ì±…**:

```yaml
# 1. ë³‘ë ¬í™”
jobs:
  security-scan:
    strategy:
      matrix:
        scanner: [sast, sca, secrets, iac]
    steps:
      - name: Run {% raw %}${{ matrix.scanner }}{% endraw %}
        run: ./scan-{% raw %}${{ matrix.scanner }}{% endraw %}.sh

# 2. ìºì‹±
- name: Cache Trivy DB
  uses: actions/cache@v4
  with:
    path: ~/.cache/trivy
    key: {% raw %}${{ runner.os }}{% endraw %}-trivy-{% raw %}${{ hashFiles('**/Dockerfile') }}{% endraw %}

# 3. ì¦ë¶„ ìŠ¤ìº” (ë³€ê²½ëœ íŒŒì¼ë§Œ)
- name: Get changed files
  id: changed-files
  uses: tj-actions/changed-files@v41

- name: Semgrep incremental
  run: |
    semgrep --config=auto {% raw %}${{ steps.changed-files.outputs.all_changed_files }}{% endraw %}

# 4. ìŠ¤ìº” ë¹ˆë„ ì¡°ì •
on:
  push:
    branches: [main]
  pull_request:
  schedule:
    - cron: '0 2 * * *'  # Full scan daily
```

**ê²°ê³¼**: ë¹Œë“œ ì‹œê°„ 50% ê°ì†Œ (20ë¶„ â†’ 10ë¶„)

#### 8.4.3 Secret ìŠ¤ìº” ì˜¤íƒ í•´ê²°

```yaml
# .gitleaks.toml
[[rules]]
id = "aws-access-key"
description = "AWS Access Key"
regex = '''AKIA[0-9A-Z]{16}'''

# ì˜¤íƒ ì œì™¸
[allowlist]
paths = [
  '''tests/fixtures/''',
  '''docs/examples/'''
]

# íŠ¹ì • ì»¤ë°‹ ì œì™¸
commits = [
  "a1b2c3d4e5f6"
]

# íŠ¹ì • íŒŒì¼ íŒ¨í„´ ì œì™¸
regexes = [
  '''example\.com''',
  '''YOUR_API_KEY_HERE''',
  '''<YOUR-.*>'''
]
```

### 8.5 DevSecOps ë¬¸í™” êµ¬ì¶•

#### 8.5.1 ë³´ì•ˆ ì±”í”¼ì–¸ í”„ë¡œê·¸ë¨

```markdown
# Security Champions Program

## ëª©í‘œ
ê°œë°œíŒ€ ë‚´ ë³´ì•ˆ ì˜ì‹ í–¥ìƒ ë° ììœ¨ì  ë³´ì•ˆ í™œë™ ì´‰ì§„

## ì—­í• 
- **ë³´ì•ˆ ì±”í”¼ì–¸** (ê° íŒ€ 1-2ëª…):
  - íŒ€ ë‚´ ë³´ì•ˆ ì§ˆë¬¸ 1ì°¨ ì‘ë‹µ
  - ë³´ì•ˆ êµìœ¡ ë‚´ìš© ì „íŒŒ
  - ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ë¦¬ë·° ì°¸ì—¬
  - ì›” 1íšŒ ë³´ì•ˆ íŒ€ ë¯¸íŒ… ì°¸ì„

## ì¸ì„¼í‹°ë¸Œ
- ë¶„ê¸°ë³„ ë³´ì•ˆ ì»¨í¼ëŸ°ìŠ¤ ì°¸ê°€ ì§€ì›
- ë³´ì•ˆ ìê²©ì¦ (CISSP, CEH) ë¹„ìš© ì§€ì›
- ì—°ë§ í‰ê°€ ì‹œ ê°€ì‚°ì 
- ë³´ì•ˆ ì±”í”¼ì–¸ ë°°ì§€/ì¹­í˜¸ ë¶€ì—¬

## KPI
- íŒ€ ë‚´ ë³´ì•ˆ ì´ìŠˆ ê°ì†Œìœ¨
- ë³´ì•ˆ êµìœ¡ ì°¸ì—¬ìœ¨
- ë³´ì•ˆ ê´€ë ¨ PR ë¦¬ë·° í’ˆì§ˆ
```

#### 8.5.2 Secure Coding êµìœ¡ ì²´ê³„

```markdown
# Secure Coding Training Roadmap

## Level 1: í•„ìˆ˜ êµìœ¡ (ì‹ ì… ê°œë°œì)
- OWASP Top 10 ì´í•´
- Secure SDLC ê°œìš”
- ì‚¬ë‚´ ë³´ì•ˆ ì •ì±… ë° ë„êµ¬ ì‚¬ìš©ë²•
- **ê¸°ê°„**: ì…ì‚¬ í›„ 1ê°œì›” ë‚´
- **í‰ê°€**: ì˜¨ë¼ì¸ í€´ì¦ˆ (80ì  ì´ìƒ í†µê³¼)

## Level 2: ì‹¬í™” êµìœ¡ (1ë…„ì°¨ ì´ìƒ)
- ì–¸ì–´ë³„ ë³´ì•ˆ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ (Java, Python, JavaScript)
- ì·¨ì•½ì  ì‹¤ìŠµ (DVWA, WebGoat)
- Threat Modeling ì›Œí¬ìƒµ
- **ê¸°ê°„**: ë¶„ê¸°ë³„ 1íšŒ
- **í‰ê°€**: CTF ì±Œë¦°ì§€ ì°¸ì—¬

## Level 3: ê³ ê¸‰ êµìœ¡ (3ë…„ì°¨ ì´ìƒ)
- ì¹¨íˆ¬ í…ŒìŠ¤íŠ¸ ê¸°ë²•
- ë³´ì•ˆ ì•„í‚¤í…ì²˜ ì„¤ê³„
- í´ë¼ìš°ë“œ ë³´ì•ˆ (AWS, Azure, GCP)
- **ê¸°ê°„**: ë°˜ê¸°ë³„ 1íšŒ
- **í‰ê°€**: ì‹¤ì œ í”„ë¡œì íŠ¸ ë³´ì•ˆ ë¦¬ë·°

## Level 4: ë³´ì•ˆ ì „ë¬¸ê°€ ê³¼ì •
- CISSP / CEH / OSCP ìê²©ì¦ ì¤€ë¹„
- ì™¸ë¶€ ì»¨í¼ëŸ°ìŠ¤ ë°œí‘œ
- ì˜¤í”ˆì†ŒìŠ¤ ë³´ì•ˆ í”„ë¡œì íŠ¸ ê¸°ì—¬
```

#### 8.5.3 ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ

```python
# security_dashboard.py
import streamlit as st
import plotly.express as px
import pandas as pd

def render_dashboard():
    st.title("DevSecOps ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ")

    # KPI ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("MTTD", "18 hours", "-6h")
    with col2:
        st.metric("MTTR", "5.2 days", "-1.8d")
    with col3:
        st.metric("Critical ì·¨ì•½ì ", "0", "0")
    with col4:
        st.metric("ë³´ì•ˆ ê²Œì´íŠ¸ í†µê³¼ìœ¨", "87%", "+7%")

    # ì·¨ì•½ì  íŠ¸ë Œë“œ
    st.subheader("ì·¨ì•½ì  ë°œê²¬ íŠ¸ë Œë“œ (ìµœê·¼ 30ì¼)")
    df_vulns = pd.DataFrame({
        'date': pd.date_range('2025-05-14', '2025-06-13'),
        'critical': [0] * 31,
        'high': [5, 4, 6, 3, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        'medium': [15, 14, 16, 13, 12, 11, 10, 9, 8, 9, 10, 9, 8, 7, 8, 9, 8, 7, 6, 5, 6, 5, 4, 3, 4, 5, 4, 3, 2, 2, 2]
    })
    fig = px.line(df_vulns, x='date', y=['critical', 'high', 'medium'],
                  labels={'value': 'Count', 'variable': 'Severity'})
    st.plotly_chart(fig, use_container_width=True)

    # íŒŒì´í”„ë¼ì¸ ì„±ê³µë¥ 
    st.subheader("CI/CD íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ê²Œì´íŠ¸ í†µê³¼ìœ¨")
    df_pipeline = pd.DataFrame({
        'stage': ['Secret Scan', 'SAST', 'SCA', 'Image Scan', 'DAST'],
        'pass_rate': [100, 92, 85, 88, 90]
    })
    fig2 = px.bar(df_pipeline, x='stage', y='pass_rate',
                  labels={'pass_rate': 'Pass Rate (%)'})
    st.plotly_chart(fig2, use_container_width=True)

    # Top ì·¨ì•½ì 
    st.subheader("Top ì·¨ì•½ì  (í•´ê²° í•„ìš”)")
    df_top_vulns = pd.DataFrame({
        'vulnerability': ['SQL Injection in auth.py', 'XSS in comment form', 'Outdated library: lodash 4.17.15', 'Missing rate limiting', 'Weak password policy'],
        'severity': ['HIGH', 'MEDIUM', 'HIGH', 'MEDIUM', 'LOW'],
        'age_days': [12, 8, 45, 5, 30],
        'status': ['In Progress', 'Open', 'Open', 'Assigned', 'Open']
    })
    st.dataframe(df_top_vulns, use_container_width=True)

if __name__ == '__main__':
    render_dashboard()
```

## 9. ì‹¤ìŠµ ê°€ì´ë“œ: ì²˜ìŒë¶€í„° ëê¹Œì§€

### 9.1 í™˜ê²½ ì¤€ë¹„

```bash
# 1. ë„êµ¬ ì„¤ì¹˜
# macOS
brew install trivy gitleaks semgrep checkov tfsec

# Ubuntu
wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
sudo apt update && sudo apt install trivy

pip install gitleaks semgrep checkov tfsec

# 2. GitHub Actions ì„¤ì •
mkdir -p .github/workflows
```

### 9.2 ë‹¨ê³„ë³„ êµ¬í˜„

#### Step 1: Secret Scanning

```yaml
# .github/workflows/01-secret-scan.yml
name: Step 1 - Secret Scan
on: [push]

jobs:
  secret-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}
```

**ê²€ì¦**:
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸
gitleaks detect --source . --verbose
```

#### Step 2: SAST

```yaml
# .github/workflows/02-sast.yml
name: Step 2 - SAST
on: [push]

jobs:
  sast:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: p/security-audit
```

**ê²€ì¦**:
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸
semgrep --config=auto --json .
```

#### Step 3: SCA

```yaml
# .github/workflows/03-sca.yml
name: Step 3 - SCA
on: [push]

jobs:
  sca:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Trivy FS Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          severity: 'HIGH,CRITICAL'
```

**ê²€ì¦**:
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸
trivy fs . --severity HIGH,CRITICAL
```

#### Step 4: Docker Image Scan

```yaml
# .github/workflows/04-image-scan.yml
name: Step 4 - Image Scan
on: [push]

jobs:
  build-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build Image
        run: docker build -t myapp:test .

      - name: Trivy Image Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          image-ref: 'myapp:test'
          severity: 'CRITICAL'
          exit-code: '1'
```

**ê²€ì¦**:
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸
docker build -t myapp:test .
trivy image myapp:test --severity CRITICAL
```

#### Step 5: IaC Scan

```yaml
# .github/workflows/05-iac-scan.yml
name: Step 5 - IaC Scan
on:
  push:
    paths:
      - 'terraform/**'
      - 'k8s/**'

jobs:
  iac-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Checkov
        uses: bridgecrewio/checkov-action@master
        with:
          directory: terraform/
          framework: terraform
```

**ê²€ì¦**:
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸
checkov -d terraform/ --framework terraform
```

### 9.3 í†µí•© íŒŒì´í”„ë¼ì¸

ì´ì œ ëª¨ë“  ë‹¨ê³„ë¥¼ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.

```yaml
# .github/workflows/complete-pipeline.yml
name: Complete Security Pipeline
on:
  push:
    branches: [main]
  pull_request:

jobs:
  security-checks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Stage 1: Secret Scan
      - name: Secret Scan
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}

      # Stage 2: SAST
      - name: SAST
        uses: returntocorp/semgrep-action@v1
        with:
          config: p/security-audit

      # Stage 3: SCA
      - name: SCA
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'

  build-and-scan:
    needs: security-checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build Docker Image
        run: docker build -t myapp:{% raw %}${{ github.sha }}{% endraw %} .

      - name: Scan Image
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          image-ref: myapp:{% raw %}${{ github.sha }}{% endraw %}
          exit-code: '1'

  deploy:
    needs: build-and-scan
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Deploy
        run: echo "Deploy to production"
```

### 9.4 ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## DevSecOps íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Pre-Deployment
- [ ] Secret ìŠ¤ìº” í†µê³¼ (0 secrets found)
- [ ] SAST ìŠ¤ìº” í†µê³¼ (0 critical, < 5 high)
- [ ] SCA ìŠ¤ìº” í†µê³¼ (0 critical dependencies)
- [ ] Container ìŠ¤ìº” í†µê³¼ (CVSS < 7.0)
- [ ] IaC ìŠ¤ìº” í†µê³¼ (0 critical misconfigurations)
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (unit + integration)

### Post-Deployment
- [ ] Health check ì •ìƒ (HTTP 200)
- [ ] Monitoring ì•Œë¦¼ ì—†ìŒ
- [ ] Falco ëŸ°íƒ€ì„ ì•Œë¦¼ ì—†ìŒ
- [ ] CloudWatch ë¡œê·¸ ì •ìƒ
- [ ] ì‚¬ìš©ì ì˜í–¥ ì—†ìŒ (error rate < 0.1%)

### Rollback ì¤€ë¹„
- [ ] ì´ì „ ë²„ì „ ì´ë¯¸ì§€ ë³´ê´€ë¨
- [ ] Rollback ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ë¨
- [ ] Rollback ì‹œê°„ < 5ë¶„ ëª©í‘œ
```

## 10. ê²°ë¡  ë° í–¥í›„ ì „ë§

### 10.1 í•µì‹¬ ìš”ì•½

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ë‹¤ë£¬ DevSecOps í†µí•©ì˜ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤:

1. **í”„ë ˆì„ì›Œí¬**: OWASP DSOMM, Shift-Left Security ì „ëµ
2. **ë„êµ¬ ì²´ì¸**: SAST/DAST/SCA/ì»¨í…Œì´ë„ˆ ë³´ì•ˆ/IaC ìŠ¤ìº”
3. **ìë™í™”**: CI/CD íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ê²Œì´íŠ¸ ì„¤ê³„
4. **í´ë¼ìš°ë“œ í†µí•©**: AWS Security Hub, GuardDuty ìë™ ëŒ€ì‘
5. **ë©”íŠ¸ë¦­ìŠ¤**: MTTD/MTTR ì¸¡ì •, ROI ê³„ì‚°
6. **ê·œì • ì¤€ìˆ˜**: ISMS-P ì¦ì  ìë™ ìˆ˜ì§‘
7. **ë¬¸í™”**: ë³´ì•ˆ ì±”í”¼ì–¸ í”„ë¡œê·¸ë¨, êµìœ¡ ì²´ê³„

### 10.2 DevSecOps ì„±ê³µ ìš”ì†Œ

**ê¸°ìˆ ì  ìš”ì†Œ:**
- âœ… ìë™í™”ëœ ë³´ì•ˆ ìŠ¤ìº” (SAST/DAST/SCA)
- âœ… ë³´ì•ˆ ê²Œì´íŠ¸ì™€ ì„ê³„ê°’ ì„¤ì •
- âœ… ì¤‘ì•™í™”ëœ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- âœ… ìë™í™”ëœ ì‚¬ê³  ëŒ€ì‘

**ì¡°ì§ì  ìš”ì†Œ:**
- âœ… ê°œë°œ-ë³´ì•ˆ íŒ€ í˜‘ì—… ë¬¸í™”
- âœ… ë³´ì•ˆ ì±”í”¼ì–¸ í”„ë¡œê·¸ë¨
- âœ… ì§€ì†ì ì¸ êµìœ¡ ë° í›ˆë ¨
- âœ… ê²½ì˜ì§„ì˜ ì§€ì›ê³¼ íˆ¬ì

**í”„ë¡œì„¸ìŠ¤ ìš”ì†Œ:**
- âœ… Shift-Left ë³´ì•ˆ ì „ëµ
- âœ… ìœ„í˜‘ ëª¨ë¸ë§ í†µí•©
- âœ… ì·¨ì•½ì  ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤
- âœ… ì‚¬ê³  ëŒ€ì‘ í”Œë ˆì´ë¶

### 10.3 2025-2026 íŠ¸ë Œë“œ ì „ë§

#### 10.3.1 AI/ML ê¸°ë°˜ ë³´ì•ˆ ìë™í™” í™•ëŒ€

```
2025ë…„: AI ë³´ì•ˆ ë„êµ¬ ë„ì… (30% ê¸°ì—…)
2026ë…„: AI ë³´ì•ˆì´ í‘œì¤€ (70% ê¸°ì—…)

ì£¼ìš” ì ìš© ë¶„ì•¼:
- ì·¨ì•½ì  ìš°ì„ ìˆœìœ„ ìë™ ê²°ì •
- False Positive ìë™ í•„í„°ë§
- ìë™ íŒ¨ì¹˜ ìƒì„± ë° ì ìš©
- ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ìë™ ìˆ˜ì§‘
```

#### 10.3.2 ê³µê¸‰ë§ ë³´ì•ˆ ê°•í™”

```
SBOM (Software Bill of Materials) ì˜ë¬´í™”:
- EU Cyber Resilience Act (2024)
- US Executive Order 14028
- í•œêµ­ ì •ë³´ë³´í˜¸ì‚°ì—…ë²• ê°œì •ì•ˆ

ì£¼ìš” ìš”êµ¬ì‚¬í•­:
- ëª¨ë“  ì†Œí”„íŠ¸ì›¨ì–´ì— SBOM ì²¨ë¶€
- ë””ì§€í„¸ ì„œëª… ë° ê²€ì¦
- ì·¨ì•½ì  ê³µê°œ ì •ì±… (VEX)
```

**êµ¬í˜„ ì˜ˆì‹œ:**

```bash
# SBOM ìƒì„± ë° ì„œëª…
syft myapp:latest -o cyclonedx-json > sbom.json
cosign sign-blob --key cosign.key sbom.json > sbom.json.sig

# SBOM ê²€ì¦
cosign verify-blob --key cosign.pub --signature sbom.json.sig sbom.json
```

#### 10.3.3 Zero Trust ì•„í‚¤í…ì²˜

```
ì „í†µì  ê²½ê³„ ë³´ì•ˆ â†’ Zero Trust

í•µì‹¬ ì›ì¹™:
1. "ì ˆëŒ€ ì‹ ë¢°í•˜ì§€ ë§ê³ , í•­ìƒ ê²€ì¦í•˜ë¼"
2. ìµœì†Œ ê¶Œí•œ ì›ì¹™
3. ë§ˆì´í¬ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜
4. ì§€ì†ì ì¸ ê²€ì¦

DevSecOps í†µí•©:
- Service Mesh (Istio, Linkerd)
- mTLS ìë™ ê´€ë¦¬
- ì„¸ë°€í•œ RBAC ì •ì±…
- ë™ì  Secret ê´€ë¦¬
```

#### 10.3.4 Platform Engineering ë¶€ìƒ

```
DevSecOps â†’ Platform Engineering

Internal Developer Platform (IDP):
- ì…€í”„ ì„œë¹„ìŠ¤ ì¸í”„ë¼
- ë³´ì•ˆ ê¸°ë³¸ ë‚´ì¥ (Secure by Default)
- Golden Path ì œê³µ
- ê°œë°œì ê²½í—˜ ìµœìš°ì„ 

ì˜ˆì‹œ: Backstage, Humanitec, Kratix
```

### 10.4 ì‹¤ë¬´ ì ìš© ë¡œë“œë§µ

**Phase 1: ê¸°ì´ˆ êµ¬ì¶• (1-3ê°œì›”)**
```
Week 1-2: í˜„í™© í‰ê°€
- ê¸°ì¡´ ë³´ì•ˆ í”„ë¡œì„¸ìŠ¤ ë¶„ì„
- ë„êµ¬ ìŠ¤íƒ ê²€í† 
- íŒ€ ì—­ëŸ‰ í‰ê°€

Week 3-4: ë„êµ¬ ë„ì…
- Secret ìŠ¤ìº” (Gitleaks)
- SAST (Semgrep, SonarQube)
- SCA (Trivy, Snyk)

Week 5-8: CI/CD í†µí•©
- GitHub Actions íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- ë³´ì•ˆ ê²Œì´íŠ¸ ì„¤ì •
- ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘ ì‹œì‘

Week 9-12: êµìœ¡ ë° ë¬¸í™”
- ê°œë°œíŒ€ êµìœ¡
- ë³´ì•ˆ ì±”í”¼ì–¸ ì„ ì •
- í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œí™”
```

**Phase 2: ì‹¬í™” (4-6ê°œì›”)**
```
Month 4: ê³ ê¸‰ ìŠ¤ìº”
- DAST (OWASP ZAP)
- IaC ìŠ¤ìº” (Checkov, tfsec)
- ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ ë³´ì•ˆ (Falco)

Month 5: ìë™í™” í™•ëŒ€
- ìë™ íŒ¨ì¹˜ ì‹œìŠ¤í…œ
- GuardDuty ìë™ ëŒ€ì‘
- Security Hub í†µí•©

Month 6: ìµœì í™”
- False Positive íŠœë‹
- íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ê°œì„ 
- ë³´ì•ˆ ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ
```

**Phase 3: ê³ ë„í™” (7-12ê°œì›”)**
```
Month 7-9: AI/ML ë„ì…
- AI ê¸°ë°˜ ì·¨ì•½ì  ìš°ì„ ìˆœìœ„í™”
- ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ
- ìë™í™”ëœ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤

Month 10-12: ê·œì • ì¤€ìˆ˜
- ISMS-P ì¸ì¦ ì¤€ë¹„
- ISO 27001 ì¤€ìˆ˜
- SOC 2 ê°ì‚¬ ëŒ€ì‘
```

### 10.5 ì¼ë°˜ì ì¸ ì‹¤ìˆ˜ì™€ í•´ê²°ì±…

| ì‹¤ìˆ˜ | ì˜í–¥ | í•´ê²°ì±… |
|------|------|--------|
| **ë³´ì•ˆ ê²Œì´íŠ¸ê°€ ë„ˆë¬´ ì—„ê²©** | ê°œë°œ ì†ë„ ì €í•˜, íŒ€ ë¶ˆë§Œ | ì ì§„ì  ë„ì…, ì„ê³„ê°’ ì¡°ì • |
| **False Positive ê³¼ë‹¤** | ë³´ì•ˆ ì•Œë¦¼ ë¬´ì‹œ ë¬¸í™” í˜•ì„± | ì˜¤íƒ ì œì™¸ ê·œì¹™, AI í•„í„°ë§ |
| **ë„êµ¬ ê³¼ë‹¤ ë„ì…** | ê´€ë¦¬ ë¶€ë‹´, ë¹„ìš© ì¦ê°€ | í†µí•© í”Œë«í¼ ì„ íƒ, ìš°ì„ ìˆœìœ„ ì„¤ì • |
| **êµìœ¡ ë¶€ì¡±** | ë„êµ¬ ì˜¤ìš©, ìš°íšŒ ì‹œë„ | ì§€ì†ì  êµìœ¡, ì±”í”¼ì–¸ í”„ë¡œê·¸ë¨ |
| **ë©”íŠ¸ë¦­ìŠ¤ ë¯¸ìˆ˜ì§‘** | íš¨ê³¼ ì…ì¦ ë¶ˆê°€ | ìë™í™”ëœ ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘, ëŒ€ì‹œë³´ë“œ |
| **ê²½ì˜ì§„ ì§€ì› ë¶€ì¡±** | ì˜ˆì‚° ì œì•½, ìš°ì„ ìˆœìœ„ ë°€ë¦¼ | ROI ê³„ì‚°, ì •ê¸° ë³´ê³  |

### 10.6 ìµœì¢… ê¶Œì¥ì‚¬í•­

**DO:**
- âœ… ì‘ê²Œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ í™•ëŒ€
- âœ… ê°œë°œì ê²½í—˜ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤
- âœ… ìë™í™”ì— íˆ¬ì
- âœ… ë©”íŠ¸ë¦­ìŠ¤ë¡œ ì„±ê³¼ ì¸¡ì •
- âœ… ë³´ì•ˆì„ ë¬¸í™”ë¡œ ë§Œë“¤ê¸°

**DON'T:**
- âŒ í•œ ë²ˆì— ëª¨ë“  ë„êµ¬ ë„ì…
- âŒ ê°œë°œ ì†ë„ë¥¼ ê³¼ë„í•˜ê²Œ í¬ìƒ
- âŒ ë³´ì•ˆ íŒ€ë§Œì˜ í”„ë¡œì íŠ¸ë¡œ ë§Œë“¤ê¸°
- âŒ False Positive ë°©ì¹˜
- âŒ ê·œì • ì¤€ìˆ˜ë§Œì„ ëª©í‘œë¡œ í•˜ê¸°

### 10.7 ë§ˆë¬´ë¦¬

9ì£¼ê°„ì˜ í´ë¼ìš°ë“œ ì‹œíë¦¬í‹° ê³¼ì •ì„ í†µí•´ DevSecOpsì˜ ì „ì²´ ê·¸ë¦¼ì„ ê·¸ë ¤ë³´ì•˜ìŠµë‹ˆë‹¤.

DevSecOpsëŠ” ë‹¨ìˆœíˆ ë„êµ¬ë¥¼ ë„ì…í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ê°œë°œÂ·ë³´ì•ˆÂ·ìš´ì˜ íŒ€ì˜ í˜‘ì—… ë¬¸í™”**ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë³´ì•ˆì„ "ë³‘ëª©"ì´ ì•„ë‹Œ "ê°€ì†ê¸°"ë¡œ ë§Œë“¤ ë•Œ, ë¹„ë¡œì†Œ ì§„ì •í•œ DevSecOpsê°€ ì‹¤í˜„ë©ë‹ˆë‹¤.

> "Security is not a product, but a process." - Bruce Schneier

2025ë…„, DevSecOpsëŠ” ë” ì´ìƒ ì„ íƒì´ ì•„ë‹Œ í•„ìˆ˜ì…ë‹ˆë‹¤. AI/ML ê¸°ë°˜ ìë™í™”, ê³µê¸‰ë§ ë³´ì•ˆ, Zero Trust ì•„í‚¤í…ì²˜ê°€ ìƒˆë¡œìš´ í‘œì¤€ìœ¼ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤.

ì´ í¬ìŠ¤íŒ…ì´ ì—¬ëŸ¬ë¶„ì˜ DevSecOps ì—¬ì •ì— ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤. ì•ˆì „í•˜ê³  ë¹ ë¥¸ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì„ ì‘ì›í•©ë‹ˆë‹¤! ğŸš€ğŸ”’

---

**ë‹¤ìŒ ê³¼ì • ì˜ˆê³ :**
- **10ì£¼ì°¨**: í´ë¼ìš°ë“œ ë³´ì•ˆ ìµœì¢… í”„ë¡œì íŠ¸ - End-to-End ë³´ì•ˆ ì•„í‚¤í…ì²˜ ì„¤ê³„
- **íŠ¹ë³„í¸**: Kubernetes ë³´ì•ˆ ì‹¬í™” - RBAC, Network Policies, Pod Security Standards

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ

| ë¦¬ì†ŒìŠ¤ | ì„¤ëª… | URL |
|--------|------|-----|
| **OWASP DevSecOps Guideline** | DevSecOps êµ¬í˜„ ê°€ì´ë“œ | [https://owasp.org/www-project-devsecops-guideline/](https://owasp.org/www-project-devsecops-guideline/) |
| **OWASP DSOMM** | DevSecOps ì„±ìˆ™ë„ ëª¨ë¸ | [https://dsomm.owasp.org/](https://dsomm.owasp.org/) |
| **CNCF Security TAG** | í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ë³´ì•ˆ | [https://github.com/cncf/tag-security](https://github.com/cncf/tag-security) |
| **NIST SSDF** | Secure Software Development Framework | [https://csrc.nist.gov/Projects/ssdf](https://csrc.nist.gov/Projects/ssdf) |
| **AWS Security Best Practices** | AWS ë³´ì•ˆ ê°€ì´ë“œ | [https://docs.aws.amazon.com/security/](https://docs.aws.amazon.com/security/) |
| **Microsoft DevSecOps** | Azure DevSecOps ê°€ì´ë“œ | [https://learn.microsoft.com/en-us/azure/architecture/solution-ideas/articles/devsecops-in-azure](https://learn.microsoft.com/en-us/azure/architecture/solution-ideas/articles/devsecops-in-azure) |

### ë„êµ¬ ê³µì‹ ì‚¬ì´íŠ¸

| ë„êµ¬ | ì¹´í…Œê³ ë¦¬ | URL |
|------|----------|-----|
| **SonarQube** | SAST | [https://www.sonarsource.com/products/sonarqube/](https://www.sonarsource.com/products/sonarqube/) |
| **Semgrep** | SAST | [https://semgrep.dev/](https://semgrep.dev/) |
| **OWASP ZAP** | DAST | [https://www.zaproxy.org/](https://www.zaproxy.org/) |
| **Trivy** | SCA/Image Scan | [https://github.com/aquasecurity/trivy](https://github.com/aquasecurity/trivy) |
| **Snyk** | SCA | [https://snyk.io/](https://snyk.io/) |
| **Falco** | Runtime Security | [https://falco.org/](https://falco.org/) |
| **Checkov** | IaC Scan | [https://www.checkov.io/](https://www.checkov.io/) |
| **Gitleaks** | Secret Scan | [https://github.com/gitleaks/gitleaks](https://github.com/gitleaks/gitleaks) |
| **Cosign** | Image Signing | [https://github.com/sigstore/cosign](https://github.com/sigstore/cosign) |
| **OPA** | Policy as Code | [https://www.openpolicyagent.org/](https://www.openpolicyagent.org/) |

### í•™ìŠµ ìë£Œ

| ë¦¬ì†ŒìŠ¤ | ì„¤ëª… | URL |
|--------|------|-----|
| **OWASP Top 10** | ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ 10ëŒ€ ì·¨ì•½ì  | [https://owasp.org/www-project-top-ten/](https://owasp.org/www-project-top-ten/) |
| **OWASP API Security Top 10** | API ë³´ì•ˆ ì·¨ì•½ì  | [https://owasp.org/www-project-api-security/](https://owasp.org/www-project-api-security/) |
| **CWE Top 25** | ê°€ì¥ ìœ„í—˜í•œ ì†Œí”„íŠ¸ì›¨ì–´ ì•½ì  | [https://cwe.mitre.org/top25/](https://cwe.mitre.org/top25/) |
| **MITRE ATT&CK** | ê³µê²© ê¸°ë²• í”„ë ˆì„ì›Œí¬ | [https://attack.mitre.org/](https://attack.mitre.org/) |
| **WebGoat** | ë³´ì•ˆ ì‹¤ìŠµ í™˜ê²½ | [https://github.com/WebGoat/WebGoat](https://github.com/WebGoat/WebGoat) |
| **DVWA** | ì·¨ì•½í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ | [https://github.com/digininja/DVWA](https://github.com/digininja/DVWA) |

### ë³´ê³ ì„œ ë° ë¦¬ì„œì¹˜

| ë¦¬ì†ŒìŠ¤ | ì„¤ëª… | URL |
|--------|------|-----|
| **Gartner DevSecOps** | DevSecOps ì‹œì¥ ë¶„ì„ | [https://www.gartner.com/en/documents/3987568](https://www.gartner.com/en/documents/3987568) |
| **IBM Cost of Data Breach** | ë°ì´í„° ìœ ì¶œ ë¹„ìš© ë³´ê³ ì„œ | [https://www.ibm.com/security/data-breach](https://www.ibm.com/security/data-breach) |
| **Forrester DevSecOps** | DevSecOps ëª¨ë²” ì‚¬ë¡€ | [https://www.forrester.com/](https://www.forrester.com/) |
| **State of DevOps Report** | DevOps í˜„í™© ë³´ê³ ì„œ | [https://www.devops-research.com/research.html](https://www.devops-research.com/research.html) |
| **Snyk State of Open Source Security** | ì˜¤í”ˆì†ŒìŠ¤ ë³´ì•ˆ í˜„í™© | [https://snyk.io/reports/](https://snyk.io/reports/) |

### í•œêµ­ ê·œì • ë° ì¸ì¦

| ë¦¬ì†ŒìŠ¤ | ì„¤ëª… | URL |
|--------|------|-----|
| **ISMS-P** | ì •ë³´ë³´í˜¸ ë° ê°œì¸ì •ë³´ë³´í˜¸ ê´€ë¦¬ì²´ê³„ | [https://isms.kisa.or.kr/](https://isms.kisa.or.kr/) |
| **ê°œì¸ì •ë³´ë³´í˜¸ë²•** | ê°œì¸ì •ë³´ë³´í˜¸ ë²•ë ¹ | [https://www.privacy.go.kr/](https://www.privacy.go.kr/) |
| **ì •ë³´ë³´í˜¸ì‚°ì—…ë²•** | ì •ë³´ë³´í˜¸ì‚°ì—… ì§„í¥ë²• | [https://www.law.go.kr/](https://www.law.go.kr/) |
| **KISA ë³´ì•ˆ ê°€ì´ë“œ** | í•œêµ­ì¸í„°ë„·ì§„í¥ì› ê°€ì´ë“œ | [https://www.kisa.or.kr/](https://www.kisa.or.kr/) |

### ì˜¨ë¼ì¸ ê°•ì˜ (edu.2twodragon.com)

| ê³¼ì • | ì„¤ëª… | ë§í¬ |
|------|------|------|
| **DevSecOps ì‹¤ì „** | DevSecOps ì „ëµ, ë³´ì•ˆ ìë™í™”, ëª¨ë‹ˆí„°ë§ | [ìˆ˜ê°•í•˜ê¸°](https://edu.2twodragon.com/courses/devsecops) |
| **CI/CD ë³´ì•ˆ** | íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ, Secret ê´€ë¦¬, ì´ë¯¸ì§€ ìŠ¤ìº” ìë™í™” | [ìˆ˜ê°•í•˜ê¸°](https://edu.2twodragon.com/courses/cicd-security) |
| **Kubernetes ë³´ì•ˆ** | í´ëŸ¬ìŠ¤í„° ë³´ì•ˆ, RBAC, Network Policies | [ìˆ˜ê°•í•˜ê¸°](https://edu.2twodragon.com/courses/kubernetes-security) |
| **í´ë¼ìš°ë“œ ë³´ì•ˆ ì•„í‚¤í…ì²˜** | AWS/Azure/GCP ë³´ì•ˆ ì„¤ê³„ | [ìˆ˜ê°•í•˜ê¸°](https://edu.2twodragon.com/courses/cloud-security) |

### YouTube ì˜ìƒ

| ì£¼ì œ | ì„¤ëª… | ë§í¬ |
|------|------|------|
| **AWS WAF ë„¤íŠ¸ì›Œí¬ ì‹œë‚˜ë¦¬ì˜¤** | AWS WAFì™€ ì „ì²´ì ì¸ ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ êµ¬ì„± | [ì‹œì²­í•˜ê¸°](https://youtu.be/r84IuPv_4TI) |
| **DevSecOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•** | GitHub Actions ë³´ì•ˆ íŒŒì´í”„ë¼ì¸ ì‹¤ìŠµ | [ì‹œì²­í•˜ê¸°](https://youtube.com/@twodragon) |
| **Kubernetes ë³´ì•ˆ ì‹¤ì „** | RBAC, Network Policies, PSS ì„¤ì • | [ì‹œì²­í•˜ê¸°](https://youtube.com/@twodragon) |

### ì»¤ë®¤ë‹ˆí‹° ë° ì»¨í¼ëŸ°ìŠ¤

| ë¦¬ì†ŒìŠ¤ | ì„¤ëª… | URL |
|--------|------|-----|
| **DevSecOps Community** | ê¸€ë¡œë²Œ ì»¤ë®¤ë‹ˆí‹° | [https://www.devsecops.org/](https://www.devsecops.org/) |
| **OWASP Korea** | OWASP í•œêµ­ ì±•í„° | [https://owasp.org/www-chapter-korea/](https://owasp.org/www-chapter-korea/) |
| **Cloud Native Security Day** | CNCF ë³´ì•ˆ ì»¨í¼ëŸ°ìŠ¤ | [https://events.linuxfoundation.org/](https://events.linuxfoundation.org/) |
| **Black Hat / DEF CON** | ë³´ì•ˆ ì»¨í¼ëŸ°ìŠ¤ | [https://www.blackhat.com/](https://www.blackhat.com/) |

### GitHub ë ˆí¬ì§€í† ë¦¬ (ì˜ˆì œ ì½”ë“œ)

| í”„ë¡œì íŠ¸ | ì„¤ëª… | URL |
|----------|------|-----|
| **DevSecOps Pipeline Examples** | CI/CD ë³´ì•ˆ íŒŒì´í”„ë¼ì¸ ì˜ˆì œ | [https://github.com/devsecops/](https://github.com/devsecops/) |
| **Awesome DevSecOps** | DevSecOps ë¦¬ì†ŒìŠ¤ íë ˆì´ì…˜ | [https://github.com/TaptuIT/awesome-devsecops](https://github.com/TaptuIT/awesome-devsecops) |
| **OWASP Threat Dragon** | ìœ„í˜‘ ëª¨ë¸ë§ ë„êµ¬ | [https://github.com/OWASP/threat-dragon](https://github.com/OWASP/threat-dragon) |

---

## ê´€ë ¨ í¬ìŠ¤íŠ¸

- [í´ë¼ìš°ë“œ ì‹œíë¦¬í‹° ê³¼ì • 7ê¸° - 1ì£¼ì°¨: í´ë¼ìš°ë“œ ë³´ì•ˆ ê¸°ì´ˆ](/security/2025/04/18/Cloud_Security_Course_7Batch_-_1Week_Cloud_Security_Basics.html)
- [í´ë¼ìš°ë“œ ì‹œíë¦¬í‹° ê³¼ì • 7ê¸° - 5ì£¼ì°¨: ì»¨í…Œì´ë„ˆ ë³´ì•ˆ](/security/2025/05/16/Cloud_Security_Course_7Batch_-_5Week_Container_Security.html)
- [AWS Security Hubì™€ GuardDuty í†µí•© ê°€ì´ë“œ](/devsecops/2025/03/20/AWS_Security_Hub_GuardDuty_Integration.html)
- [Kubernetes RBAC ì™„ë²½ ê°€ì´ë“œ](/kubernetes/2025/02/10/Kubernetes_RBAC_Complete_Guide.html)

---

**ì´ í¬ìŠ¤íŒ…ì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´:**
- â­ ë¶ë§ˆí¬í•˜ê¸°
- ğŸ’¬ ëŒ“ê¸€ë¡œ ì§ˆë¬¸í•˜ê¸°
- ğŸ”— ë™ë£Œì—ê²Œ ê³µìœ í•˜ê¸°

**ë¬¸ì˜ì‚¬í•­:**
- ğŸ“§ ì´ë©”ì¼: security@2twodragon.com
- ğŸ’¼ LinkedIn: [Twodragon LinkedIn](https://linkedin.com/in/twodragon)
- ğŸ¦ Twitter: [@twodragon_tech](https://twitter.com/twodragon_tech)
