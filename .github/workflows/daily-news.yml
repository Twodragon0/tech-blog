name: Daily Tech News Auto Publish

on:
  schedule:
    # Îß§Ïùº Ïò§Ï†Ñ 10Ïãú KST = UTC 01:00
    # GitHub Actions cronÏùÄ ÌÅê ÏßÄÏó∞Ïù¥ ÏûàÏùÑ Ïàò ÏûàÏùå (ÏµúÎåÄ 15-30Î∂Ñ)
    - cron: '0 1 * * *'
    # Î∞±ÏóÖ: Ïò§ÌõÑ 6Ïãú KST = UTC 09:00 (schedule ÎØ∏ÏûëÎèô ÎåÄÎπÑ)
    - cron: '0 9 * * *'
  
  # Ï†ÄÏû•ÏÜå Ìë∏Ïãú ÏãúÏóêÎèÑ Ìä∏Î¶¨Í±∞ (ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÌååÏùº ÏàòÏ†ï Ïãú)
  push:
    branches: [main]
    paths:
      - '.github/workflows/daily-news.yml'
      - 'scripts/collect_tech_news.py'
      - 'scripts/auto_publish_news.py'
  
  workflow_dispatch:
    inputs:
      hours:
        description: 'Hours to look back for news'
        required: false
        default: '24'
      dry_run:
        description: 'Dry run (preview only)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
      max_news:
        description: 'Maximum news items to include'
        required: false
        default: '15'

concurrency:
  group: daily-news-publish
  cancel-in-progress: false

env:
  PYTHON_VERSION: '3.11'

jobs:
  collect-and-publish:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install feedparser requests beautifulsoup4 python-frontmatter PyYAML
      
      - name: Create directories
        run: mkdir -p _data data _posts assets/images
      
      - name: Collect tech news from RSS
        id: collect
        run: |
          HOURS="${{ github.event.inputs.hours || '24' }}"
          echo "Collecting news from last $HOURS hours..."

          # RSS ÏàòÏßë Ïã§Ìñâ (ÌÉÄÏûÑÏïÑÏõÉ 8Î∂Ñ, Í∞úÎ≥Ñ ÌîºÎìú ÌÉÄÏûÑÏïÑÏõÉ 15Ï¥à)
          timeout 480 python3 scripts/collect_tech_news.py --hours $HOURS --output _data/collected_news.json --feed-timeout 15 || {
            echo "::warning::RSS collection timed out or failed, checking existing data..."
          }

          # _dataÏóê ÏàòÏßë Ïã§Ìå® Ïãú Í∏∞Ï°¥ data/ Ìè¥ÎçîÏóêÏÑú Î≥µÏÇ¨ (ÌïòÏúÑ Ìò∏Ìôò)
          if [ ! -f "_data/collected_news.json" ] && [ -f "data/collected_news.json" ]; then
            cp data/collected_news.json _data/collected_news.json
            echo "::notice::Copied existing news data from data/ to _data/"
          fi

          # ÏàòÏßë ÏÑ±Í≥µ Ïãú data/ÏóêÎèÑ ÎèôÍ∏∞Ìôî (git Ï∂îÏ†ÅÏö©)
          if [ -f "_data/collected_news.json" ]; then
            cp _data/collected_news.json data/collected_news.json
          fi
      
      - name: Check collected news
        id: check_news
        run: |
          # _data/ ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏ (Jekyll ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨)
          if [ -f "_data/collected_news.json" ]; then
            TOTAL=$(python3 -c "import json; d=json.load(open('_data/collected_news.json')); print(d.get('total_items', 0))")
            echo "news_count=$TOTAL" >> $GITHUB_OUTPUT
            echo "‚úÖ Collected $TOTAL news items"

            if [ "$TOTAL" -ge 5 ]; then
              echo "has_enough_news=true" >> $GITHUB_OUTPUT
            else
              echo "has_enough_news=false" >> $GITHUB_OUTPUT
              echo "‚ö†Ô∏è Not enough news to publish (minimum: 5, got: $TOTAL)"
            fi
          else
            echo "news_count=0" >> $GITHUB_OUTPUT
            echo "has_enough_news=false" >> $GITHUB_OUTPUT
            echo "‚ùå No news collected - _data/collected_news.json not found"
          fi
      
      - name: Auto publish daily digest (single post per day)
        if: steps.check_news.outputs.has_enough_news == 'true'
        run: |
          DRY_RUN="${{ github.event.inputs.dry_run || 'false' }}"
          MAX_NEWS="${{ github.event.inputs.max_news || '15' }}"
          HOURS="${{ github.event.inputs.hours || '24' }}"
          TODAY=$(date +%Y-%m-%d)

          echo "üìä Debug Info:"
          echo "  - Event: ${{ github.event_name }}"
          echo "  - Dry Run: $DRY_RUN"
          echo "  - Max News: $MAX_NEWS"
          echo "  - Hours: $HOURS"
          echo "  - Trigger Time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"

          # Check if any post already exists for today (manual or auto)
          EXISTING=$(ls _posts/${TODAY}-*Digest*.md _posts/${TODAY}-*Weekly*.md 2>/dev/null | head -1)
          if [ -n "$EXISTING" ]; then
            echo "‚è≠Ô∏è Post already exists for today: $EXISTING"
            echo "   Skipping auto-publish to avoid duplicates (1 post/day policy)."
          else
            CMD="python3 scripts/auto_publish_news.py --hours $HOURS --max-news $MAX_NEWS"

            if [ "$DRY_RUN" = "true" ]; then
              CMD="$CMD --dry-run"
            fi

            echo "Running: $CMD"
            $CMD
          fi

          echo ""
          echo "üìÅ Today's files:"
          ls -la _posts/${TODAY}-*.md 2>/dev/null || echo "No posts found"
          ls -la assets/images/${TODAY}-*.svg 2>/dev/null || echo "No images found"

      - name: Validate post quality
        if: steps.check_news.outputs.has_enough_news == 'true'
        run: |
          TODAY=$(date +%Y-%m-%d)
          POST_FILE=$(ls _posts/${TODAY}-*Digest*.md _posts/${TODAY}-*Weekly*.md 2>/dev/null | sort -u | head -1)

          if [ -n "$POST_FILE" ] && [ -f "$POST_FILE" ]; then
            echo "üìã Validating post quality..."

            # Check minimum file size (at least 5KB for quality post)
            FILE_SIZE=$(wc -c < "$POST_FILE")
            echo "  File size: ${FILE_SIZE} bytes"

            if [ "$FILE_SIZE" -lt 5000 ]; then
              echo "::warning::Post is too small (${FILE_SIZE} bytes). Quality may be low."
            fi

            # Check for required sections
            SECTIONS=0
            for section in "## 1." "## 2." "Ïã§Î¨¥ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏" "Ï∞∏Í≥† ÏûêÎ£å" "Ìä∏Î†åÎìú Î∂ÑÏÑù"; do
              if grep -q "$section" "$POST_FILE"; then
                SECTIONS=$((SECTIONS + 1))
              fi
            done
            echo "  Required sections found: ${SECTIONS}/5"

            # Check for front matter completeness
            FM_FIELDS=0
            for field in "title:" "date:" "categories:" "tags:" "excerpt:" "description:" "image:" "toc:"; do
              if head -20 "$POST_FILE" | grep -q "$field"; then
                FM_FIELDS=$((FM_FIELDS + 1))
              fi
            done
            echo "  Front matter fields: ${FM_FIELDS}/8"

            # Check for AI summary card
            if grep -q "ai-summary-card" "$POST_FILE"; then
              echo "  AI Summary Card: ‚úÖ"
            else
              echo "::warning::Missing AI Summary Card"
            fi

            echo "‚úÖ Quality validation complete"
          else
            echo "‚è≠Ô∏è No post to validate"
          fi

      - name: Check for new post
        id: check_post
        if: steps.check_news.outputs.has_enough_news == 'true'
        run: |
          TODAY=$(date +%Y-%m-%d)
          
          # Ïó¨Îü¨ Ìå®ÌÑ¥Ïùò Ìè¨Ïä§Ìä∏ ÌååÏùº ÌôïÏù∏
          POST_FILE=""
          for pattern in "_posts/${TODAY}-Tech_Security_Weekly_Digest.md" "_posts/${TODAY}-Tech_Security_Weekly_Digest_*.md" "_posts/${TODAY}-Tech_Blog_Weekly_Digest_*.md" "_posts/${TODAY}-*.md"; do
            found=$(ls $pattern 2>/dev/null | head -1)
            if [ -n "$found" ]; then
              POST_FILE="$found"
              break
            fi
          done
          
          if [ -n "$POST_FILE" ] && [ -f "$POST_FILE" ]; then
            echo "post_created=true" >> $GITHUB_OUTPUT
            echo "post_file=$POST_FILE" >> $GITHUB_OUTPUT
            echo "Post created: $POST_FILE"
          else
            echo "post_created=false" >> $GITHUB_OUTPUT
            echo "No post created for today"
            ls -la _posts/*.md 2>/dev/null | tail -5 || echo "No posts found"
          fi
      
      - name: Commit and push
        if: steps.check_post.outputs.post_created == 'true' && github.event.inputs.dry_run != 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          TODAY=$(date +%Y-%m-%d)
          
          # ÏÉà Ìè¨Ïä§Ìä∏ÏôÄ Ïù¥ÎØ∏ÏßÄ, ÏàòÏßë Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
          git add _posts/${TODAY}*.md 2>/dev/null || true
          git add assets/images/${TODAY}*.svg 2>/dev/null || true
          git add _data/collected_news.json 2>/dev/null || true
          git add data/collected_news.json 2>/dev/null || true

          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            NEWS_COUNT="${{ steps.check_news.outputs.news_count }}"
            POST_FILE="${{ steps.check_post.outputs.post_file }}"
            git commit -m "feat: auto publish daily tech & security digest - ${TODAY}" \
              -m "News collected: ${NEWS_COUNT}" \
              -m "Post: ${POST_FILE}" \
              -m "Triggered by: ${{ github.event_name }}"

            # ÎèôÏãú Ïã§Ìñâ Ïãú push Ï∂©Îèå Î∞©ÏßÄ (ÏµúÎåÄ 3Ìöå Ïû¨ÏãúÎèÑ)
            for i in 1 2 3; do
              if git push; then
                echo "‚úÖ Changes committed and pushed (attempt $i)"
                break
              else
                echo "‚ö†Ô∏è Push failed (attempt $i), pulling latest..."
                git pull --rebase origin main || true
                if [ $i -eq 3 ]; then
                  echo "‚ùå Push failed after 3 attempts"
                  exit 1
                fi
              fi
            done
          fi
      
      - name: Summary
        if: always()
        run: |
          echo "## üì∞ Daily News Auto Publish Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Date**: $(date +%Y-%m-%d)" >> $GITHUB_STEP_SUMMARY
          echo "- **News Collected**: ${{ steps.check_news.outputs.news_count }}" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.check_post.outputs.post_created }}" = "true" ]; then
            echo "- **Status**: ‚úÖ Post published successfully" >> $GITHUB_STEP_SUMMARY
            echo "- **File**: \`${{ steps.check_post.outputs.post_file }}\`" >> $GITHUB_STEP_SUMMARY

            # Show post size if available
            POST_FILE="${{ steps.check_post.outputs.post_file }}"
            if [ -n "$POST_FILE" ] && [ -f "$POST_FILE" ]; then
              POST_SIZE=$(wc -c < "$POST_FILE")
              POST_LINES=$(wc -l < "$POST_FILE")
              echo "- **Post Size**: ${POST_SIZE} bytes (${POST_LINES} lines)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- **Status**: ‚è≠Ô∏è Skipped (not enough news or dry run)" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- Hours lookback: ${{ github.event.inputs.hours || '24' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Max news: ${{ github.event.inputs.max_news || '15' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Dry run: ${{ github.event.inputs.dry_run || 'false' }}" >> $GITHUB_STEP_SUMMARY

      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::Daily news workflow failed. Check logs for details."
          echo "## ‚ùå Daily News Workflow Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The daily news auto-publish workflow encountered an error." >> $GITHUB_STEP_SUMMARY
          echo "Please check the [workflow run logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details." >> $GITHUB_STEP_SUMMARY

  weekly-source-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' && github.event.schedule == '0 1 * * 1'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: pip install feedparser requests
      
      - name: Check RSS feed health
        run: |
          python3 -c "
          import sys
          sys.path.insert(0, 'scripts')
          from collect_tech_news import NEWS_SOURCES
          import feedparser
          
          print('üîç Checking RSS feed status...')
          print('=' * 50)
          
          ok_count = 0
          failed = []
          
          for key, config in NEWS_SOURCES.items():
              feed_url = config.get('feed_url', '')
              if not feed_url:
                  continue
              
              try:
                  feed = feedparser.parse(feed_url)
                  if feed.bozo and not feed.entries:
                      failed.append((key, config['name'], str(feed.bozo_exception)[:50]))
                      print(f'‚ùå {config[\"name\"]}')
                  else:
                      ok_count += 1
                      print(f'‚úÖ {config[\"name\"]} ({len(feed.entries)} entries)')
              except Exception as e:
                  failed.append((key, config['name'], str(e)[:50]))
                  print(f'‚ùå {config[\"name\"]}: {str(e)[:30]}')
          
          print('=' * 50)
          print(f'Summary: {ok_count}/{len(NEWS_SOURCES)} sources OK')
          
          if failed:
              print('\\nFailed sources:')
              for key, name, error in failed:
                  print(f'  - {name}: {error}')
          "
