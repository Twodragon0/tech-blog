#!/usr/bin/env python3
"""
AI ê°•í™” ê²°ê³¼ ìºì‹± ì‹œìŠ¤í…œ (7ì¼ TTL)

AI ë¶„ì„ ê²°ê³¼ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìºì‹±í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import hashlib
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ìºì‹œ íŒŒì¼ ìœ„ì¹˜
CACHE_FILE = Path(__file__).parent.parent / "_data" / "ai_cache.json"
TTL_DAYS = 7


def get_cache_key(url: str) -> str:
    """
    URL ê¸°ë°˜ ìºì‹œ í‚¤ ìƒì„±

    Args:
        url: ì›ë³¸ URL

    Returns:
        SHA256 ê¸°ë°˜ 16ì ìºì‹œ í‚¤
    """
    return hashlib.sha256(url.encode()).hexdigest()[:16]


def load_cache() -> Dict:
    """
    ìºì‹œ íŒŒì¼ ë¡œë“œ

    Returns:
        ìºì‹œ ë”•ì…”ë„ˆë¦¬
    """
    if CACHE_FILE.exists():
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load cache: {e}")
            return {}
    return {}


def save_cache(cache: Dict) -> bool:
    """
    ìºì‹œ íŒŒì¼ ì €ì¥

    Args:
        cache: ì €ì¥í•  ìºì‹œ ë”•ì…”ë„ˆë¦¬

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        logger.error(f"Failed to save cache: {e}")
        return False


def is_cache_valid(timestamp_str: str) -> bool:
    """
    ìºì‹œ í•­ëª©ì˜ ìœ íš¨ì„± ê²€ì‚¬ (7ì¼ TTL)

    Args:
        timestamp_str: ISO í˜•ì‹ íƒ€ì„ìŠ¤íƒ¬í”„

    Returns:
        ìºì‹œê°€ ìœ íš¨í•œ ê²½ìš° True
    """
    try:
        cached_time = datetime.fromisoformat(timestamp_str)
        age = datetime.now() - cached_time
        return age < timedelta(days=TTL_DAYS)
    except Exception:
        return False


def get_cached_analysis(url: str) -> Optional[str]:
    """
    ìºì‹œëœ AI ë¶„ì„ ì¡°íšŒ (7ì¼ ì´ë‚´ë§Œ ë°˜í™˜)

    Args:
        url: ì¡°íšŒí•  URL

    Returns:
        ìºì‹œëœ ë¶„ì„ ê²°ê³¼ (ì—†ìœ¼ë©´ None)
    """
    cache = load_cache()
    key = get_cache_key(url)

    if key in cache:
        entry = cache[key]
        if is_cache_valid(entry.get("timestamp", "")):
            return entry.get("analysis")
        else:
            # ë§Œë£Œëœ ìºì‹œ ì œê±°
            del cache[key]
            save_cache(cache)
            logger.info(f"Removed expired cache entry for {url}")

    return None


def cache_analysis(url: str, analysis: str) -> bool:
    """
    AI ë¶„ì„ ê²°ê³¼ ìºì‹±

    Args:
        url: ì›ë³¸ URL
        analysis: AI ë¶„ì„ ê²°ê³¼

    Returns:
        ìºì‹± ì„±ê³µ ì—¬ë¶€
    """
    cache = load_cache()
    key = get_cache_key(url)

    cache[key] = {
        "url": url,
        "analysis": analysis,
        "timestamp": datetime.now().isoformat(),
    }

    return save_cache(cache)


def clear_expired_cache() -> int:
    """
    ë§Œë£Œëœ ìºì‹œ í•­ëª© ì •ë¦¬

    Returns:
        ì‚­ì œëœ í•­ëª© ê°œìˆ˜
    """
    cache = load_cache()
    initial_size = len(cache)

    # ë§Œë£Œëœ í•­ëª© ì œê±°
    cache = {
        k: v
        for k, v in cache.items()
        if is_cache_valid(v.get("timestamp", ""))
    }

    if len(cache) < initial_size:
        save_cache(cache)
        removed = initial_size - len(cache)
        logger.info(f"Removed {removed} expired cache entries")
        return removed

    return 0


def get_cache_stats() -> Dict:
    """
    ìºì‹œ í†µê³„ ì¡°íšŒ

    Returns:
        ìºì‹œ í†µê³„ ì •ë³´
    """
    cache = load_cache()

    total_entries = len(cache)
    valid_entries = sum(
        1
        for v in cache.values()
        if is_cache_valid(v.get("timestamp", ""))
    )
    expired_entries = total_entries - valid_entries

    total_size = sum(
        len(v.get("analysis", "")) for v in cache.values()
    )

    return {
        "total_entries": total_entries,
        "valid_entries": valid_entries,
        "expired_entries": expired_entries,
        "total_size_chars": total_size,
        "ttl_days": TTL_DAYS,
    }


def print_cache_stats():
    """ìºì‹œ í†µê³„ ì¶œë ¥"""
    stats = get_cache_stats()
    print("\nğŸ“Š AI Cache Statistics")
    print(f"{'=' * 50}")
    print(f"Total entries: {stats['total_entries']}")
    print(f"Valid entries: {stats['valid_entries']}")
    print(f"Expired entries: {stats['expired_entries']}")
    print(f"Total size: {stats['total_size_chars']:,} chars")
    print(f"TTL: {stats['ttl_days']} days")
    print(f"{'=' * 50}\n")
