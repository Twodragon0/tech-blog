#!/usr/bin/env python3
"""
Vendor News Draft Generator - Î≥¥Ïïà Î≤§Îçî Î∏îÎ°úÍ∑∏ Í∏∞Î∞ò Ï¥àÏïà Ìè¨Ïä§ÌåÖ ÏÉùÏÑ±

Î≥¥Ïïà Î≤§ÎçîÎì§(Jamf, Zscaler, Cloudflare, Okta, Datadog Îì±)Ïùò Î∏îÎ°úÍ∑∏ÏóêÏÑú
ÏàòÏßëÌïú Îâ¥Ïä§Î•º Í∏∞Î∞òÏúºÎ°ú Î∏îÎ°úÍ∑∏ Ï¥àÏïàÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.

Usage:
    python3 scripts/generate_vendor_news_draft.py
    python3 scripts/generate_vendor_news_draft.py --vendors jamf,cloudflare,okta
    python3 scripts/generate_vendor_news_draft.py --hours 168 --max-items 20
"""

import argparse
import json
import re
import subprocess
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional

VENDOR_SOURCES = [
    "jamf",
    "zscaler",
    "zscaler_research",
    "cloudflare",
    "okta",
    "okta_security",
    "datadog",
    "datadog_security",
    "crowdstrike",
    "paloalto",
    "unit42",
    "snyk",
    "hashicorp",
    "wiz",
    "lacework",
    "sentinelone",
    "aquasec",
    "sysdig",
    "tenable",
    "rapid7",
    "splunk",
    "mandiant",
    "elastic_security",
]

VENDOR_CATEGORIES = {
    "endpoint": ["jamf", "crowdstrike", "sentinelone"],
    "network": ["zscaler", "zscaler_research", "cloudflare", "paloalto", "unit42"],
    "identity": ["okta", "okta_security"],
    "observability": ["datadog", "datadog_security", "splunk", "elastic_security"],
    "devsecops": ["snyk", "aquasec", "sysdig", "wiz", "lacework"],
    "infrastructure": ["hashicorp"],
    "threat_intel": ["mandiant", "tenable", "rapid7"],
}

CATEGORY_NAMES = {
    "endpoint": "ÏóîÎìúÌè¨Ïù∏Ìä∏ Î≥¥Ïïà",
    "network": "ÎÑ§Ìä∏ÏõåÌÅ¨/ÌÅ¥ÎùºÏö∞Îìú Î≥¥Ïïà",
    "identity": "ID Î∞è Ï†ëÍ∑º Í¥ÄÎ¶¨",
    "observability": "Í¥ÄÏ∏°ÏÑ± Î∞è SIEM",
    "devsecops": "DevSecOps Î∞è Ïª®ÌÖåÏù¥ÎÑà Î≥¥Ïïà",
    "infrastructure": "Ïù∏ÌîÑÎùº ÏûêÎèôÌôî",
    "threat_intel": "ÏúÑÌòë Ïù∏ÌÖîÎ¶¨Ï†ÑÏä§",
}


def collect_vendor_news(vendors: List[str], hours: int) -> Optional[dict]:
    script_dir = Path(__file__).parent
    collect_script = script_dir / "collect_tech_news.py"

    if not collect_script.exists():
        print(f"Error: {collect_script} not found")
        return None

    sources = ",".join(vendors)
    cmd = [
        sys.executable,
        str(collect_script),
        "--sources",
        sources,
        "--hours",
        str(hours),
    ]

    print(f"Collecting news from {len(vendors)} vendor sources...")
    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        print(f"Error collecting news: {result.stderr}")
        return None

    output_file = script_dir.parent / "_data" / "collected_news.json"
    if not output_file.exists():
        print(f"Error: Output file not found: {output_file}")
        return None

    with open(output_file, "r", encoding="utf-8") as f:
        return json.load(f)


def categorize_items(items: List[dict]) -> Dict[str, List[dict]]:
    categorized = {cat: [] for cat in VENDOR_CATEGORIES}

    for item in items:
        source = item.get("source", "")
        for category, sources in VENDOR_CATEGORIES.items():
            if source in sources:
                categorized[category].append(item)
                break

    return categorized


def generate_draft_content(items: List[dict], title: str, date_str: str) -> str:
    categorized = categorize_items(items)

    all_tags = set()
    vendors_mentioned = set()

    for item in items:
        all_tags.update(item.get("tags", []))
        source = item.get("source", "")
        if source:
            vendors_mentioned.add(source.replace("_", "-").title())

    tags = ["Security-Vendor-News", "DevSecOps", "Cloud-Security"]
    for vendor in list(vendors_mentioned)[:5]:
        clean_vendor = re.sub(r"[^a-zA-Z0-9-]", "", vendor)
        if clean_vendor:
            tags.append(clean_vendor)
    tags.append(datetime.now().strftime("%Y"))

    front_matter = f"""---
layout: post
title: "{title}"
date: {date_str}
categories: [security, devsecops]
tags: [{", ".join(tags)}]
excerpt: "Ï£ºÏöî Î≥¥Ïïà Î≤§ÎçîÎì§Ïùò ÏµúÏã† Î∏îÎ°úÍ∑∏ Ìè¨Ïä§ÌåÖ Î™®Ïùå. Jamf, Zscaler, Cloudflare, Okta, Datadog, CrowdStrike, Palo Alto Networks, Snyk Îì± Î≥¥Ïïà ÏóÖÍ≥Ñ ÎèôÌñ•Í≥º ÏúÑÌòë Ïù∏ÌÖîÎ¶¨Ï†ÑÏä§ ÏöîÏïΩ."
comments: true
toc: true
---

"""

    content = f"""## ÏÑúÎ°†

ÏïàÎÖïÌïòÏÑ∏Ïöî, **Twodragon**ÏûÖÎãàÎã§.

Ïù¥Î≤à Ìè¨Ïä§ÌåÖÏóêÏÑúÎäî Ï£ºÏöî Î≥¥Ïïà Î≤§ÎçîÎì§Ïùò ÏµúÏã† Î∏îÎ°úÍ∑∏ Ìè¨Ïä§ÌåÖÏùÑ Ï†ïÎ¶¨ÌñàÏäµÎãàÎã§. 
ÏóîÎìúÌè¨Ïù∏Ìä∏ Î≥¥Ïïà, ÎÑ§Ìä∏ÏõåÌÅ¨ Î≥¥Ïïà, ID Í¥ÄÎ¶¨, DevSecOps Îì± Îã§ÏñëÌïú Î∂ÑÏïºÏùò ÏµúÏã† ÎèôÌñ•ÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§.

**ÏàòÏßë Í∏∞Í∞Ñ**: ÏµúÍ∑º 7ÏùºÍ∞Ñ Î∞úÌñâÎêú Ìè¨Ïä§ÌåÖ
**ÏàòÏßë ÏÜåÏä§**: {len(vendors_mentioned)}Í∞ú Î≤§Îçî Î∏îÎ°úÍ∑∏

---

## üìä Îπ†Î•∏ Ï∞∏Ï°∞

| Î∂ÑÏïº | Ï£ºÏöî Î≤§Îçî | Ìè¨Ïä§ÌåÖ Ïàò |
|------|----------|----------|
"""

    for category, cat_items in categorized.items():
        if cat_items:
            vendor_list = ", ".join(
                [item.get("source_name", "").split()[0] for item in cat_items[:3]]
            )
            content += f"| **{CATEGORY_NAMES.get(category, category)}** | {vendor_list} | {len(cat_items)} |\n"

    content += "\n---\n\n"

    section_num = 1
    for category, cat_items in categorized.items():
        if not cat_items:
            continue

        content += f"## {section_num}. {CATEGORY_NAMES.get(category, category)}\n\n"

        for item in cat_items[:5]:
            title_text = item.get("title", "Untitled")
            url = item.get("url", "#")
            source_name = item.get("source_name", "Unknown")
            summary = item.get("summary", "")[:300]
            published = item.get("published", "")[:10]

            content += f"### {source_name}: {title_text}\n\n"
            content += f"- **URL**: [{url}]({url})\n"
            content += f"- **Î∞úÌñâÏùº**: {published}\n\n"

            if summary:
                content += f"> {summary}\n\n"

            content += "---\n\n"

        section_num += 1

    content += f"""## Í≤∞Î°†

Ïù¥Î≤à Ï£º Î≥¥Ïïà Î≤§ÎçîÎì§Ïùò Î∏îÎ°úÍ∑∏ÏóêÏÑú Ï£ºÎ™©Ìï† ÎßåÌïú Ï£ºÏ†úÎì§:

1. **ÏúÑÌòë ÎèôÌñ•**: ÏµúÏã† Í≥µÍ≤© Í∏∞Î≤ïÍ≥º ÏúÑÌòë Ïù∏ÌÖîÎ¶¨Ï†ÑÏä§
2. **Ï†úÌíà ÏóÖÎç∞Ïù¥Ìä∏**: Í∞Å Î≤§ÎçîÏùò ÏÉàÎ°úÏö¥ Í∏∞Îä•Í≥º Í∞úÏÑ† ÏÇ¨Ìï≠
3. **Î™®Î≤î ÏÇ¨Î°Ä**: Î≥¥Ïïà Ïö¥ÏòÅ Î∞è DevSecOps Î≤†Ïä§Ìä∏ ÌîÑÎûôÌã∞Ïä§
4. **Í∑úÏ†ï Ï§ÄÏàò**: Ïª¥ÌîåÎùºÏù¥Ïñ∏Ïä§ Í¥ÄÎ†® Í∞ÄÏù¥ÎìúÎùºÏù∏

Ï†ïÍ∏∞Ï†ÅÏù∏ Î≤§Îçî Î∏îÎ°úÍ∑∏ Î™®ÎãàÌÑ∞ÎßÅÏùÑ ÌÜµÌï¥ ÏµúÏã† Î≥¥Ïïà Ìä∏Î†åÎìúÎ•º ÌååÏïÖÌïòÏãúÍ∏∞ Î∞îÎûçÎãàÎã§.

---

## Ï∞∏Í≥† ÏûêÎ£å

| Î≤§Îçî | Î∏îÎ°úÍ∑∏ URL |
|------|------------|
| Jamf | [https://www.jamf.com/blog/](https://www.jamf.com/blog/) |
| Zscaler | [https://www.zscaler.com/blogs](https://www.zscaler.com/blogs) |
| Cloudflare | [https://blog.cloudflare.com/](https://blog.cloudflare.com/) |
| Okta | [https://www.okta.com/blog/](https://www.okta.com/blog/) |
| Datadog | [https://www.datadoghq.com/blog/](https://www.datadoghq.com/blog/) |
| CrowdStrike | [https://www.crowdstrike.com/blog/](https://www.crowdstrike.com/blog/) |
| Palo Alto Networks | [https://www.paloaltonetworks.com/blog/](https://www.paloaltonetworks.com/blog/) |
| Snyk | [https://snyk.io/blog/](https://snyk.io/blog/) |
"""

    return front_matter + content


def save_draft(content: str, filename: str, drafts_dir: Path) -> Path:
    drafts_dir.mkdir(parents=True, exist_ok=True)
    filepath = drafts_dir / filename

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)

    return filepath


def main():
    parser = argparse.ArgumentParser(description="Generate vendor news draft post")
    parser.add_argument(
        "--vendors",
        type=str,
        help=f"Comma-separated vendor sources (default: all). Available: {', '.join(VENDOR_SOURCES)}",
    )
    parser.add_argument(
        "--hours",
        type=int,
        default=168,
        help="Hours to look back (default: 168 = 7 days)",
    )
    parser.add_argument(
        "--max-items",
        type=int,
        default=30,
        help="Maximum items per draft (default: 30)",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="_drafts",
        help="Output directory for drafts (default: _drafts)",
    )
    parser.add_argument(
        "--list-vendors", action="store_true", help="List available vendor sources"
    )

    args = parser.parse_args()

    if args.list_vendors:
        print("\nAvailable vendor sources:\n")
        for category, sources in VENDOR_CATEGORIES.items():
            print(f"  {CATEGORY_NAMES.get(category, category)}:")
            for source in sources:
                print(f"    - {source}")
        return

    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    if args.vendors:
        vendors = [v.strip() for v in args.vendors.split(",")]
        invalid = [v for v in vendors if v not in VENDOR_SOURCES]
        if invalid:
            print(f"Error: Unknown vendors: {invalid}")
            print(f"Available: {VENDOR_SOURCES}")
            sys.exit(1)
    else:
        vendors = VENDOR_SOURCES

    news_data = collect_vendor_news(vendors, args.hours)

    if not news_data or not news_data.get("items"):
        print("No news items collected.")
        return

    items = news_data.get("items", [])[: args.max_items]
    print(f"\nProcessing {len(items)} items for draft generation...")

    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d %H:%M:%S +0900")
    date_prefix = now.strftime("%Y-%m-%d")

    title = f"Î≥¥Ïïà Î≤§Îçî Î∏îÎ°úÍ∑∏ Ï£ºÍ∞Ñ Î¶¨Î∑∞ ({now.strftime('%YÎÖÑ %mÏõî %dÏùº')})"
    filename = f"{date_prefix}-Security_Vendor_Blog_Weekly_Review.md"

    content = generate_draft_content(items, title, date_str)

    drafts_dir = project_root / args.output_dir
    filepath = save_draft(content, filename, drafts_dir)

    print(f"\n‚úÖ Draft generated: {filepath}")
    print(f"   - Total items: {len(items)}")
    print(f"   - Vendors: {len(vendors)}")
    print(f"\nTo publish, move to _posts/:")
    print(f"   mv {filepath} _posts/")


if __name__ == "__main__":
    main()
