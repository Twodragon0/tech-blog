#!/usr/bin/env python3
"""
í¬ìŠ¤íŒ… ìš”ì•½ ì„¹ì…˜ í˜•ì‹ í†µì¼ ë° ì¤‘ë³µ ì œê±° ìŠ¤í¬ë¦½íŠ¸
"""

import os
import re
from pathlib import Path
from typing import Dict, Optional

POSTS_DIR = Path(__file__).parent.parent / "_posts"

def extract_front_matter(file_path: Path) -> Dict:
    """Front matterì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    content = file_path.read_text(encoding='utf-8')
    
    front_matter_match = re.search(r'^---\n(.*?)\n---', content, re.DOTALL)
    front_matter = {}
    if front_matter_match:
        for line in front_matter_match.group(1).split('\n'):
            if ':' in line and not line.strip().startswith('#'):
                parts = line.split(':', 1)
                if len(parts) == 2:
                    key = parts[0].strip()
                    value = parts[1].strip().strip('"').strip("'")
                    front_matter[key] = value
    
    return front_matter

def parse_tags(tags_str: str) -> list:
    """íƒœê·¸ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not tags_str:
        return []
    
    # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì¸ ê²½ìš°
    if tags_str.startswith('['):
        tags = re.findall(r'\[(.*?)\]', tags_str)
        if tags:
            tags = tags[0].split(',')
            return [t.strip() for t in tags]
    
    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì¸ ê²½ìš°
    if ',' in tags_str:
        return [t.strip() for t in tags_str.split(',')]
    
    return [tags_str.strip()] if tags_str.strip() else []

def extract_core_content(excerpt: str, title: str) -> list:
    """excerptì—ì„œ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ (3-5ê°œ bullet points)"""
    core_points = []
    
    # excerptê°€ ì¶©ë¶„íˆ ê¸¸ë©´ ì—¬ëŸ¬ í¬ì¸íŠ¸ë¡œ ë¶„ë¦¬
    if len(excerpt) > 200:
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'[.!?]\s+', excerpt)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # í•µì‹¬ ë¬¸ì¥ ì„ íƒ (3-5ê°œ)
        for i, sentence in enumerate(sentences[:5]):
            if len(sentence) > 20:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
                core_points.append(sentence)
    else:
        # ì§§ì€ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
        core_points.append(excerpt)
    
    return core_points[:5]  # ìµœëŒ€ 5ê°œ

def extract_technologies(tags: list, title: str, category: str) -> list:
    """ì£¼ìš” ê¸°ìˆ /ë„êµ¬ ì¶”ì¶œ"""
    tech_list = []
    
    # íƒœê·¸ì—ì„œ ê¸°ìˆ  ê´€ë ¨ í•­ëª© ì¶”ì¶œ
    tech_keywords = ['AWS', 'Kubernetes', 'Docker', 'Terraform', 'GitHub', 
                     'Cloudflare', 'Datadog', 'Zscaler', 'Security', 'DevSecOps',
                     'FinOps', 'SIEM', 'WAF', 'IAM', 'VPC', 'GuardDuty']
    
    for tag in tags:
        for keyword in tech_keywords:
            if keyword.lower() in tag.lower():
                tech_list.append(keyword)
                break
    
    # ì œëª©ì—ì„œë„ ì¶”ì¶œ
    for keyword in tech_keywords:
        if keyword.lower() in title.lower() and keyword not in tech_list:
            tech_list.append(keyword)
    
    # ì¹´í…Œê³ ë¦¬ ì¶”ê°€
    if category and category not in tech_list:
        tech_list.append(category)
    
    return tech_list[:8] if tech_list else tags[:8]  # ìµœëŒ€ 8ê°œ

def get_target_audience(category: str, tags: list) -> str:
    """ëŒ€ìƒ ë…ì ê²°ì •"""
    audiences = {
        'security': 'ê¸°ì—… ë³´ì•ˆ ë‹´ë‹¹ì, ë³´ì•ˆ ì—”ì§€ë‹ˆì–´, CISO',
        'cloud': 'í´ë¼ìš°ë“œ ì•„í‚¤í…íŠ¸, DevOps ì—”ì§€ë‹ˆì–´, í´ë¼ìš°ë“œ ê´€ë¦¬ì',
        'devsecops': 'DevSecOps ì—”ì§€ë‹ˆì–´, ë³´ì•ˆ ì—”ì§€ë‹ˆì–´, ê°œë°œì',
        'finops': 'FinOps ì „ë¬¸ê°€, í´ë¼ìš°ë“œ ê´€ë¦¬ì, ì¬ë¬´ ë‹´ë‹¹ì',
        'incident': 'SRE, ì¸ì‹œë˜íŠ¸ ëŒ€ì‘ ë‹´ë‹¹ì, ìš´ì˜ ì—”ì§€ë‹ˆì–´'
    }
    
    category_lower = category.lower()
    for key, value in audiences.items():
        if key in category_lower:
            return value
    
    # ê¸°ë³¸ê°’
    return 'í´ë¼ìš°ë“œ ë³´ì•ˆ ì „ë¬¸ê°€, DevOps ì—”ì§€ë‹ˆì–´, ë³´ì•ˆ ë‹´ë‹¹ì'

def generate_standard_summary(front_matter: Dict) -> str:
    """í‘œì¤€ ìš”ì•½ ì„¹ì…˜ ìƒì„±"""
    title = front_matter.get('title', '').replace('&amp;', '&').replace('&lsquo;', "'").replace('&rsquo;', "'")
    category = front_matter.get('categories', front_matter.get('category', ''))
    tags_str = front_matter.get('tags', '')
    excerpt = front_matter.get('excerpt', '')
    
    # ì¹´í…Œê³ ë¦¬ ì •ë¦¬
    if isinstance(category, str) and category.startswith('['):
        category = re.findall(r'\[(.*?)\]', category)
        category = category[0] if category else ''
    
    # íƒœê·¸ íŒŒì‹±
    tags = parse_tags(tags_str)
    tags_display = ', '.join(tags) if tags else 'ì—†ìŒ'
    
    # í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
    core_points = extract_core_content(excerpt, title)
    if not core_points:
        core_points = [excerpt[:200] + '...' if len(excerpt) > 200 else excerpt]
    
    # í•µì‹¬ ë‚´ìš© í¬ë§·íŒ…
    core_content = '\n'.join([f"> - {point}" for point in core_points])
    
    # ì£¼ìš” ê¸°ìˆ /ë„êµ¬ ì¶”ì¶œ
    technologies = extract_technologies(tags, title, category)
    tech_display = ', '.join(technologies) if technologies else tags_display
    
    # ëŒ€ìƒ ë…ì
    audience = get_target_audience(category, tags)
    
    summary = f"""## ğŸ“‹ í¬ìŠ¤íŒ… ìš”ì•½

> **ì œëª©**: {title}

> **ì¹´í…Œê³ ë¦¬**: {category}

> **íƒœê·¸**: {tags_display}

> **í•µì‹¬ ë‚´ìš©**: 
{core_content}

> **ì£¼ìš” ê¸°ìˆ /ë„êµ¬**: {tech_display}

> **ëŒ€ìƒ ë…ì**: {audience}

> ---

> *ì´ í¬ìŠ¤íŒ…ì€ AI(Cursor, Claude ë“±)ê°€ ì‰½ê²Œ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ í¬í•¨í•©ë‹ˆë‹¤.*
"""
    
    return summary

def fix_summary_section(file_path: Path) -> bool:
    """ìš”ì•½ ì„¹ì…˜ ìˆ˜ì •"""
    try:
        content = file_path.read_text(encoding='utf-8')
        front_matter = extract_front_matter(file_path)
        
        if not front_matter:
            return False
        
        # ìš”ì•½ ì„¹ì…˜ ì°¾ê¸°
        summary_pattern = r'(## ğŸ“‹ í¬ìŠ¤íŒ… ìš”ì•½\n\n)(.*?)(\n\n## |\n\n## ì„œë¡ |\n\n## 1\.|\Z)'
        summary_match = re.search(summary_pattern, content, re.DOTALL)
        
        if not summary_match:
            # ìš”ì•½ ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì¶”ê°€
            front_matter_end = content.find('---\n', 4)  # ë‘ ë²ˆì§¸ --- ì°¾ê¸°
            if front_matter_end != -1:
                standard_summary = generate_standard_summary(front_matter)
                new_content = content[:front_matter_end+4] + '\n' + standard_summary + '\n' + content[front_matter_end+4:]
                file_path.write_text(new_content, encoding='utf-8')
                return True
            return False
        
        # ê¸°ì¡´ ìš”ì•½ ì„¹ì…˜ ì œê±°
        summary_start = summary_match.start()
        summary_end = summary_match.end(2)  # ìš”ì•½ ë‚´ìš© ë
        
        # í‘œì¤€ ìš”ì•½ ìƒì„±
        standard_summary = generate_standard_summary(front_matter)
        
        # ìš”ì•½ ì„¹ì…˜ êµì²´
        new_content = content[:summary_start] + standard_summary + content[summary_end:]
        
        # ì¤‘ë³µëœ ìš”ì•½ ì„¹ì…˜ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°)
        # "## ğŸ“‹ í¬ìŠ¤íŒ… ìš”ì•½"ì´ ë‘ ë²ˆ ì´ìƒ ë‚˜íƒ€ë‚˜ëŠ” ê²½ìš°
        summary_count = new_content.count('## ğŸ“‹ í¬ìŠ¤íŒ… ìš”ì•½')
        if summary_count > 1:
            # ì²« ë²ˆì§¸ ê²ƒë§Œ ìœ ì§€
            first_summary_end = new_content.find('*ì´ í¬ìŠ¤íŒ…ì€ AI', summary_start)
            if first_summary_end != -1:
                first_summary_end = new_content.find('\n', first_summary_end) + 1
                # ë‘ ë²ˆì§¸ ìš”ì•½ ì„¹ì…˜ ì°¾ê¸°
                second_summary_start = new_content.find('## ğŸ“‹ í¬ìŠ¤íŒ… ìš”ì•½', first_summary_end)
                if second_summary_start != -1:
                    # ë‘ ë²ˆì§¸ ìš”ì•½ ì„¹ì…˜ ì œê±°
                    second_summary_end = new_content.find('\n\n## ', second_summary_start)
                    if second_summary_end == -1:
                        second_summary_end = new_content.find('\n\n## ì„œë¡ ', second_summary_start)
                    if second_summary_end == -1:
                        second_summary_end = new_content.find('\n\n## 1.', second_summary_start)
                    if second_summary_end != -1:
                        new_content = new_content[:second_summary_start] + new_content[second_summary_end+2:]
        
        file_path.write_text(new_content, encoding='utf-8')
        return True
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ ({file_path.name}): {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    fixed_count = 0
    total_count = 0
    
    print("=" * 60)
    print("í¬ìŠ¤íŒ… ìš”ì•½ ì„¹ì…˜ í˜•ì‹ í†µì¼ ë° ì¤‘ë³µ ì œê±°")
    print("=" * 60)
    print()
    
    for post_file in sorted(POSTS_DIR.glob("*.md")):
        total_count += 1
        print(f"[{total_count}] ì²˜ë¦¬ ì¤‘: {post_file.name}")
        
        if fix_summary_section(post_file):
            fixed_count += 1
            print(f"  âœ“ ìˆ˜ì • ì™„ë£Œ")
        else:
            print(f"  - ìŠ¤í‚µ (ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ê±°ë‚˜ ì˜¤ë¥˜)")
    
    print()
    print("=" * 60)
    print(f"ì™„ë£Œ: {fixed_count}/{total_count}ê°œ í¬ìŠ¤íŒ… ìˆ˜ì •")
    print("=" * 60)

if __name__ == "__main__":
    main()
