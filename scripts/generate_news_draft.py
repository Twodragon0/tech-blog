#!/usr/bin/env python3
"""
Tech News Draft Generator - ë‰´ìŠ¤ ì´ˆì•ˆ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Enhanced Version)

ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ _posts ìˆ˜ì¤€ì˜ ê¹Šì´ ìˆëŠ” ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.
ë¡œì»¬ Claude/Cursorì™€ í•¨ê»˜ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

Usage:
    # 1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘
    python3 scripts/collect_tech_news.py --hours 24

    # 2ë‹¨ê³„: ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    python3 scripts/generate_news_draft.py --prepare --max-posts 3

    # 3ë‹¨ê³„: Claude/Cursorì—ì„œ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
    # _drafts/prompts/ í´ë”ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ Claudeì— ì „ë‹¬
    # ë˜ëŠ” ì§ì ‘ Claudeì—ê²Œ "ì´ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì½ê³  í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì¤˜" ìš”ì²­
"""

import argparse
import json
import os
import re
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional

import frontmatter
import requests
from bs4 import BeautifulSoup


# ============================================================================
# ì„¤ì •
# ============================================================================

CATEGORY_MAP = {
    "security": "security",
    "cloud": "cloud",
    "tech": "devops",
    "kubernetes": "kubernetes",
    "devops": "devops",
    "devsecops": "devsecops",
}

CATEGORY_EMOJI = {
    "security": "ğŸ”’",
    "cloud": "â˜ï¸",
    "devops": "âš™ï¸",
    "kubernetes": "ğŸš€",
    "devsecops": "ğŸ›¡ï¸",
    "incident": "ğŸš¨",
    "finops": "ğŸ’°",
}

TARGET_AUDIENCE = {
    "security": "ë³´ì•ˆ ì—”ì§€ë‹ˆì–´, DevSecOps ì—”ì§€ë‹ˆì–´, SOC ë¶„ì„ê°€",
    "cloud": "í´ë¼ìš°ë“œ ì•„í‚¤í…íŠ¸, SRE, DevOps ì—”ì§€ë‹ˆì–´",
    "devops": "DevOps ì—”ì§€ë‹ˆì–´, SRE, í”Œë«í¼ ì—”ì§€ë‹ˆì–´",
    "kubernetes": "ì¿ ë²„ë„¤í‹°ìŠ¤ ê´€ë¦¬ì, í”Œë«í¼ ì—”ì§€ë‹ˆì–´, SRE",
    "devsecops": "DevSecOps ì—”ì§€ë‹ˆì–´, ë³´ì•ˆ ì—”ì§€ë‹ˆì–´, ê°œë°œì",
}

CATEGORY_CONTEXT = {
    "security": """
ë³´ì•ˆ ë‰´ìŠ¤ëŠ” ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
- ê³µê²© ê¸°ë²• ë° TTP (Tactics, Techniques, Procedures)
- ì·¨ì•½ì  ìœ í˜• (CVE, CWE ë“±)
- ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œ/ì†Œí”„íŠ¸ì›¨ì–´
- IoC (Indicators of Compromise) ê°€ëŠ¥í•˜ë©´ í¬í•¨
- MITRE ATT&CK í”„ë ˆì„ì›Œí¬ ë§¤í•‘
- ë°©ì–´ ì „ëµ ë° íƒì§€ ë°©ë²•
- CISA, NIST ë“± ê³µì‹ ê°€ì´ë“œë¼ì¸ ì°¸ì¡°
""",
    "cloud": """
í´ë¼ìš°ë“œ ë‰´ìŠ¤ëŠ” ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
- AWS/GCP/Azure íŠ¹ì • ì„œë¹„ìŠ¤ ê´€ë ¨ì„±
- ì•„í‚¤í…ì²˜ ë³€ê²½ ì‚¬í•­
- ë¹„ìš© ì˜í–¥ (FinOps ê´€ì )
- ë³´ì•ˆ ì˜í–¥ (Shared Responsibility Model)
- ë§ˆì´ê·¸ë ˆì´ì…˜ ê³ ë ¤ì‚¬í•­
- Well-Architected Framework ê´€ì 
""",
    "kubernetes": """
ì¿ ë²„ë„¤í‹°ìŠ¤ ë‰´ìŠ¤ëŠ” ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
- K8s ë²„ì „ í˜¸í™˜ì„±
- CRD, Operator ê´€ë ¨ ë³€ê²½
- ë„¤íŠ¸ì›Œí¬ ì •ì±… ì˜í–¥
- RBAC ë° ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸
- Helm ì°¨íŠ¸ ì—…ë°ì´íŠ¸ í•„ìš”ì„±
- GitOps ì›Œí¬í”Œë¡œìš° ì˜í–¥
""",
    "devops": """
DevOps ë‰´ìŠ¤ëŠ” ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
- CI/CD íŒŒì´í”„ë¼ì¸ ì˜í–¥
- IaC (Infrastructure as Code) ê´€ë ¨ì„±
- ìë™í™” ê¸°íšŒ
- ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±
- SRE ì‹¤ë¬´ ì ìš©ì 
- ê°œë°œ ìƒì‚°ì„± í–¥ìƒ ë°©ì•ˆ
""",
}


# ============================================================================
# ì›ë¬¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
# ============================================================================


def fetch_original_content(url: str) -> str:
    """ì›ë¬¸ URLì—ì„œ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, "html.parser")

        # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°
        for tag in soup(
            ["script", "style", "nav", "footer", "header", "aside", "iframe", "ad"]
        ):
            tag.decompose()

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = soup.get_text(separator="\n")
        text = re.sub(r"\n{3,}", "\n\n", text)
        text = re.sub(r" {2,}", " ", text)

        return text[:8000].strip()
    except Exception as e:
        print(f"    Warning: Could not fetch content: {e}")
        return ""


# ============================================================================
# ê´€ë ¨ í¬ìŠ¤íŠ¸ ì°¾ê¸°
# ============================================================================


def find_related_posts(news_item: dict, posts_dir: Path) -> List[dict]:
    """ê¸°ì¡´ í¬ìŠ¤íŠ¸ ì¤‘ ê´€ë ¨ëœ ê²ƒ ì°¾ê¸°"""
    related = []
    category = news_item.get("category", "")
    title_words = set(news_item.get("title", "").lower().split())

    try:
        for post_file in sorted(posts_dir.glob("*.md"), reverse=True)[:100]:
            try:
                with open(post_file, 'r', encoding='utf-8') as f:
                    post = frontmatter.load(f)
                post_category = str(post.get("category", ""))
                raw_tags = post.get("tags", [])
                post_tags = [str(t).lower() for t in (raw_tags if isinstance(raw_tags, list) else []) if t]
                post_title = str(post.get("title", ""))
                post_excerpt = str(post.get("excerpt", ""))

                # ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë˜ëŠ” í‚¤ì›Œë“œ ì¼ì¹˜
                score = 0
                if post_category == category:
                    score += 2

                # íƒœê·¸ ì¼ì¹˜
                news_tags = [t.lower() for t in news_item.get("tags", [])]
                matching_tags = set(post_tags) & set(news_tags)
                score += len(matching_tags)

                # ì œëª© ë‹¨ì–´ ì¼ì¹˜
                post_title_words = set(post_title.lower().split())
                matching_words = title_words & post_title_words
                score += len(matching_words) * 0.5

                if score >= 1:
                    tags_raw = post.get("tags", [])
                    tags_slice = post_tags[:5] if post_tags else []
                    related.append(
                        {
                            "title": post_title,
                            "file": post_file.name,
                            "category": post_category,
                            "tags": tags_slice,
                            "excerpt": post_excerpt[:200] if post_excerpt else "",
                            "score": score,
                        }
                    )
            except:
                continue
    except:
        pass

    # ì ìˆ˜ìˆœ ì •ë ¬
    related.sort(key=lambda x: x.get("score", 0), reverse=True)
    return related[:5]


# ============================================================================
# ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (Claude/Cursorìš©)
# ============================================================================


def generate_detailed_prompt(
    news_item: dict, original_content: str, related_posts: List[dict]
) -> str:
    """Claude/Cursorìš© ìƒì„¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

    category = news_item.get("category", "tech")
    blog_category = CATEGORY_MAP.get(category, "devops")
    audience = TARGET_AUDIENCE.get(category, "IT ì‹¤ë¬´ì")
    category_context = CATEGORY_CONTEXT.get(category, "")
    emoji = CATEGORY_EMOJI.get(blog_category, "ğŸ“°")

    # ê´€ë ¨ í¬ìŠ¤íŠ¸ ì •ë³´
    related_info = ""
    if related_posts:
        related_info = """
### ğŸ”— ê´€ë ¨ ê¸°ì¡´ í¬ìŠ¤íŠ¸ (ì—°ê´€ì„± ë¶„ì„ ë° ì°¸ì¡°ìš©)

ë‹¤ìŒ ê¸°ì¡´ í¬ìŠ¤íŠ¸ë“¤ê³¼ì˜ ì—°ê´€ì„±ì„ ë¶„ì„í•˜ê³ , ì ì ˆíˆ ì°¸ì¡°í•˜ê±°ë‚˜ ë§í¬ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:

"""
        for i, post in enumerate(related_posts, 1):
            related_info += f"""**{i}. {post["title"]}**
- íŒŒì¼: `{post["file"]}`
- ì¹´í…Œê³ ë¦¬: {post["category"]}
- íƒœê·¸: {", ".join(post["tags"])}
- ìš”ì•½: {post["excerpt"][:150]}...

"""

    prompt = f"""# ğŸ“ ê¸°ìˆ  ë‰´ìŠ¤ ì‹¬ì¸µ ë¶„ì„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„± ìš”ì²­

ë‹¹ì‹ ì€ **Twodragonì˜ Tech Blog**ì˜ DevSecOps ì „ë¬¸ ê¸°ìˆ  ë¸”ë¡œê±°ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ **_posts í´ë”ì˜ ê¸°ì¡´ í¬ìŠ¤íŠ¸ ìˆ˜ì¤€**ì˜ ê¹Šì´ ìˆëŠ” í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

---

## ğŸ“° ë‰´ìŠ¤ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì œëª©** | {news_item["title"]} |
| **ì›ë¬¸ URL** | {news_item["url"]} |
| **ì¶œì²˜** | {news_item["source_name"]} |
| **ì¹´í…Œê³ ë¦¬** | {category} â†’ ë¸”ë¡œê·¸ ì¹´í…Œê³ ë¦¬: `{blog_category}` |
| **ë°œí–‰ì¼** | {news_item.get("published", "N/A")[:10]} |
| **ëŒ€ìƒ ë…ì** | {audience} |

### ì›ë¬¸ ìš”ì•½
{news_item.get("summary", "ìš”ì•½ ì—†ìŒ")}

### ì›ë¬¸ ë‚´ìš© (ë°œì·Œ)
```
{original_content[:5000] if original_content else "ì›ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìœ„ URLì„ ì§ì ‘ ë°©ë¬¸í•˜ì—¬ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”."}
```
{related_info}

---

## ğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ê°€ì´ë“œ

{category_context if category_context else "ì¼ë°˜ì ì¸ ê¸°ìˆ  ë¶„ì„ ê´€ì ì—ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”."}

---

## ğŸ¯ ì‘ì„± ìš”êµ¬ì‚¬í•­ (ë§¤ìš° ì¤‘ìš”!)

### ë¶„ëŸ‰ ìš”êµ¬ì‚¬í•­
- **ìµœì†Œ 3000ì ì´ìƒ** (ì½”ë“œ ì œì™¸)
- **í…Œì´ë¸” ìµœì†Œ 3ê°œ ì´ìƒ** (ë¹ ë¥¸ ì°¸ì¡°, ë¹„êµ ë¶„ì„, ëŒ€ì‘ ë°©ì•ˆ ë“±)
- **ì½”ë“œ ì˜ˆì‹œ ìµœì†Œ 2ê°œ ì´ìƒ** (ì‹¤ì œ ë™ì‘í•˜ëŠ” ì½”ë“œ)
- **ì²´í¬ë¦¬ìŠ¤íŠ¸ 1ê°œ ì´ìƒ** (ì‹¤ë¬´ í™œìš©)

### ì½˜í…ì¸  í’ˆì§ˆ ìš”êµ¬ì‚¬í•­
1. **ì‹¬ì¸µ ë¶„ì„**: ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ, ê¸°ìˆ ì  ê¹Šì´ ìˆëŠ” ë¶„ì„
2. **ì‹¤ë¬´ ê´€ì **: ì‹¤ì œ ì—…ë¬´ì— ì–´ë–»ê²Œ ì ìš©í• ì§€ êµ¬ì²´ì  ê°€ì´ë“œ
3. **ë§¥ë½ ì œê³µ**: ì´ ë‰´ìŠ¤ê°€ ë‚˜ì˜¨ ë°°ê²½, ì—…ê³„ ë™í–¥ê³¼ì˜ ì—°ê´€ì„±
4. **ë¹„íŒì  ì‹œê°**: ì¥ë‹¨ì , ì£¼ì˜ì‚¬í•­, í•œê³„ì  ë¶„ì„
5. **ì•¡ì…˜ ì•„ì´í…œ**: ë…ìê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì¡°ì¹˜

---

## ğŸ“„ í¬ìŠ¤íŠ¸ êµ¬ì¡° (ì´ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”)

```markdown
---
layout: post
title: "í•œêµ­ì–´ ì œëª© (ì›ë¬¸ì˜ í•µì‹¬ì„ ì‚´ë¦° ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­, 50ì ì´ë‚´)"
date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} +0900
category: {blog_category}
categories: [{blog_category}]
tags: [íƒœê·¸1, íƒœê·¸2, íƒœê·¸3, íƒœê·¸4, íƒœê·¸5, íƒœê·¸6]
excerpt: "ì´ í¬ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹´ì€ SEO ìµœì í™” ìš”ì•½ (150-200ì)"
original_url: {news_item["url"]}
original_source: {news_item["source_name"]}
comments: true
toc: true
---

[ì•„ë˜ AI ìš”ì•½ ì¹´ë“œ HTMLì„ ì—¬ê¸°ì— ì‚½ì…]

## ì„œë¡ 

ì•ˆë…•í•˜ì„¸ìš”, **Twodragon**ì…ë‹ˆë‹¤.

[ì´ ë‰´ìŠ¤ì˜ ì¤‘ìš”ì„±, ì™œ ì£¼ëª©í•´ì•¼ í•˜ëŠ”ì§€, ì—…ê³„ ë§¥ë½ì—ì„œì˜ ì˜ë¯¸ ì„¤ëª…]
[ìµœê·¼ ê´€ë ¨ ë™í–¥ê³¼ ì—°ê²°]
[ì´ í¬ìŠ¤íŠ¸ì—ì„œ ë‹¤ë£° ë‚´ìš© ì˜ˆê³ ]

## ğŸ“Š ë¹ ë¥¸ ì°¸ì¡°

### í•µì‹¬ ìš”ì•½

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì£¼ìš” ë‚´ìš©** | [í•µì‹¬ ë‚´ìš© 1ì¤„ ìš”ì•½] |
| **ì˜í–¥ ë²”ìœ„** | [ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œ/ì„œë¹„ìŠ¤/ì‚¬ìš©ì] |
| **ì‹¬ê°ë„** | [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ + ì´ìœ ] |
| **ì¦‰ì‹œ ì¡°ì¹˜** | [í•„ìš”/ê¶Œì¥/ë¶ˆí•„ìš”] |
| **ê´€ë ¨ ê¸°ìˆ ** | [ê´€ë ¨ ê¸°ìˆ  ìŠ¤íƒ] |

### [ì¶”ê°€ ë¹„êµ/ë¶„ì„ í…Œì´ë¸”]

| ë¹„êµ í•­ëª© | ì´ì „ | ì´í›„/í˜„ì¬ | ì˜í–¥ |
|----------|------|----------|------|
| ... | ... | ... | ... |

## 1. ê°œìš”

### 1.1 ë°°ê²½ ë° ë§¥ë½

[ì´ ë‰´ìŠ¤ê°€ ë‚˜ì˜¨ ë°°ê²½]
[ê´€ë ¨ ì—…ê³„ ë™í–¥]
[ì´ì „ ì‚¬ê±´/ë°œí‘œì™€ì˜ ì—°ê´€ì„±]

### 1.2 í•µì‹¬ ë‚´ìš© ë¶„ì„

[ë‰´ìŠ¤ì˜ í•µì‹¬ ë‚´ìš©ì„ ìƒì„¸íˆ ë¶„ì„]
[ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­]
[ê´€ë ¨ ìˆ˜ì¹˜/ë°ì´í„° ë¶„ì„]

## 2. ê¸°ìˆ ì  ë¶„ì„

### 2.1 ì£¼ìš” ê¸°ìˆ  ìš”ì†Œ

[í•µì‹¬ ê¸°ìˆ  ê°œë… ì„¤ëª…]
[ì•„í‚¤í…ì²˜/êµ¬ì¡° ë¶„ì„]

| ê¸°ìˆ  ìš”ì†Œ | ì„¤ëª… | ì¤‘ìš”ë„ |
|----------|------|--------|
| ... | ... | ... |

### 2.2 êµ¬í˜„/ì½”ë“œ ì˜ˆì‹œ

[ì‹¤ì œ ì ìš© ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì‹œ]

```bash
# ì˜ˆì‹œ: ê´€ë ¨ ëª…ë ¹ì–´ë‚˜ ìŠ¤í¬ë¦½íŠ¸
# ì‹¤ì œ ë™ì‘í•˜ëŠ” ì½”ë“œë¡œ ì‘ì„±
```

```python
# ì˜ˆì‹œ: Python ì½”ë“œ (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
# ì‹¤ì œ ë™ì‘í•˜ëŠ” ì½”ë“œë¡œ ì‘ì„±
```

### 2.3 ì•„í‚¤í…ì²˜/í”Œë¡œìš°

[ê´€ë ¨ ì•„í‚¤í…ì²˜ë‚˜ í”Œë¡œìš° ì„¤ëª…]
[ê°€ëŠ¥í•˜ë©´ ë‹¤ì´ì–´ê·¸ë¨ ì„¤ëª…]

## 3. ì‹¤ë¬´ ì˜í–¥

### 3.1 ì˜í–¥ ë²”ìœ„

[ëˆ„ê°€ ì˜í–¥ì„ ë°›ëŠ”ì§€]
[ì–´ë–¤ ì‹œìŠ¤í…œ/ì„œë¹„ìŠ¤ê°€ ì˜í–¥ì„ ë°›ëŠ”ì§€]
[ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥]

### 3.2 ì£¼ì˜ ì‚¬í•­

| êµ¬ë¶„ | ë‚´ìš© | ìš°ì„ ìˆœìœ„ |
|------|------|----------|
| [ì£¼ì˜ì‚¬í•­1] | [ìƒì„¸ ë‚´ìš©] | ğŸ”´ ë†’ìŒ |
| [ì£¼ì˜ì‚¬í•­2] | [ìƒì„¸ ë‚´ìš©] | ğŸŸ¡ ì¤‘ê°„ |
| [ì£¼ì˜ì‚¬í•­3] | [ìƒì„¸ ë‚´ìš©] | ğŸŸ¢ ë‚®ìŒ |

## 4. ëŒ€ì‘ ë°©ì•ˆ

### 4.1 ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­

| ìš°ì„ ìˆœìœ„ | ì¡°ì¹˜ í•­ëª© | ë‹´ë‹¹ | ì˜ˆìƒ ì†Œìš” |
|---------|----------|------|----------|
| ğŸ”´ Critical | [ì¡°ì¹˜1] | [ë‹´ë‹¹íŒ€] | [ì‹œê°„] |
| ğŸŸ¡ High | [ì¡°ì¹˜2] | [ë‹´ë‹¹íŒ€] | [ì‹œê°„] |
| ğŸŸ¢ Medium | [ì¡°ì¹˜3] | [ë‹´ë‹¹íŒ€] | [ì‹œê°„] |

### 4.2 ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] [ì²´í¬í•­ëª© 1: êµ¬ì²´ì ì¸ ì•¡ì…˜]
- [ ] [ì²´í¬í•­ëª© 2: êµ¬ì²´ì ì¸ ì•¡ì…˜]
- [ ] [ì²´í¬í•­ëª© 3: êµ¬ì²´ì ì¸ ì•¡ì…˜]
- [ ] [ì²´í¬í•­ëª© 4: êµ¬ì²´ì ì¸ ì•¡ì…˜]
- [ ] [ì²´í¬í•­ëª© 5: êµ¬ì²´ì ì¸ ì•¡ì…˜]

### 4.3 ì¥ê¸° ëŒ€ì‘ ì „ëµ

[ì¥ê¸°ì ì¸ ê´€ì ì—ì„œì˜ ëŒ€ì‘ ë°©ì•ˆ]
[í”„ë¡œì„¸ìŠ¤ ê°œì„  ì œì•ˆ]
[ëª¨ë‹ˆí„°ë§/ìë™í™” ë°©ì•ˆ]

## 5. ê´€ë ¨ ë¦¬ì†ŒìŠ¤

### 5.1 ê³µì‹ ë¬¸ì„œ ë° ë ˆí¼ëŸ°ìŠ¤

- [ì›ë¬¸: {news_item["title"]}]({news_item["url"]})
- [ê´€ë ¨ ê³µì‹ ë¬¸ì„œ 1](URL) - ì„¤ëª…
- [ê´€ë ¨ ê³µì‹ ë¬¸ì„œ 2](URL) - ì„¤ëª…

### 5.2 ê´€ë ¨ ë„êµ¬ ë° GitHub ì €ì¥ì†Œ

| ë„êµ¬/ì €ì¥ì†Œ | ìš©ë„ | ë§í¬ |
|------------|------|------|
| [ë„êµ¬ëª…] | [ìš©ë„ ì„¤ëª…] | [GitHub URL] |

### 5.3 ì¶”ê°€ í•™ìŠµ ìë£Œ

- [ê´€ë ¨ ê°•ì˜/íŠœí† ë¦¬ì–¼]
- [ê´€ë ¨ ì„œì /ë¬¸ì„œ]

## ê²°ë¡ 

[ì´ ë‰´ìŠ¤ì˜ í•µì‹¬ ì‹œì‚¬ì  ìš”ì•½]
[ì‹¤ë¬´ìì—ê²Œ ì£¼ëŠ” ì˜ë¯¸]
[í–¥í›„ ì „ë§ ë° ì£¼ì‹œí•´ì•¼ í•  ë¶€ë¶„]
[ë§ˆë¬´ë¦¬ ë©˜íŠ¸]

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {datetime.now().strftime("%Y-%m-%d")}
```

---

## ğŸ¨ AI ìš”ì•½ ì¹´ë“œ HTML (ë³¸ë¬¸ ì‹œì‘ ë¶€ë¶„ì— ì‚½ì…)

```html
<div class="ai-summary-card">
<div class="ai-summary-header">
  <span class="ai-badge">AI ìš”ì•½</span>
</div>
<div class="ai-summary-content">
  <div class="summary-row">
    <span class="summary-label">ì œëª©</span>
    <span class="summary-value">[í•œêµ­ì–´ ì œëª©]</span>
  </div>
  <div class="summary-row">
    <span class="summary-label">ì¹´í…Œê³ ë¦¬</span>
    <span class="summary-value"><span class="category-tag {blog_category}">{blog_category.capitalize()}</span></span>
  </div>
  <div class="summary-row">
    <span class="summary-label">íƒœê·¸</span>
    <span class="summary-value tags">
      <span class="tag">[íƒœê·¸1]</span>
      <span class="tag">[íƒœê·¸2]</span>
      <span class="tag">[íƒœê·¸3]</span>
      <span class="tag">[íƒœê·¸4]</span>
      <span class="tag">[íƒœê·¸5]</span>
    </span>
  </div>
  <div class="summary-row highlights">
    <span class="summary-label">í•µì‹¬ ë‚´ìš©</span>
    <ul class="summary-list">
      <li><strong>[í•µì‹¬1 ì œëª©]</strong>: [í•µì‹¬1 ë‚´ìš© ì„¤ëª…]</li>
      <li><strong>[í•µì‹¬2 ì œëª©]</strong>: [í•µì‹¬2 ë‚´ìš© ì„¤ëª…]</li>
      <li><strong>[í•µì‹¬3 ì œëª©]</strong>: [í•µì‹¬3 ë‚´ìš© ì„¤ëª…]</li>
    </ul>
  </div>
  <div class="summary-row">
    <span class="summary-label">ê¸°ìˆ /ë„êµ¬</span>
    <span class="summary-value">[ê´€ë ¨ ê¸°ìˆ  ë° ë„êµ¬ ë‚˜ì—´]</span>
  </div>
  <div class="summary-row">
    <span class="summary-label">ëŒ€ìƒ ë…ì</span>
    <span class="summary-value">{audience}</span>
  </div>
</div>
<div class="ai-summary-footer">
  ì´ í¬ìŠ¤íŒ…ì€ AIê°€ ì‰½ê²Œ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ í¬í•¨í•©ë‹ˆë‹¤.
</div>
</div>
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì‹¤ì œ ì¡´ì¬í•˜ëŠ” URLë§Œ ì‚¬ìš©**: ê°€ì§œ URL ì ˆëŒ€ ê¸ˆì§€, í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ìƒëµ
2. **ì½”ë“œëŠ” ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•¨**: ë¬¸ë²• ì˜¤ë¥˜ ì—†ëŠ” ì‹¤ì œ ë™ì‘ ì½”ë“œ
3. **í•œêµ­ì–´ë¡œ ì‘ì„±**: ê¸°ìˆ  ìš©ì–´ëŠ” ì˜ì–´ ë³‘ê¸° ê°€ëŠ¥ (ì˜ˆ: ì¿ ë²„ë„¤í‹°ìŠ¤ (Kubernetes))
4. **ì´ëª¨ì§€ëŠ” ì„¹ì…˜ ì œëª©ì—ë§Œ**: ë³¸ë¬¸ì—ëŠ” ì´ëª¨ì§€ ìµœì†Œí™”
5. **ì¶”ì¸¡ ê¸ˆì§€**: í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ "ì¶”ê°€ í™•ì¸ í•„ìš”" ëª…ì‹œ
6. **ì €ì‘ê¶Œ ì£¼ì˜**: ì›ë¬¸ ì§ì ‘ ì¸ìš©ì€ ìµœì†Œí™”, ë¶„ì„/ì¬í•´ì„ ì¤‘ì‹¬

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

í¬ìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ í›„ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] ë¶„ëŸ‰ì´ 3000ì ì´ìƒì¸ê°€?
- [ ] í…Œì´ë¸”ì´ 3ê°œ ì´ìƒ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- [ ] ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì‹œê°€ 2ê°œ ì´ìƒì¸ê°€?
- [ ] ì²´í¬ë¦¬ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- [ ] AI ìš”ì•½ ì¹´ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ì„±ë˜ì—ˆëŠ”ê°€?
- [ ] ëª¨ë“  ë§í¬ê°€ ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] í•œêµ­ì–´ê°€ ìì—°ìŠ¤ëŸ¬ìš´ê°€?
- [ ] Front matterê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ê°€?

---

ìœ„ ìš”êµ¬ì‚¬í•­ì— ë§ì¶° **ì™„ì „í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸**ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
Front matterë¶€í„° ê²°ë¡ ê¹Œì§€ ì „ì²´ë¥¼ ì‘ì„±í•˜ë©°, ê¸°ì¡´ _posts í´ë”ì˜ í¬ìŠ¤íŠ¸ë“¤ê³¼ ë™ì¼í•œ í’ˆì§ˆ ìˆ˜ì¤€ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.
"""
    return prompt


def generate_filename(title: str, date: datetime) -> str:
    """ì˜ë¬¸ íŒŒì¼ëª… ìƒì„±"""
    english_title = re.sub(r"[^a-zA-Z0-9\s-]", "", title)
    english_title = re.sub(r"\s+", "_", english_title.strip())

    if len(english_title) > 80:
        english_title = english_title[:80].rsplit("_", 1)[0]

    if not english_title:
        english_title = "Tech_News"

    date_str = date.strftime("%Y-%m-%d")
    return f"{date_str}-{english_title}.md"


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================


def main():
    parser = argparse.ArgumentParser(
        description="Tech News Draft Generator (Enhanced Version)"
    )
    parser.add_argument(
        "--input",
        type=str,
        default="_data/collected_news.json",
        help="Input JSON file with collected news",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="_drafts",
        help="Output directory for draft posts",
    )
    parser.add_argument(
        "--max-posts",
        type=int,
        default=3,
        help="Maximum number of posts to generate (default: 3)",
    )
    parser.add_argument(
        "--category",
        type=str,
        help="Filter by category (security, cloud, tech, kubernetes, devops)",
    )
    parser.add_argument(
        "--prepare",
        action="store_true",
        help="Generate detailed prompts for Claude/Cursor analysis",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be generated without saving",
    )

    args = parser.parse_args()

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    input_path = project_root / args.input
    if not input_path.exists():
        print(f"Error: Input file not found: {input_path}")
        print("Run 'python3 scripts/collect_tech_news.py' first.")
        sys.exit(1)

    # ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    items = data.get("items", [])
    print(f"\nğŸ“° Loaded {len(items)} news items")

    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    if args.category:
        items = [item for item in items if item["category"] == args.category]
        print(f"   Filtered to {len(items)} items in category '{args.category}'")

    # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
    items = items[: args.max_posts]

    if not items:
        print("No items to process.")
        return

    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = project_root / args.output_dir
    prompts_dir = output_dir / "prompts"
    posts_dir = project_root / "_posts"

    print(f"\nğŸ”§ Mode: Generating detailed prompts for Claude/Cursor")
    print(f"ğŸ“ Output: {prompts_dir}")
    print(f"{'=' * 60}\n")

    generated = []
    processed_ids = []

    # SSL ê²½ê³  ë¬´ì‹œ
    import urllib3

    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    for i, item in enumerate(items, 1):
        print(f"[{i}/{len(items)}] {item['title'][:55]}...")

        # ì›ë¬¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
        print("    ğŸ“¥ Fetching original content...")
        original_content = fetch_original_content(item["url"])
        if original_content:
            print(f"    âœ… Fetched {len(original_content)} chars")
        else:
            print(f"    âš ï¸ Could not fetch content (will use summary only)")

        # ê´€ë ¨ í¬ìŠ¤íŠ¸ ì°¾ê¸°
        related_posts = find_related_posts(item, posts_dir)
        if related_posts:
            print(f"    ğŸ”— Found {len(related_posts)} related posts")
            for rp in related_posts[:3]:
                print(f"       - {rp['title'][:40]}...")

        # ë‚ ì§œ
        try:
            pub_date = datetime.fromisoformat(item["published"].replace("Z", "+00:00"))
        except:
            pub_date = datetime.now(timezone.utc)

        # íŒŒì¼ëª… ìƒì„±
        filename = generate_filename(item["title"], pub_date)

        # ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = generate_detailed_prompt(item, original_content, related_posts)

        if args.dry_run:
            print(
                f"    Would create prompt: prompts/{filename.replace('.md', '_prompt.md')}"
            )
            print(f"    Prompt length: {len(prompt)} chars")
        else:
            prompts_dir.mkdir(parents=True, exist_ok=True)
            prompt_file = prompts_dir / filename.replace(".md", "_prompt.md")
            with open(prompt_file, "w", encoding="utf-8") as f:
                f.write(prompt)
            print(f"    âœ… Created: prompts/{prompt_file.name} ({len(prompt)} chars)")
            generated.append(prompt_file)

        processed_ids.append(item["id"])
        print()

    # ì²˜ë¦¬ëœ ID ì €ì¥
    if not args.dry_run and processed_ids:
        processed_file = project_root / "_data" / "processed_news_ids.json"
        existing_ids = set()

        if processed_file.exists():
            with open(processed_file, "r", encoding="utf-8") as f:
                existing_ids = set(json.load(f))

        existing_ids.update(processed_ids)

        processed_file.parent.mkdir(parents=True, exist_ok=True)
        with open(processed_file, "w", encoding="utf-8") as f:
            json.dump(list(existing_ids), f)

    # ê²°ê³¼ ìš”ì•½
    print(f"{'=' * 60}")
    print("ğŸ“Š Summary")
    print(f"{'=' * 60}")
    print(f"Processed: {len(items)} news items")

    if not args.dry_run and generated:
        print(f"Generated: {len(generated)} prompt files")
        print(f"\nğŸ“ Prompt files saved to: {prompts_dir}/")
        print()
        print("ğŸš€ Next Steps:")
        print("â”€" * 40)
        print("1. Open a prompt file in _drafts/prompts/")
        print("2. Copy the entire content")
        print("3. Paste it to Claude/Cursor and ask to generate the post")
        print("4. Save Claude's output as a .md file in _drafts/")
        print("5. Review and move to _posts/ when ready")
        print()
        print("ğŸ’¡ Or directly tell Claude:")
        print(f'   "Read {prompts_dir}/<filename>_prompt.md and write the blog post"')


if __name__ == "__main__":
    main()
