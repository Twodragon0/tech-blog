#!/usr/bin/env python3
"""
Tistory ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ì„œ ë¡œì»¬ì— ì €ì¥í•˜ê³  í¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import re
import sys
import time
import requests
from pathlib import Path
from urllib.parse import urlparse, urljoin, unquote
from typing import Optional, List, Tuple
import urllib3

# SSL ê²½ê³  ë¹„í™œì„±í™” (ì¼ë¶€ í™˜ê²½ì—ì„œ ì¸ì¦ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

try:
    from bs4 import BeautifulSoup
except ImportError:
    print("âŒ beautifulsoup4ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜ ë°©ë²•: pip3 install --break-system-packages beautifulsoup4 lxml")
    sys.exit(1)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
PROJECT_ROOT = Path(__file__).parent.parent
POSTS_DIR = PROJECT_ROOT / "_posts"
IMAGES_DIR = PROJECT_ROOT / "assets" / "images"

# User-Agent ì„¤ì • (ë´‡ ì°¨ë‹¨ ë°©ì§€)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def extract_images_from_tistory(url: str) -> List[str]:
    """
    Tistory ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        url: Tistory ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ URL
        
    Returns:
        ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
    """
    try:
        print(f"  ğŸ“¥ Fetching: {url}")
        # SSL ê²€ì¦ ê²½ê³  ë¬´ì‹œ (ì¼ë¶€ í™˜ê²½ì—ì„œ ì¸ì¦ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥)
        response = requests.get(url, headers=HEADERS, timeout=30, verify=False)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        image_urls = []
        
        # Tistory ì´ë¯¸ì§€ URL íŒ¨í„´ ì°¾ê¸°
        # 1. img íƒœê·¸ì˜ src ì†ì„±
        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src')
            if src:
                # Tistory CDN ì´ë¯¸ì§€ URL í™•ì¸
                if 'blog.kakaocdn.net' in src or 'img1.daumcdn.net' in src:
                    # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                    if src.startswith('//'):
                        src = 'https:' + src
                    elif src.startswith('/'):
                        src = urljoin(url, src)
                    image_urls.append(src)
        
        # 2. ë©”íƒ€ íƒœê·¸ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸° (og:image ë“±)
        for meta in soup.find_all('meta', property=re.compile(r'og:image')):
            content = meta.get('content')
            if content and ('blog.kakaocdn.net' in content or 'img1.daumcdn.net' in content):
                if content.startswith('//'):
                    content = 'https:' + content
                elif content.startswith('/'):
                    content = urljoin(url, content)
                image_urls.append(content)
        
        # ì¤‘ë³µ ì œê±°
        image_urls = list(dict.fromkeys(image_urls))
        
        print(f"  âœ… Found {len(image_urls)} image(s)")
        return image_urls
        
    except Exception as e:
        print(f"  âŒ Error fetching {url}: {e}")
        return []

def download_image(image_url: str, save_path: Path) -> bool:
    """
    ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        image_url: ì´ë¯¸ì§€ URL
        save_path: ì €ì¥í•  ê²½ë¡œ
        
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if save_path.exists():
            print(f"    â­ï¸  Already exists: {save_path.name}")
            return True
        
        print(f"    ğŸ“¥ Downloading: {image_url[:80]}...")
        response = requests.get(image_url, headers=HEADERS, timeout=30, stream=True, verify=False)
        response.raise_for_status()
        
        # Content-Type í™•ì¸
        content_type = response.headers.get('Content-Type', '')
        if 'image' not in content_type:
            print(f"    âš ï¸  Not an image: {content_type}")
            return False
        
        # íŒŒì¼ ì €ì¥
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print(f"    âœ… Saved: {save_path.name}")
        return True
        
    except Exception as e:
        print(f"    âŒ Error downloading {image_url}: {e}")
        return False

def get_image_filename(post_file: Path, image_index: int = 0) -> str:
    """
    í¬ìŠ¤íŠ¸ íŒŒì¼ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        post_file: í¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        image_index: ì´ë¯¸ì§€ ì¸ë±ìŠ¤ (ì—¬ëŸ¬ ì´ë¯¸ì§€ê°€ ìˆì„ ê²½ìš°)
        
    Returns:
        ì´ë¯¸ì§€ íŒŒì¼ëª…
    """
    post_name = post_file.stem  # í™•ì¥ì ì œê±°
    
    # ì´ë¯¸ì§€ í™•ì¥ìëŠ” ë‹¤ìš´ë¡œë“œ ì‹œ ê²°ì • (ì¼ë‹¨ pngë¡œ ì„¤ì •)
    if image_index == 0:
        return f"{post_name}_image.png"
    else:
        return f"{post_name}_image_{image_index}.png"

def extract_image_extension_from_url(url: str) -> str:
    """
    URLì—ì„œ ì´ë¯¸ì§€ í™•ì¥ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        url: ì´ë¯¸ì§€ URL
        
    Returns:
        í™•ì¥ì (ì˜ˆ: .png, .jpg)
    """
    # URLì—ì„œ í™•ì¥ì ì¶”ì¶œ
    parsed = urlparse(url)
    path = unquote(parsed.path)
    
    # í™•ì¥ì í™•ì¸
    if path.endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg')):
        ext = Path(path).suffix
        return ext
    
    # Content-Typeì—ì„œ í™•ì¥ì ì¶”ì •
    try:
        response = requests.head(url, headers=HEADERS, timeout=10, verify=False)
        content_type = response.headers.get('Content-Type', '')
        if 'png' in content_type:
            return '.png'
        elif 'jpeg' in content_type or 'jpg' in content_type:
            return '.jpg'
        elif 'gif' in content_type:
            return '.gif'
        elif 'webp' in content_type:
            return '.webp'
        elif 'svg' in content_type:
            return '.svg'
    except:
        pass
    
    return '.png'  # ê¸°ë³¸ê°’

def add_image_to_post(post_file: Path, image_path: Path, image_index: int = 0) -> bool:
    """
    í¬ìŠ¤íŠ¸ íŒŒì¼ì— ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        post_file: í¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (assets/images ê¸°ì¤€)
        image_index: ì´ë¯¸ì§€ ì¸ë±ìŠ¤
        
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(post_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Front matter íŒŒì‹±
        metadata, body = parse_frontmatter(content)
        
        # ì´ë¯¸ì§€ ê²½ë¡œ (assets/images ê¸°ì¤€)
        image_ref = f"/assets/images/{image_path.name}"
        
        # ì´ë¯¸ ì´ë¯¸ì§€ê°€ front matterì— ìˆëŠ”ì§€ í™•ì¸
        if 'image' in metadata:
            existing_image = metadata['image']
            # ê°™ì€ ì´ë¯¸ì§€ë©´ ìŠ¤í‚µ
            if existing_image == image_ref:
                print(f"    â„¹ï¸  Image already in front matter")
                return True
        
        # ë³¸ë¬¸ì— ì´ë¯¸ì§€ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        image_markdown = f"![ì´ë¯¸ì§€]({image_ref})"
        if image_markdown in content or image_ref in content:
            print(f"    â„¹ï¸  Image already in content")
            return True
        
        # Front matter ì¬êµ¬ì„±
        if content.startswith('---'):
            end_match = re.search(r'\n---\n', content[3:])
            if end_match:
                frontmatter_text = content[3:end_match.start() + 3]
                body = content[end_match.end():]
            else:
                body = content
                frontmatter_text = ""
        else:
            body = content
            frontmatter_text = ""
        
        # ì„œë¡  ì„¹ì…˜ ì°¾ê¸°
        intro_pattern = r'## ì„œë¡ '
        intro_match = re.search(intro_pattern, body)
        
        if intro_match:
            # ì„œë¡  ì„¹ì…˜ ë ë¶€ë¶„ ì°¾ê¸°
            intro_end = intro_match.end()
            # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ê¹Œì§€ ì°¾ê¸°
            next_section = re.search(r'\n## ', body[intro_end:])
            if next_section:
                insert_pos = intro_end + next_section.start()
            else:
                insert_pos = intro_end + 200  # ì„œë¡  ì„¹ì…˜ ë ë¶€ë¶„
        else:
            # ì„œë¡ ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì„¹ì…˜ ì•ì— ì‚½ì…
            first_section = re.search(r'\n## ', body)
            if first_section:
                insert_pos = first_section.start()
            else:
                insert_pos = 100
        
        # ì´ë¯¸ì§€ ì‚½ì…
        image_block = f"\n\n![í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€]({image_ref})\n*ê·¸ë¦¼: í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€*\n\n"
        body = body[:insert_pos] + image_block + body[insert_pos:]
        
        # ì „ì²´ ë‚´ìš© ì¬êµ¬ì„±
        if frontmatter_text:
            content = f"---{frontmatter_text}\n---\n{body}"
        else:
            content = body
        
        # íŒŒì¼ ì €ì¥
        with open(post_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"    âœ… Added image reference to post")
        return True
        
    except Exception as e:
        print(f"    âŒ Error adding image to post: {e}")
        return False

def parse_frontmatter(content: str) -> Tuple[dict, str]:
    """
    Front matterë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    Args:
        content: íŒŒì¼ ë‚´ìš©
        
    Returns:
        (metadata ë”•ì…”ë„ˆë¦¬, ë³¸ë¬¸)
    """
    metadata = {}
    body = content
    
    # Front matter ì‹œì‘ í™•ì¸
    if content.startswith('---'):
        # Front matter ë ì°¾ê¸°
        end_match = re.search(r'\n---\n', content[3:])
        if end_match:
            frontmatter_text = content[3:end_match.start() + 3]
            body = content[end_match.end():]
            
            # ê°„ë‹¨í•œ YAML íŒŒì‹±
            for line in frontmatter_text.split('\n'):
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip().strip('"\'')
                    metadata[key] = value
    
    return metadata, body

def process_post(post_file: Path, force: bool = False) -> Tuple[int, int]:
    """
    ë‹¨ì¼ í¬ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        post_file: í¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        force: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí• ì§€ ì—¬ë¶€
        
    Returns:
        (ì„±ê³µí•œ ì´ë¯¸ì§€ ìˆ˜, ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ ìˆ˜)
    """
    print(f"\nğŸ“„ Processing: {post_file.name}")
    
    # Front matter ì½ê¸°
    try:
        with open(post_file, 'r', encoding='utf-8') as f:
            content = f.read()
        metadata, _ = parse_frontmatter(content)
    except Exception as e:
        print(f"  âŒ Error reading post: {e}")
        return (0, 0)
    
    # original_url í™•ì¸
    original_url = metadata.get('original_url', '')
    if not original_url or 'twodragon.tistory.com' not in original_url:
        print(f"  â­ï¸  No tistory URL found")
        return (0, 0)
    
    # ì´ë¯¸ì§€ URL ì¶”ì¶œ
    image_urls = extract_images_from_tistory(original_url)
    if not image_urls:
        print(f"  âš ï¸  No images found")
        return (0, 0)
    
    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (ë©”ì¸ ì´ë¯¸ì§€)
    main_image_url = image_urls[0]
    
    # ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
    image_ext = extract_image_extension_from_url(main_image_url)
    
    # ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±
    image_filename = get_image_filename(post_file, 0)
    # í™•ì¥ì êµì²´
    image_filename = Path(image_filename).stem + image_ext
    image_path = IMAGES_DIR / image_filename
    
    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    if force or not image_path.exists():
        success = download_image(main_image_url, image_path)
        if not success:
            return (0, 1)
    else:
        print(f"    â„¹ï¸  Image already exists: {image_filename}")
    
    # í¬ìŠ¤íŠ¸ì— ì´ë¯¸ì§€ ì¶”ê°€
    add_image_to_post(post_file, image_path)
    
    return (1, 0)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Fetch images from Tistory blog posts')
    parser.add_argument('--test', action='store_true', help='Test mode: process only first post')
    parser.add_argument('--force', action='store_true', help='Force re-download existing images')
    args = parser.parse_args()
    
    print("ğŸš€ Starting Tistory image fetch process...\n")
    
    # ë””ë ‰í† ë¦¬ í™•ì¸
    if not POSTS_DIR.exists():
        print(f"âŒ Posts directory not found: {POSTS_DIR}")
        sys.exit(1)
    
    IMAGES_DIR.mkdir(parents=True, exist_ok=True)
    
    # ëª¨ë“  í¬ìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸°
    post_files = sorted(POSTS_DIR.glob("*.md"))
    
    if not post_files:
        print("âŒ No post files found")
        sys.exit(1)
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²« ë²ˆì§¸ í¬ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
    if args.test:
        post_files = post_files[:1]
        print("ğŸ§ª Test mode: processing first post only\n")
    
    print(f"ğŸ“š Found {len(post_files)} post file(s) to process\n")
    
    # ì²˜ë¦¬ í†µê³„
    total_success = 0
    total_failed = 0
    processed = 0
    
    # ê° í¬ìŠ¤íŠ¸ ì²˜ë¦¬
    for post_file in post_files:
        success, failed = process_post(post_file, force=args.force)
        total_success += success
        total_failed += failed
        processed += 1
        
        # Rate limiting (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        if processed < len(post_files):
            time.sleep(2)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"âœ… Processed: {processed} post(s)")
    print(f"âœ… Success: {total_success} image(s)")
    print(f"âŒ Failed: {total_failed} image(s)")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
