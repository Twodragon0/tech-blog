#!/usr/bin/env python3
"""
Auto Publish News - ìë™ ë‰´ìŠ¤ í¬ìŠ¤íŠ¸ ë°œí–‰ ìŠ¤í¬ë¦½íŠ¸

RSSì—ì„œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ í’ˆì§ˆ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìë™ ìƒì„±í•˜ê³ 
_posts í´ë”ì— ì§ì ‘ ë°œí–‰í•©ë‹ˆë‹¤.

Features:
- AI ìš”ì•½ ì¹´ë“œ ìë™ ìƒì„±
- SVG ì´ë¯¸ì§€ ìë™ ìƒì„±
- ê¸°ì¡´ í¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ê³¼ ì¼ê´€ì„± ìœ ì§€
- ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ë° ë¶„ì„
- ë³´ì•ˆ ë‹¤ì´ì œìŠ¤íŠ¸ / í…Œí¬ ë¸”ë¡œê·¸ ë‹¤ì´ì œìŠ¤íŠ¸ ëª¨ë“œ ì§€ì›

Usage:
    python3 scripts/auto_publish_news.py
    python3 scripts/auto_publish_news.py --dry-run
    python3 scripts/auto_publish_news.py --hours 48
    python3 scripts/auto_publish_news.py --mode tech-blog
    python3 scripts/auto_publish_news.py --mode security --force
"""

import argparse
import html
import json
import os
import re
import subprocess
import sys
import unicodedata
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import defaultdict

# ============================================================================
# ì„¤ì •
# ============================================================================

POSTS_DIR = Path("_posts")
IMAGES_DIR = Path("assets/images")
DATA_DIR = Path("_data")  # ì‹¤ì œ ë°ì´í„° ë””ë ‰í† ë¦¬

CATEGORY_PRIORITY = {
    "security": 1,
    "devsecops": 2,
    "ai": 3,
    "cloud": 4,
    "devops": 5,
    "blockchain": 6,
    "tech": 7,
}

CATEGORY_EMOJI = {
    "security": "ğŸ”’",
    "devsecops": "ğŸ›¡ï¸",
    "ai": "ğŸ¤–",
    "cloud": "â˜ï¸",
    "devops": "âš™ï¸",
    "tech": "ğŸ’»",
    "kubernetes": "ğŸš€",
    "blockchain": "â›“ï¸",
    "finops": "ğŸ’°",
}

CATEGORY_COLOR = {
    "security": "#ef4444",
    "devsecops": "#8b5cf6",
    "ai": "#6366f1",
    "cloud": "#22c55e",
    "devops": "#f59e0b",
    "blockchain": "#f97316",
    "tech": "#3b82f6",
}

SOURCE_PRIORITY = {
    "thehackernews": 1,
    "microsoft_security": 1,
    "aws_security": 1,
    "gcp": 2,
    "hashicorp": 2,
    "cncf": 2,
    "geeknews": 2,
    "hackernews": 3,
    "skshieldus": 2,
    "skshieldus_report": 2,
    "palantir": 1,
    "openai": 1,
    "google_ai": 1,
    "meta_engineering": 1,
    "huggingface": 2,
    "google_research": 1,
    "netflix_tech": 2,
    "bitcoin_magazine": 1,
    "cointelegraph": 2,
    "vitalik": 1,
    "chainalysis": 1,
    "microsoft_devblogs": 1,
    "microsoft_dotnet": 2,
    "tesla": 1,
    "electrek": 2,
    "github_blog": 1,
    "stripe": 2,
    "slack_engineering": 2,
    "x_engineering": 1,
    "apple_ml": 1,
    "spotify_engineering": 2,
    "discord": 2,
    "docker": 1,
    "google_developers": 1,
    "rust_lang": 2,
    "golang": 2,
    "apple_developer": 1,
    "apple_newsroom": 2,
    "webkit": 2,
}

# Tech blog sources (non-security, non-blockchain)
TECH_BLOG_SOURCES = {
    "geeknews", "hackernews", "palantir", "openai", "google_ai",
    "meta_engineering", "huggingface", "google_research", "netflix_tech",
    "microsoft_devblogs", "microsoft_dotnet", "tesla", "electrek",
    "github_blog", "stripe", "slack_engineering", "x_engineering",
    "apple_ml", "spotify_engineering", "discord", "docker",
    "google_developers", "rust_lang", "golang", "apple_developer",
    "apple_newsroom", "webkit", "hashicorp", "cncf", "gcp",
}

MIN_NEWS_COUNT = 5  # ìµœì†Œ ë‰´ìŠ¤ ìˆ˜
MAX_NEWS_PER_CATEGORY = 5  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜


# ============================================================================
# ë‰´ìŠ¤ ë¡œë“œ ë° í•„í„°ë§
# ============================================================================


def load_collected_news() -> Dict:
    """ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¡œë“œ"""
    news_file = DATA_DIR / "collected_news.json"
    if not news_file.exists():
        print("âŒ No collected news found. Run collect_tech_news.py first.")
        sys.exit(1)

    with open(news_file, "r", encoding="utf-8") as f:
        return json.load(f)


def filter_and_prioritize_news(news_data: Dict, hours: int = 24) -> List[Dict]:
    """ë‰´ìŠ¤ í•„í„°ë§ ë° ìš°ì„ ìˆœìœ„ ì •ë ¬ (í”„ë¡œê·¸ë ˆì‹œë¸Œ ì™„í™” í¬í•¨)"""
    items = news_data.get("items", [])
    if not items:
        return []

    # collected_at ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì‹ ì„ ë„ í™•ì¸
    collected_at_str = news_data.get("collected_at", "")
    data_age_hours = 0
    if collected_at_str:
        try:
            collected_at = datetime.fromisoformat(
                collected_at_str.replace("Z", "+00:00")
            )
            data_age_hours = (
                datetime.now(timezone.utc) - collected_at
            ).total_seconds() / 3600
            print(f"  ğŸ“… Data age: {data_age_hours:.1f}h (collected at {collected_at_str})")
        except (ValueError, TypeError):
            pass

    # ë°ì´í„°ê°€ ì˜¤ë˜ëœ ê²½ìš° ì‹œê°„ ìœˆë„ìš°ë¥¼ ìë™ í™•ì¥
    effective_hours = hours + data_age_hours

    # í”„ë¡œê·¸ë ˆì‹œë¸Œ ì™„í™”: hours â†’ hours*2 â†’ hours*3 â†’ ì „ì²´
    time_windows = [hours, effective_hours, hours * 2, hours * 3]

    for window in time_windows:
        cutoff = datetime.now(timezone.utc) - timedelta(hours=window)
        filtered = _filter_by_cutoff(items, cutoff)
        if len(filtered) >= MIN_NEWS_COUNT:
            if window > hours:
                print(f"  â° Time window relaxed: {hours}h â†’ {window:.0f}h ({len(filtered)} items)")
            break
    else:
        # ëª¨ë“  ìœˆë„ìš°ì—ì„œ ë¶€ì¡±í•˜ë©´ ì „ì²´ ì•„ì´í…œì„ ë‚ ì§œìˆœ ì •ë ¬ í›„ ì‚¬ìš©
        print(f"  âš ï¸ All time windows insufficient. Using all {len(items)} items sorted by date.")
        filtered = sorted(
            items,
            key=lambda x: x.get("published", ""),
            reverse=True,
        )

    # Deprioritize items with empty summary AND empty content
    for item in filtered:
        summary = item.get("summary", "").strip()
        content_text = item.get("content", "").strip()
        if not summary and not content_text:
            item["_empty_content"] = True

    # Group related Bitcoin/crypto crash stories - deduplicate
    filtered = _deduplicate_crypto_stories(filtered)

    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    def get_priority(item):
        source_priority = SOURCE_PRIORITY.get(item.get("source", ""), 5)
        category_priority = CATEGORY_PRIORITY.get(item.get("category", "tech"), 5)
        # Items with empty content get deprioritized
        empty_penalty = 10 if item.get("_empty_content") else 0
        return (empty_penalty, source_priority, category_priority)

    filtered.sort(key=get_priority)
    return filtered


def _deduplicate_crypto_stories(items: List[Dict]) -> List[Dict]:
    """Group related Bitcoin/crypto crash stories and keep only the 2 most substantive"""
    crypto_keywords = ["bitcoin", "btc", "crypto", "cryptocurrency"]
    price_keywords = ["crash", "drop", "fall", "plunge", "dump", "price", "surge", "rally"]

    crypto_price_items = []
    other_items = []

    for item in items:
        text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
        is_crypto = any(kw in text for kw in crypto_keywords)
        is_price = any(kw in text for kw in price_keywords)
        category = item.get("category", "")

        if category == "blockchain" and is_crypto and is_price:
            crypto_price_items.append(item)
        else:
            other_items.append(item)

    if len(crypto_price_items) >= 3:
        # Keep the 2 most substantive (longest summary + content)
        crypto_price_items.sort(
            key=lambda x: len(x.get("summary", "")) + len(x.get("content", "")),
            reverse=True,
        )
        other_items.extend(crypto_price_items[:2])
    else:
        other_items.extend(crypto_price_items)

    return other_items


def _filter_by_cutoff(items: List[Dict], cutoff: datetime) -> List[Dict]:
    """cutoff ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë‰´ìŠ¤ í•„í„°ë§"""
    filtered = []
    for item in items:
        try:
            pub_date = datetime.fromisoformat(
                item.get("published", "").replace("Z", "+00:00")
            )
            if pub_date >= cutoff:
                filtered.append(item)
        except (ValueError, TypeError):
            # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í¬í•¨
            filtered.append(item)
    return filtered


def categorize_news(items: List[Dict]) -> Dict[str, List[Dict]]:
    """ë‰´ìŠ¤ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    categorized = defaultdict(list)

    for item in items:
        category = item.get("category", "tech")
        # security, devsecopsëŠ” securityë¡œ í†µí•©
        if category in ("security", "devsecops"):
            category = "security"
        elif category == "kubernetes":
            category = "devops"
        # ai, blockchainì€ ë…ë¦½ ì¹´í…Œê³ ë¦¬ë¡œ ìœ ì§€
        # cloud, devops, techë„ ê·¸ëŒ€ë¡œ ìœ ì§€

        if len(categorized[category]) < MAX_NEWS_PER_CATEGORY:
            # Filter out stale items for non-security categories
            if category not in ("security", "devsecops"):
                # Check URL for old year indicators (e.g., /2023/ or /2024/)
                url = item.get("url", "")
                current_year = datetime.now(timezone.utc).year
                url_year_match = re.search(r'/(\d{4})/', url)
                if url_year_match:
                    url_year = int(url_year_match.group(1))
                    if 2000 <= url_year < current_year - 1:
                        continue
                # Also check published date
                try:
                    pub_date = datetime.fromisoformat(item.get("published", "").replace("Z", "+00:00"))
                    if (datetime.now(timezone.utc) - pub_date).days > 90:
                        continue
                except (ValueError, TypeError):
                    pass
            categorized[category].append(item)

    return dict(categorized)


def select_top_news(
    categorized: Dict[str, List[Dict]], max_total: int = 15
) -> List[Dict]:
    """ìƒìœ„ ë‰´ìŠ¤ ì„ íƒ"""
    selected = []

    # ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì„ íƒ
    for category in sorted(
        categorized.keys(), key=lambda c: CATEGORY_PRIORITY.get(c, 5)
    ):
        for item in categorized[category]:
            if len(selected) >= max_total:
                break
            selected.append(item)

    return selected


# ============================================================================
# í¬ìŠ¤íŠ¸ ìƒì„±
# ============================================================================


def _extract_meaningful_topics(news_items: List[Dict], mode: str = "security") -> str:
    """Extract 2-3 meaningful topic keywords from news items for title generation.

    For security mode: extract threat names, tools, companies mentioned.
    For tech-blog mode: extract tech topics like AI Agent, Claude Code, Open Source etc.
    Cap at 80 chars.
    """
    if mode == "tech-blog":
        tech_patterns = [
            (r'\b(AI Agent|Claude Code|Cursor|Copilot|ChatGPT|Gemini|LLM)\b', None),
            (r'\b(Open Source|Open-Source|OSS)\b', "Open Source"),
            (r'\b(Kubernetes|K8s)\b', "Kubernetes"),
            (r'\b(Docker|Container)\b', "Docker"),
            (r'\b(Rust|Golang|Go\s+\d|TypeScript)\b', None),
            (r'\b(React|Next\.?js|Vue|Svelte)\b', None),
            (r'\b(AWS|Azure|GCP|Cloud)\b', None),
            (r'\b(GitHub|GitLab)\b', None),
            (r'\b(Apple|Google|Microsoft|Meta|Tesla|Spotify)\b', None),
            (r'\b(WebAssembly|WASM|gRPC|GraphQL)\b', None),
            (r'\b(DevOps|CI/CD|Platform Engineering)\b', None),
        ]
    else:
        tech_patterns = [
            (r'(CVE-\d{4}-\d+)', None),
            (r'\b(ransomware|Ransomware|ëœì„¬ì›¨ì–´)\b', "Ransomware"),
            (r'\b(zero-day|Zero-Day|0-day|ì œë¡œë°ì´)\b', "Zero-Day"),
            (r'\b(Fortinet|Cisco|Palo Alto|CrowdStrike|SonicWall|Ivanti)\b', None),
            (r'\b(Chrome|Firefox|Windows|Linux|macOS|Android|iOS)\b', None),
            (r'\b(APT\d+|Lazarus|APT28|APT29|Kimsuky)\b', None),
            (r'\b(phishing|Phishing|í”¼ì‹±)\b', "Phishing"),
            (r'\b(supply chain|Supply Chain|ê³µê¸‰ë§)\b', "Supply Chain"),
            (r'\b(botnet|Botnet|ë´‡ë„·)\b', "Botnet"),
            (r'\b(malware|Malware|ì•…ì„±ì½”ë“œ)\b', "Malware"),
            (r'\b(authentication|MFA|SSO|ì¸ì¦)\b', "Authentication"),
            (r'\b(RCE|remote code execution)\b', "RCE"),
            (r'\b(AWS|Azure|GCP|Cloud)\b', None),
            (r'\b(Kubernetes|K8s|Docker)\b', None),
        ]

    found_topics = []
    seen_lower = set()

    for item in news_items:
        text = f"{item.get('title', '')} {item.get('summary', '')}"
        for pattern, canonical in tech_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                topic = canonical if canonical else match.group(1)
                if topic.lower() not in seen_lower:
                    seen_lower.add(topic.lower())
                    found_topics.append(topic)
                    if len(found_topics) >= 4:
                        break
        if len(found_topics) >= 4:
            break

    if not found_topics:
        if mode == "tech-blog":
            found_topics = ["Tech", "DevOps"]
        else:
            found_topics = ["DevSecOps News"]

    title_keywords = ", ".join(found_topics[:3])
    if len(title_keywords) > 80:
        title_keywords = title_keywords[:77] + "..."
    return title_keywords


def generate_post_content(
    news_items: List[Dict], categorized: Dict[str, List[Dict]], date: datetime, topics_slug: str = ""
) -> str:
    """ê³ í’ˆì§ˆ í¬ìŠ¤íŠ¸ ì»¨í…ì¸  ìƒì„±"""

    date_str = date.strftime("%Yë…„ %mì›” %dì¼")
    date_file = date.strftime("%Y-%m-%d")
    image_filename = f"{date_file}-Tech_Security_Weekly_Digest_{topics_slug}.svg" if topics_slug else f"{date_file}-Tech_Security_Weekly_Digest.svg"

    stats = {cat: len(items) for cat, items in categorized.items()}
    total = sum(stats.values())

    # í•µì‹¬ ë‰´ìŠ¤ ì¶”ì¶œ
    security_news = categorized.get("security", [])[:3]
    ai_news = categorized.get("ai", [])[:3]
    cloud_news = categorized.get("cloud", [])[:3]
    devops_news = categorized.get("devops", [])[:3]
    blockchain_news = categorized.get("blockchain", [])[:2]
    tech_news = categorized.get("tech", [])[:2]

    # í•µì‹¬ í•˜ì´ë¼ì´íŠ¸ ìƒì„±
    highlights = []
    for item in (security_news + cloud_news)[:4]:
        source = item.get("source_name", item.get("source", "Unknown"))
        title = item.get("title", "")
        if len(title) > 60:
            # Truncate at word boundary
            title = title[:57].rsplit(" ", 1)[0] + "..."
        source = html.escape(source)
        title = html.escape(title)
        highlights.append(f"<li><strong>{source}</strong>: {title}</li>")

    highlights_html = (
        "\n      ".join(highlights)
        if highlights
        else "<li>ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”</li>"
    )

    topics = _extract_key_topics(news_items)

    # Better title generation: extract meaningful topics from content
    title_keywords = _extract_meaningful_topics(news_items, mode="security")

    base_tags = ["Security-Weekly", "DevSecOps", "Cloud-Security", "Weekly-Digest", str(date.year)]
    topic_tags = [t for t in topics if t not in base_tags]
    tags = base_tags + topic_tags[:5]

    top_sources = list({item.get("source_name", ""): True for item in news_items[:5]}.keys())[:3]
    source_list = ", ".join(top_sources)

    content = f'''---
layout: post
title: "Tech & Security Weekly Digest: {title_keywords}"
date: {date.strftime("%Y-%m-%d %H:%M:%S")} +0900
categories: [security, devsecops]
tags: [{", ".join(tags)}]
excerpt: "{date_str} ì£¼ìš” ë³´ì•ˆ/ê¸°ìˆ  ë‰´ìŠ¤ {total}ê±´ - {", ".join(topics[:3])}"
description: "{date_str} ë³´ì•ˆ ë‰´ìŠ¤: {source_list} ë“± {total}ê±´. {", ".join(topics[:4])} ê´€ë ¨ DevSecOps ì‹¤ë¬´ ìœ„í˜‘ ë¶„ì„ ë° ëŒ€ì‘ ê°€ì´ë“œ."
keywords: [{", ".join(tags[:8])}]
author: Twodragon
comments: true
image: /assets/images/{image_filename}
image_alt: "Tech Security Weekly Digest {date.strftime('%B %d %Y')} {' '.join(topics[:3])}"
toc: true
---

<div class="ai-summary-card">
<div class="ai-summary-header">
  <span class="ai-badge">AI ìš”ì•½</span>
</div>
<div class="ai-summary-content">
  <div class="summary-row">
    <span class="summary-label">ì œëª©</span>
    <span class="summary-value">Tech & Security Weekly Digest ({date_str})</span>
  </div>
  <div class="summary-row">
    <span class="summary-label">ì¹´í…Œê³ ë¦¬</span>
    <span class="summary-value"><span class="category-tag security">Security</span> <span class="category-tag devsecops">DevSecOps</span></span>
  </div>
  <div class="summary-row">
    <span class="summary-label">íƒœê·¸</span>
    <span class="summary-value tags">
      <span class="tag">Security-Weekly</span>
      <span class="tag">DevSecOps</span>
      <span class="tag">Cloud-Security</span>
      <span class="tag">AI-Security</span>
      <span class="tag">Zero-Trust</span>
      <span class="tag">{date.year}</span>
    </span>
  </div>
  <div class="summary-row highlights">
    <span class="summary-label">í•µì‹¬ ë‚´ìš©</span>
    <ul class="summary-list">
      {highlights_html}
    </ul>
  </div>
  <div class="summary-row">
    <span class="summary-label">ìˆ˜ì§‘ ê¸°ê°„</span>
    <span class="summary-value">{date_str} (24ì‹œê°„)</span>
  </div>
  <div class="summary-row">
    <span class="summary-label">ëŒ€ìƒ ë…ì</span>
    <span class="summary-value">ë³´ì•ˆ ë‹´ë‹¹ì, DevSecOps ì—”ì§€ë‹ˆì–´, SRE, í´ë¼ìš°ë“œ ì•„í‚¤í…íŠ¸</span>
  </div>
</div>
<div class="ai-summary-footer">
  ì´ í¬ìŠ¤íŒ…ì€ AIê°€ ì‰½ê²Œ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ í¬í•¨í•©ë‹ˆë‹¤.
</div>
</div>

## ì„œë¡ 

ì•ˆë…•í•˜ì„¸ìš”, **Twodragon**ì…ë‹ˆë‹¤.

{date_str} ê¸°ì¤€, ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ ë°œí‘œëœ ì£¼ìš” ê¸°ìˆ  ë° ë³´ì•ˆ ë‰´ìŠ¤ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

**ìˆ˜ì§‘ í†µê³„:**
- **ì´ ë‰´ìŠ¤ ìˆ˜**: {total}ê°œ
- **ë³´ì•ˆ ë‰´ìŠ¤**: {stats.get("security", 0)}ê°œ
- **AI/ML ë‰´ìŠ¤**: {stats.get("ai", 0)}ê°œ
- **í´ë¼ìš°ë“œ ë‰´ìŠ¤**: {stats.get("cloud", 0)}ê°œ
- **DevOps ë‰´ìŠ¤**: {stats.get("devops", 0)}ê°œ
- **ë¸”ë¡ì²´ì¸ ë‰´ìŠ¤**: {stats.get("blockchain", 0)}ê°œ

---

## ğŸ“Š ë¹ ë¥¸ ì°¸ì¡°

### ì´ë²ˆ ì£¼ í•˜ì´ë¼ì´íŠ¸

| ë¶„ì•¼ | ì†ŒìŠ¤ | í•µì‹¬ ë‚´ìš© | ì˜í–¥ë„ |
|------|------|----------|--------|
'''

    # í•˜ì´ë¼ì´íŠ¸ í…Œì´ë¸” ìƒì„±
    for item in news_items[:5]:
        source = item.get("source_name", item.get("source", "Unknown"))[:15]
        title = item.get("title", "")[:50]
        category = item.get("category", "tech")
        emoji = CATEGORY_EMOJI.get(category, "ğŸ“°")
        severity = _determine_severity(item)
        severity_emoji = {"Critical": "ğŸ”´", "High": "ğŸŸ ", "Medium": "ğŸŸ¡"}.get(severity, "ğŸŸ¡")
        content += (
            f"| {emoji} **{category.title()}** | {source} | {title}... | {severity_emoji} {severity} |\n"
        )

    content += "\n---\n\n"

    section_num = 1

    # ë³´ì•ˆ ë‰´ìŠ¤ ì„¹ì…˜ - SK Shieldus ê·¸ë£¹í•‘ í¬í•¨
    if security_news:
        content += f"## {section_num}. ë³´ì•ˆ ë‰´ìŠ¤\n\n"

        # Separate SK Shieldus reports from regular security news
        skshieldus_reports = [item for item in security_news if item.get("source") == "skshieldus_report"]
        regular_security = [item for item in security_news if item.get("source") != "skshieldus_report"]

        for i, item in enumerate(regular_security, 1):
            is_critical = (i == 1)  # ì²« ë²ˆì§¸ ë‰´ìŠ¤ëŠ” ìƒì„¸ ë¶„ì„
            content += generate_news_section(item, f"{section_num}.{i}", is_critical=is_critical)

        # SK Shieldus reports grouped into a single subsection
        if skshieldus_reports:
            sub_idx = len(regular_security) + 1
            month_str = date.strftime("%-mì›”") if sys.platform != "win32" else date.strftime("%mì›”").lstrip("0")
            content += f"### {section_num}.{sub_idx} SKì‰´ë”ìŠ¤ {month_str} ë³´ì•ˆ ë¦¬í¬íŠ¸\n\n"
            content += "SKì‰´ë”ìŠ¤ì—ì„œ ë°œí–‰í•œ ìµœì‹  ë³´ì•ˆ ë¦¬í¬íŠ¸ ëª¨ìŒì…ë‹ˆë‹¤.\n\n"
            for report in skshieldus_reports:
                report_title = report.get("title", "ë³´ì•ˆ ë¦¬í¬íŠ¸")
                report_url = report.get("url", "")
                report_summary = report.get("summary", "")
                content += f"- **[{report_title}]({report_url})**"
                if report_summary:
                    short_summary = report_summary[:100].rstrip(".")
                    content += f": {short_summary}"
                content += "\n"
            content += "\n> SKì‰´ë”ìŠ¤ ë³´ì•ˆ ë¦¬í¬íŠ¸ëŠ” êµ­ë‚´ ë³´ì•ˆ í™˜ê²½ì— íŠ¹í™”ëœ ìœ„í˜‘ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì›ë¬¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n"
            content += "---\n\n"

        section_num += 1

    # AI/ML ë‰´ìŠ¤ ì„¹ì…˜
    if ai_news:
        content += f"## {section_num}. AI/ML ë‰´ìŠ¤\n\n"
        for i, item in enumerate(ai_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # í´ë¼ìš°ë“œ ë‰´ìŠ¤ ì„¹ì…˜
    if cloud_news:
        content += f"## {section_num}. í´ë¼ìš°ë“œ & ì¸í”„ë¼ ë‰´ìŠ¤\n\n"
        for i, item in enumerate(cloud_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # DevOps ë‰´ìŠ¤ ì„¹ì…˜
    if devops_news:
        content += f"## {section_num}. DevOps & ê°œë°œ ë‰´ìŠ¤\n\n"
        for i, item in enumerate(devops_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # ë¸”ë¡ì²´ì¸ ë‰´ìŠ¤ ì„¹ì…˜
    if blockchain_news:
        content += f"## {section_num}. ë¸”ë¡ì²´ì¸ ë‰´ìŠ¤\n\n"
        for i, item in enumerate(blockchain_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # ê¸°íƒ€ ë‰´ìŠ¤
    if tech_news:
        content += f"## {section_num}. ê¸°íƒ€ ì£¼ëª©í•  ë‰´ìŠ¤\n\n"
        content += "| ì œëª© | ì¶œì²˜ | í•µì‹¬ ë‚´ìš© |\n"
        content += "|------|------|----------|\n"
        for item in tech_news[:5]:
            title = item.get("title", "")[:50]
            source = item.get("source_name", "")
            url = item.get("url", "")
            summary = item.get("summary", "")[:80]
            content += f"| [{title}...]({url}) | {source} | {summary}... |\n"
        content += "\n"
        section_num += 1

    # íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜
    content += _generate_trend_analysis(news_items, section_num)
    section_num += 1

    # ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸
    content += _generate_news_specific_checklist(news_items)

    content += """
---

## ì°¸ê³  ìë£Œ

| ë¦¬ì†ŒìŠ¤ | ë§í¬ |
|--------|------|
| CISA KEV | [cisa.gov/known-exploited-vulnerabilities-catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog) |
| MITRE ATT&CK | [attack.mitre.org](https://attack.mitre.org/) |
| FIRST EPSS | [first.org/epss](https://www.first.org/epss/) |

---

**ì‘ì„±ì**: Twodragon
"""

    return content


def generate_tech_blog_content(
    news_items: List[Dict], categorized: Dict[str, List[Dict]], date: datetime, topics_slug: str = ""
) -> str:
    """Tech Blog Weekly Digest ì»¨í…ì¸  ìƒì„±.

    Filters for geeknews, hackernews, and tech blog sources (NOT security/blockchain).
    Groups by topic: AI/ML, DevOps/Cloud, Open Source, General.
    Uses GeekNews Korean summaries prominently.
    """
    date_str = date.strftime("%Yë…„ %mì›” %dì¼")
    date_file = date.strftime("%Y-%m-%d")
    image_filename = f"{date_file}-Tech_Blog_Weekly_Digest_{topics_slug}.svg" if topics_slug else f"{date_file}-Tech_Blog_Weekly_Digest.svg"

    total = len(news_items)

    # Group items by topic
    topic_groups = {
        "AI/ML": [],
        "DevOps/Cloud": [],
        "Open Source": [],
        "General": [],
    }

    ai_keywords = ["ai", "ml", "llm", "gpt", "claude", "gemini", "chatgpt", "copilot",
                    "machine learning", "deep learning", "neural", "transformer", "agent"]
    devops_keywords = ["kubernetes", "k8s", "docker", "cloud", "aws", "azure", "gcp",
                       "terraform", "ci/cd", "devops", "sre", "infrastructure", "helm",
                       "container", "serverless", "microservice"]
    oss_keywords = ["open source", "open-source", "oss", "github", "rust", "golang", "go ",
                    "python", "typescript", "linux", "apache", "mit license", "cncf"]

    for item in news_items:
        text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}".lower()
        category = item.get("category", "tech")

        if any(kw in text for kw in ai_keywords) or category == "ai":
            topic_groups["AI/ML"].append(item)
        elif any(kw in text for kw in devops_keywords) or category in ("devops", "cloud"):
            topic_groups["DevOps/Cloud"].append(item)
        elif any(kw in text for kw in oss_keywords):
            topic_groups["Open Source"].append(item)
        else:
            topic_groups["General"].append(item)

    # Title generation for tech-blog mode
    title_keywords = _extract_meaningful_topics(news_items, mode="tech-blog")

    topics = _extract_key_topics(news_items)
    base_tags = ["Tech-Blog", "Weekly-Digest", "Developer", str(date.year)]
    topic_tags = [t for t in topics if t not in base_tags]
    tags = base_tags + topic_tags[:5]

    # GeekNews items for prominent display
    geeknews_items = [item for item in news_items if item.get("source") == "geeknews"]

    top_sources = list({item.get("source_name", ""): True for item in news_items[:5]}.keys())[:3]
    source_list = ", ".join(top_sources)

    # Build highlights from top items
    highlights = []
    for item in news_items[:4]:
        source = html.escape(item.get("source_name", item.get("source", "Unknown")))
        title = item.get("title", "")
        if len(title) > 60:
            title = title[:57].rsplit(" ", 1)[0] + "..."
        title = html.escape(title)
        highlights.append(f"<li><strong>{source}</strong>: {title}</li>")

    highlights_html = (
        "\n      ".join(highlights)
        if highlights
        else "<li>ì´ë²ˆ ì£¼ ì£¼ìš” ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”</li>"
    )

    content = f'''---
layout: post
title: "Tech Blog Weekly Digest: {title_keywords}"
date: {date.strftime("%Y-%m-%d %H:%M:%S")} +0900
categories: [tech, devops]
tags: [{", ".join(tags)}]
excerpt: "{date_str} ì£¼ìš” ê¸°ìˆ  ë¸”ë¡œê·¸ ë‰´ìŠ¤ {total}ê±´ - {", ".join(topics[:3])}"
description: "{date_str} í…Œí¬ ë¸”ë¡œê·¸ ë‹¤ì´ì œìŠ¤íŠ¸: {source_list} ë“± {total}ê±´. {", ".join(topics[:4])} ê´€ë ¨ ê°œë°œì ë‰´ìŠ¤ ë° íŠ¸ë Œë“œ ë¶„ì„."
keywords: [{", ".join(tags[:8])}]
author: Twodragon
comments: true
image: /assets/images/{image_filename}
image_alt: "Tech Blog Weekly Digest {date.strftime('%B %d %Y')} {' '.join(topics[:3])}"
toc: true
---

<div class="ai-summary-card">
<div class="ai-summary-header">
  <span class="ai-badge">AI ìš”ì•½</span>
</div>
<div class="ai-summary-content">
  <div class="summary-row">
    <span class="summary-label">ì œëª©</span>
    <span class="summary-value">Tech Blog Weekly Digest ({date_str})</span>
  </div>
  <div class="summary-row">
    <span class="summary-label">ì¹´í…Œê³ ë¦¬</span>
    <span class="summary-value"><span class="category-tag tech">Tech</span> <span class="category-tag devops">DevOps</span></span>
  </div>
  <div class="summary-row">
    <span class="summary-label">íƒœê·¸</span>
    <span class="summary-value tags">
      <span class="tag">Tech-Blog</span>
      <span class="tag">Weekly-Digest</span>
      <span class="tag">Developer</span>
      <span class="tag">Open-Source</span>
      <span class="tag">AI/ML</span>
      <span class="tag">{date.year}</span>
    </span>
  </div>
  <div class="summary-row highlights">
    <span class="summary-label">í•µì‹¬ ë‚´ìš©</span>
    <ul class="summary-list">
      {highlights_html}
    </ul>
  </div>
  <div class="summary-row">
    <span class="summary-label">ìˆ˜ì§‘ ê¸°ê°„</span>
    <span class="summary-value">{date_str} (24ì‹œê°„)</span>
  </div>
  <div class="summary-row">
    <span class="summary-label">ëŒ€ìƒ ë…ì</span>
    <span class="summary-value">ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì, DevOps ì—”ì§€ë‹ˆì–´, í…Œí¬ ë¦¬ë“œ, CTO</span>
  </div>
</div>
<div class="ai-summary-footer">
  ì´ í¬ìŠ¤íŒ…ì€ AIê°€ ì‰½ê²Œ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ í¬í•¨í•©ë‹ˆë‹¤.
</div>
</div>

## ì„œë¡ 

ì•ˆë…•í•˜ì„¸ìš”, **Twodragon**ì…ë‹ˆë‹¤.

{date_str} ê¸°ì¤€, ì£¼ìš” ê¸°ìˆ  ë¸”ë¡œê·¸ì™€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë°œí‘œëœ ê°œë°œì ë‰´ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

**ìˆ˜ì§‘ í†µê³„:**
- **ì´ ë‰´ìŠ¤ ìˆ˜**: {total}ê°œ
- **AI/ML**: {len(topic_groups["AI/ML"])}ê°œ
- **DevOps/Cloud**: {len(topic_groups["DevOps/Cloud"])}ê°œ
- **Open Source**: {len(topic_groups["Open Source"])}ê°œ
- **General**: {len(topic_groups["General"])}ê°œ

---

'''

    section_num = 1

    # GeekNews í•˜ì´ë¼ì´íŠ¸ (Korean summaries prominently displayed)
    if geeknews_items:
        content += f"## {section_num}. GeekNews í•˜ì´ë¼ì´íŠ¸\n\n"
        content += "GeekNewsì—ì„œ ì£¼ëª©ë°›ì€ ê¸°ìˆ  ë‰´ìŠ¤ì…ë‹ˆë‹¤.\n\n"
        for item in geeknews_items[:5]:
            title = item.get("title", "")
            url = item.get("url", "")
            summary = item.get("summary", "")
            source_name = item.get("source_name", "GeekNews")

            content += f"### {title}\n\n"
            if summary:
                content += f"{summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source_name}]({url})\n\n"
        section_num += 1

    # AI/ML ì„¹ì…˜
    if topic_groups["AI/ML"]:
        content += f"## {section_num}. AI/ML íŠ¸ë Œë“œ\n\n"
        for i, item in enumerate(topic_groups["AI/ML"][:5], 1):
            title = item.get("title", "")
            url = item.get("url", "")
            source = item.get("source_name", item.get("source", "Unknown"))
            summary = item.get("summary", "")

            content += f"### {section_num}.{i} {title}\n\n"
            if summary:
                content += f"{summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source}]({url})\n\n"

            # Key points
            key_points = _generate_key_points(item)
            if key_points:
                content += "**í•µì‹¬ í¬ì¸íŠ¸:**\n\n"
                content += key_points + "\n"
        section_num += 1

    # DevOps/Cloud ì„¹ì…˜
    if topic_groups["DevOps/Cloud"]:
        content += f"## {section_num}. DevOps & Cloud\n\n"
        for i, item in enumerate(topic_groups["DevOps/Cloud"][:5], 1):
            title = item.get("title", "")
            url = item.get("url", "")
            source = item.get("source_name", item.get("source", "Unknown"))
            summary = item.get("summary", "")

            content += f"### {section_num}.{i} {title}\n\n"
            if summary:
                content += f"{summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source}]({url})\n\n"
        section_num += 1

    # Open Source ì„¹ì…˜
    if topic_groups["Open Source"]:
        content += f"## {section_num}. Open Source\n\n"
        for i, item in enumerate(topic_groups["Open Source"][:5], 1):
            title = item.get("title", "")
            url = item.get("url", "")
            source = item.get("source_name", item.get("source", "Unknown"))
            summary = item.get("summary", "")

            content += f"### {section_num}.{i} {title}\n\n"
            if summary:
                content += f"{summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source}]({url})\n\n"
        section_num += 1

    # General ì„¹ì…˜
    if topic_groups["General"]:
        content += f"## {section_num}. ê¸°íƒ€ ì£¼ëª©í•  ë‰´ìŠ¤\n\n"
        content += "| ì œëª© | ì¶œì²˜ | í•µì‹¬ ë‚´ìš© |\n"
        content += "|------|------|----------|\n"
        for item in topic_groups["General"][:5]:
            title = item.get("title", "")[:50]
            source = item.get("source_name", "")
            url = item.get("url", "")
            summary = item.get("summary", "")[:80]
            content += f"| [{title}...]({url}) | {source} | {summary}... |\n"
        content += "\n"
        section_num += 1

    # íŠ¸ë Œë“œ ë¶„ì„
    content += _generate_tech_trend_analysis(news_items, section_num)

    content += """
---

**ì‘ì„±ì**: Twodragon
"""

    return content


def _generate_tech_trend_analysis(news_items: List[Dict], section_num: int) -> str:
    """ê¸°ìˆ  ë¸”ë¡œê·¸ íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
    content = f"\n---\n\n## {section_num}. íŠ¸ë Œë“œ ë¶„ì„\n\n"

    trend_defs = {
        "AI/LLM": ["ai", "llm", "gpt", "claude", "gemini", "machine learning", "ì¸ê³µì§€ëŠ¥", "ìƒì„±í˜•"],
        "Cloud Native": ["cloud", "aws", "azure", "gcp", "serverless", "í´ë¼ìš°ë“œ"],
        "Container/K8s": ["kubernetes", "k8s", "container", "docker", "ì»¨í…Œì´ë„ˆ"],
        "Developer Tools": ["ide", "editor", "cli", "developer experience", "dx", "cursor", "copilot"],
        "Open Source": ["open source", "open-source", "oss", "github", "cncf"],
        "Programming Languages": ["rust", "golang", "typescript", "python", "java", "swift"],
        "Platform Engineering": ["platform", "internal developer", "golden path", "backstage"],
    }

    trend_results = []
    for trend_name, keywords in trend_defs.items():
        count = 0
        matched_kws = set()
        for item in news_items:
            text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
            for kw in keywords:
                if kw in text:
                    count += 1
                    matched_kws.add(kw)
                    break
        if count > 0:
            trend_results.append((trend_name, count, ", ".join(list(matched_kws)[:3])))

    trend_results.sort(key=lambda x: x[1], reverse=True)

    if trend_results:
        content += "| íŠ¸ë Œë“œ | ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ | ì£¼ìš” í‚¤ì›Œë“œ |\n"
        content += "|--------|-------------|------------|\n"
        for name, count, kws in trend_results[:7]:
            content += f"| **{name}** | {count}ê±´ | {kws} |\n"
        content += "\n"

        top = trend_results[0]
        content += f"ì´ë²ˆ ì£¼ê¸°ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ íŠ¸ë Œë“œëŠ” **{top[0]}** ({top[1]}ê±´)ì…ë‹ˆë‹¤. "
        if len(trend_results) > 1:
            second = trend_results[1]
            content += f"ê·¸ ë‹¤ìŒìœ¼ë¡œ **{second[0]}** ({second[1]}ê±´)ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. "
        content += "ê´€ë ¨ ê¸°ìˆ  ë™í–¥ì„ íŒŒì•…í•˜ê³  íŒ€ ë‚´ ê¸°ìˆ  ê³µìœ ì— í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n"
    else:
        content += "ì´ë²ˆ ì£¼ê¸°ì—ëŠ” ë‘ë“œëŸ¬ì§„ íŠ¸ë Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"

    return content


def _determine_severity(item: Dict) -> str:
    """ë‰´ìŠ¤ ì‹¬ê°ë„ ê²°ì •"""
    text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
    critical_keywords = [
        "critical", "rce", "zero-day", "ì œë¡œë°ì´", "0-day",
        "cvss 9", "cvss 10", "unauthenticated", "actively exploited",
    ]
    high_keywords = [
        "high", "ê¶Œí•œ ìƒìŠ¹", "privilege escalation",
        "authentication bypass", "ì¸ì¦ ìš°íšŒ", "ssrf", "injection",
    ]

    for kw in critical_keywords:
        if kw in text:
            return "Critical"
    for kw in high_keywords:
        if kw in text:
            return "High"
    return "Medium"


def _extract_cve_ids(item: Dict) -> List[str]:
    """ë‰´ìŠ¤ ì•„ì´í…œì—ì„œ ëª¨ë“  CVE ID ì¶”ì¶œ"""
    text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}"
    cves = re.findall(r'CVE-\d{4}-\d+', text)
    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
    seen = set()
    unique = []
    for cve in cves:
        if cve not in seen:
            seen.add(cve)
            unique.append(cve)
    return unique


def _generate_key_points(item: Dict) -> str:
    """ë‰´ìŠ¤ ì•„ì´í…œì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ"""
    summary = item.get("summary", "")
    if not summary:
        return ""

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ í•µì‹¬ í¬ì¸íŠ¸ ìƒì„±
    sentences = re.split(r'[.!?]\s+', summary)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 15]

    if not sentences:
        return ""

    points = ""
    for s in sentences[:4]:
        # ë§ˆì¹¨í‘œ ì œê±° í›„ í¬ì¸íŠ¸ë¡œ
        s = s.rstrip(".")
        points += f"- {s}\n"
    return points


def generate_news_section(item: Dict, section_num: str, is_critical: bool = False) -> str:
    """ê°œë³„ ë‰´ìŠ¤ ì„¹ì…˜ ìƒì„± - ê³ í’ˆì§ˆ ë¶„ì„ í¬í•¨"""
    title = item.get("title", "Untitled")
    url = item.get("url", "")
    source = item.get("source_name", item.get("source", "Unknown"))
    summary = item.get("summary", "")
    content_text = item.get("content", "")
    category = item.get("category", "tech")

    severity = _determine_severity(item)
    cve_ids = _extract_cve_ids(item)

    section = f"### {section_num} {title}\n\n"

    # ì‹¬ê°ë„ ë° CVE ë±ƒì§€
    if cve_ids or severity == "Critical":
        severity_emoji = {"Critical": "ğŸ”´", "High": "ğŸŸ ", "Medium": "ğŸŸ¡"}.get(severity, "ğŸŸ¡")
        section += f"> {severity_emoji} **ì‹¬ê°ë„**: {severity}"
        if cve_ids:
            section += f" | **CVE**: {', '.join(cve_ids[:5])}"
        section += "\n\n"

    # ê°œìš” ì¶”ê°€
    section += "#### ê°œìš”\n\n"
    if summary:
        section += f"{summary}\n\n"
    elif content_text:
        section += f"{content_text[:800]}...\n\n"

    section += f"> **ì¶œì²˜**: [{source}]({url})\n\n"

    # í•µì‹¬ í¬ì¸íŠ¸
    key_points = _generate_key_points(item)
    if key_points:
        section += "#### í•µì‹¬ í¬ì¸íŠ¸\n\n"
        section += key_points + "\n"

    # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë¶„ì„ í…œí”Œë¦¿
    if category in ("security", "devsecops") and is_critical:
        section += _generate_security_analysis_template(item)
    elif category in ("security", "devsecops"):
        section += _generate_security_brief_template(item)
    elif category == "ai":
        section += _generate_ai_analysis_template(item)
    elif category in ("cloud", "devops", "kubernetes"):
        section += _generate_devops_template()

    section += "\n---\n\n"
    return section


def _generate_security_analysis_template(item: Dict) -> str:
    """ë³´ì•ˆ ë‰´ìŠ¤ ìƒì„¸ ë¶„ì„ í…œí”Œë¦¿ - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜"""
    cve_ids = _extract_cve_ids(item)
    severity = _determine_severity(item)
    text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}".lower()

    # ëŒ€ì‘ ìš°ì„ ìˆœìœ„ ê²°ì •
    priority = "P0 - ì¦‰ì‹œ ëŒ€ì‘" if severity == "Critical" else "P1 - 7ì¼ ì´ë‚´ ê²€í†  ê¶Œì¥"

    template = "\n#### ìœ„í˜‘ ë¶„ì„\n\n"
    template += "| í•­ëª© | ë‚´ìš© |\n"
    template += "|------|------|\n"

    if cve_ids:
        template += f"| **CVE ID** | {', '.join(cve_ids[:5])} |\n"
    else:
        template += "| **CVE ID** | ë¯¸ê³µê°œ ë˜ëŠ” í•´ë‹¹ ì—†ìŒ |\n"

    template += f"| **ì‹¬ê°ë„** | {severity} |\n"
    template += f"| **ëŒ€ì‘ ìš°ì„ ìˆœìœ„** | {priority} |\n"
    template += "\n"

    # SIEM íƒì§€ íŒíŠ¸ (ì·¨ì•½ì  ìœ í˜• ê¸°ë°˜)
    siem_hints = []
    mitre_techniques = []

    if "rce" in text or "remote code execution" in text:
        siem_hints.append(
            '```splunk\nindex=security sourcetype=syslog ("exploit" OR "remote code execution" OR "shell")\n| stats count by src_ip, dest_ip, action\n| where count > 3\n```'
        )
        mitre_techniques.append("T1203 (Exploitation for Client Execution)")
    if "authentication" in text or "ì¸ì¦" in text or "auth bypass" in text:
        siem_hints.append(
            '```splunk\nindex=security sourcetype=auth ("bypass" OR "unauthorized" OR "failed_login")\n| stats count by user, src_ip\n| where count > 10\n```'
        )
        mitre_techniques.append("T1078 (Valid Accounts)")
    if "injection" in text or "sql" in text or "xss" in text:
        siem_hints.append(
            '```splunk\nindex=web sourcetype=access_combined (SELECT OR UNION OR script OR "\\x" OR "%27")\n| stats count by uri, src_ip\n| where count > 5\n```'
        )
        mitre_techniques.append("T1190 (Exploit Public-Facing Application)")
    if "supply chain" in text or "ê³µê¸‰ë§" in text:
        mitre_techniques.append("T1195 (Supply Chain Compromise)")
    if "zero-day" in text or "ì œë¡œë°ì´" in text or "0-day" in text:
        mitre_techniques.append("T1068 (Exploitation for Privilege Escalation)")
    if "privilege" in text or "ê¶Œí•œ ìƒìŠ¹" in text:
        mitre_techniques.append("T1068 (Exploitation for Privilege Escalation)")

    if siem_hints:
        template += "#### SIEM íƒì§€ ì¿¼ë¦¬ (ì°¸ê³ ìš©)\n\n"
        template += siem_hints[0] + "\n\n"

    if mitre_techniques:
        template += "#### MITRE ATT&CK ë§¤í•‘\n\n"
        for tech in mitre_techniques[:3]:
            template += f"- **{tech}**\n"
        template += "\n"

    template += """#### ê¶Œì¥ ì¡°ì¹˜

- [ ] ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œ/ì†Œí”„íŠ¸ì›¨ì–´ ì¸ë²¤í† ë¦¬ í™•ì¸
- [ ] ë²¤ë” íŒ¨ì¹˜ ë° ë³´ì•ˆ ê¶Œê³  í™•ì¸
- [ ] SIEM/EDR íƒì§€ ë£° ì—…ë°ì´íŠ¸ ê²€í† 
- [ ] í•„ìš”ì‹œ ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ ë˜ëŠ” ì„ì‹œ ì™„í™” ì¡°ì¹˜ ì ìš©
- [ ] ë³´ì•ˆíŒ€ ë‚´ ê³µìœ  ë° ëª¨ë‹ˆí„°ë§ ê°•í™”

"""
    return template


def _generate_security_brief_template(item: Dict = None) -> str:
    """ë³´ì•ˆ ë‰´ìŠ¤ ê°„ëµ ë¶„ì„ í…œí”Œë¦¿ - í† í”½ë³„ ë§ì¶¤ ì¡°ì–¸ ì œê³µ"""
    if item is None:
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ê´€ë ¨ ì‹œìŠ¤í…œ ëª©ë¡ í™•ì¸
- ë³´ì•ˆ ë‹´ë‹¹ìëŠ” ì›ë¬¸ì„ ê²€í† í•˜ì—¬ ìì‚¬ í™˜ê²½ í•´ë‹¹ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
- ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œì´ ìˆëŠ” ê²½ìš° ë²¤ë” ê¶Œê³ ì— ë”°ë¼ íŒ¨ì¹˜ ë˜ëŠ” ì™„í™” ì¡°ì¹˜ë¥¼ ì ìš©í•˜ì„¸ìš”
- SIEM íƒì§€ ë£°ì— ê´€ë ¨ IOCë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤

"""

    text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}".lower()

    # Ransomware-related advice
    if any(kw in text for kw in ["ransomware", "ëœì„¬ì›¨ì–´", "ransom", "encrypt"]):
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ë°±ì—… ì‹œìŠ¤í…œ ì •ìƒ ë™ì‘ ì—¬ë¶€ ì¦‰ì‹œ ê²€ì¦ (ì˜¤í”„ë¼ì¸ ë°±ì—… í¬í•¨)
- ì¸ì‹œë˜íŠ¸ ëŒ€ì‘ í”Œë ˆì´ë¶ ì ê²€ ë° ëœì„¬ì›¨ì–´ ì‹œë‚˜ë¦¬ì˜¤ í™•ì¸
- ë„¤íŠ¸ì›Œí¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìƒíƒœ í™•ì¸ ë° íš¡ì  ì´ë™ ì°¨ë‹¨ ê²€í† 
- EDR/XDR ì†”ë£¨ì…˜ì˜ ëœì„¬ì›¨ì–´ íƒì§€ ì •ì±… ìµœì‹  ìƒíƒœ í™•ì¸

"""

    # Authentication-related advice
    if any(kw in text for kw in ["authentication", "ì¸ì¦", "credential", "password", "mfa",
                                  "sso", "auth bypass", "ì¸ì¦ ìš°íšŒ", "login"]):
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ê´€ë ¨ ì‹œìŠ¤í…œì˜ ì¸ì¦ ì •ë³´(Credential) ì¦‰ì‹œ ë¡œí…Œì´ì…˜ ê²€í† 
- MFA(ë‹¤ì¤‘ ì¸ì¦) ì ìš© í˜„í™© ì ê²€ ë° ë¯¸ì ìš© ì‹œìŠ¤í…œ ì‹ë³„
- SSO/IdP ë¡œê·¸ì—ì„œ ë¹„ì •ìƒ ì¸ì¦ ì‹œë„ ëª¨ë‹ˆí„°ë§ ê°•í™”
- ì„œë¹„ìŠ¤ ê³„ì • ë° API í‚¤ ì‚¬ìš© í˜„í™© ê°ì‚¬

"""

    # Supply chain-related advice
    if any(kw in text for kw in ["supply chain", "ê³µê¸‰ë§", "dependency", "package",
                                  "npm", "pypi", "maven", "sbom"]):
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ì˜ì¡´ì„± ê°ì‚¬(dependency audit) ì¦‰ì‹œ ì‹¤í–‰: `npm audit`, `pip audit`, `bundle audit`
- SBOM(Software Bill of Materials) ìµœì‹  ìƒíƒœ í™•ì¸
- ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ê³ ì • ë° ë¬´ê²°ì„± ê²€ì¦(checksum/signature)
- CI/CD íŒŒì´í”„ë¼ì¸ì˜ ì˜ì¡´ì„± ìŠ¤ìº” ì •ì±… ì ê²€

"""

    # Default: improved generic with "ê´€ë ¨ ì‹œìŠ¤í…œ ëª©ë¡ í™•ì¸" as first item
    return """
#### ì‹¤ë¬´ ì˜í–¥

- ê´€ë ¨ ì‹œìŠ¤í…œ ëª©ë¡ í™•ì¸
- ë³´ì•ˆ ë‹´ë‹¹ìëŠ” ì›ë¬¸ì„ ê²€í† í•˜ì—¬ ìì‚¬ í™˜ê²½ í•´ë‹¹ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
- ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œì´ ìˆëŠ” ê²½ìš° ë²¤ë” ê¶Œê³ ì— ë”°ë¼ íŒ¨ì¹˜ ë˜ëŠ” ì™„í™” ì¡°ì¹˜ë¥¼ ì ìš©í•˜ì„¸ìš”
- SIEM íƒì§€ ë£°ì— ê´€ë ¨ IOCë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤

"""


def _generate_ai_analysis_template(item: Dict) -> str:
    """AI/ML ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„ í…œí”Œë¦¿"""
    title = item.get("title", "")
    summary = item.get("summary", "")

    template = """
#### AI/ML ë³´ì•ˆ ì˜í–¥ ë¶„ì„

- **ëª¨ë¸ ë³´ì•ˆ**: AI ëª¨ë¸ ë¬´ê²°ì„± ë° ì ëŒ€ì  ê³µê²© ëŒ€ì‘ í˜„í™© ì ê²€
- **ë°ì´í„° ë³´ì•ˆ**: í•™ìŠµ ë°ì´í„° ë° ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ê²€í†  í•„ìš”
- **ê±°ë²„ë„ŒìŠ¤**: AI ëª¨ë¸ ë°°í¬ ì „ ë³´ì•ˆ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸

#### ì‹¤ë¬´ ì ìš©

- AI/ML íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ì ê²€ í•­ëª© ê²€í† 
- ëª¨ë¸ ì…ì¶œë ¥ ê²€ì¦ ë¡œì§ ì¶”ê°€ ê²€í† 
- AI ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬ ëŒ€ë¹„ í˜„í™© ì ê²€

"""
    return template


def _generate_devops_template() -> str:
    return """
#### ì‹¤ë¬´ ì ìš© í¬ì¸íŠ¸

- ê¸°ì¡´ ì¸í”„ë¼/ìš´ì˜ í™˜ê²½ê³¼ì˜ í˜¸í™˜ì„± ë° ì˜í–¥ë„ ê²€í† 
- í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ë¨¼ì € ê²€ì¦ í›„ í”„ë¡œë•ì…˜ ì ìš© ê³„íš ìˆ˜ë¦½
- íŒ€ ë‚´ ê¸°ìˆ  ê³µìœ  ë° ë„ì… ë¡œë“œë§µ ë…¼ì˜

"""


def _generate_trend_analysis(news_items: List[Dict], section_num: int) -> str:
    """ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
    content = f"\n---\n\n## {section_num}. íŠ¸ë Œë“œ ë¶„ì„\n\n"

    # íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
    trend_defs = {
        "AI/ML": ["ai", "ml", "llm", "gpt", "machine learning", "ì¸ê³µì§€ëŠ¥", "ìƒì„±í˜•"],
        "Zero-Day": ["zero-day", "0-day", "ì œë¡œë°ì´"],
        "Cloud Security": ["cloud", "aws", "azure", "gcp", "í´ë¼ìš°ë“œ"],
        "Supply Chain": ["supply chain", "ê³µê¸‰ë§", "dependency", "package"],
        "Ransomware": ["ransomware", "ëœì„¬ì›¨ì–´"],
        "Container/K8s": ["kubernetes", "k8s", "container", "docker", "ì»¨í…Œì´ë„ˆ"],
        "Authentication": ["authentication", "ì¸ì¦", "credential", "identity", "sso"],
    }

    trend_results = []
    for trend_name, keywords in trend_defs.items():
        count = 0
        matched_kws = set()
        for item in news_items:
            text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
            for kw in keywords:
                if kw in text:
                    count += 1
                    matched_kws.add(kw)
                    break  # ë‰´ìŠ¤ë‹¹ 1ë²ˆë§Œ ì¹´ìš´íŠ¸
        if count > 0:
            trend_results.append((trend_name, count, ", ".join(list(matched_kws)[:3])))

    trend_results.sort(key=lambda x: x[1], reverse=True)

    if trend_results:
        content += "| íŠ¸ë Œë“œ | ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ | ì£¼ìš” í‚¤ì›Œë“œ |\n"
        content += "|--------|-------------|------------|\n"
        for name, count, kws in trend_results[:7]:
            content += f"| **{name}** | {count}ê±´ | {kws} |\n"
        content += "\n"

        # íŠ¸ë Œë“œ ë¶„ì„ ì½”ë©˜íŠ¸
        top = trend_results[0]
        content += f"ì´ë²ˆ ì£¼ê¸°ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ íŠ¸ë Œë“œëŠ” **{top[0]}** ({top[1]}ê±´)ì…ë‹ˆë‹¤. "
        if len(trend_results) > 1:
            second = trend_results[1]
            content += f"ê·¸ ë‹¤ìŒìœ¼ë¡œ **{second[0]}** ({second[1]}ê±´)ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. "
        content += "ì‹¤ë¬´ì—ì„œëŠ” í•´ë‹¹ íŠ¸ë Œë“œì™€ ê´€ë ¨ëœ ë³´ì•ˆ ì •ì±… ë° ëª¨ë‹ˆí„°ë§ ì²´ê³„ë¥¼ ì ê²€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n"
    else:
        content += "ì´ë²ˆ ì£¼ê¸°ì—ëŠ” ë‘ë“œëŸ¬ì§„ íŠ¸ë Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"

    return content


def _generate_news_specific_checklist(news_items: List[Dict]) -> str:
    """ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    content = "---\n\n## ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"

    p0_items = []
    p1_items = []

    for item in news_items:
        severity = _determine_severity(item)
        title = item.get("title", "")[:60]
        cve_ids = _extract_cve_ids(item)
        cve_str = f" ({', '.join(cve_ids[:2])})" if cve_ids else ""

        if severity == "Critical":
            p0_items.append(f"- [ ] **{title}**{cve_str} ê´€ë ¨ ê¸´ê¸‰ íŒ¨ì¹˜ ë° ì˜í–¥ë„ í™•ì¸")
        elif severity == "High":
            p1_items.append(f"- [ ] **{title}**{cve_str} ê´€ë ¨ ë³´ì•ˆ ê²€í†  ë° ëª¨ë‹ˆí„°ë§")

    content += "### P0 (ì¦‰ì‹œ)\n\n"
    if p0_items:
        content += "\n".join(p0_items[:5]) + "\n"
    else:
        content += "- [ ] ê¸´ê¸‰ ë³´ì•ˆ íŒ¨ì¹˜ ì ìš©\n"
        content += "- [ ] ì·¨ì•½ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê°•í™”\n"

    content += "\n### P1 (7ì¼ ë‚´)\n\n"
    if p1_items:
        content += "\n".join(p1_items[:5]) + "\n"
    else:
        content += "- [ ] SIEM íƒì§€ ë£° ì—…ë°ì´íŠ¸\n"
        content += "- [ ] ë³´ì•ˆ ì •ì±… ê²€í† \n"

    content += "\n### P2 (30ì¼ ë‚´)\n\n"
    content += "- [ ] ê³µê²© í‘œë©´ ì¸ë²¤í† ë¦¬ ê°±ì‹ \n"
    content += "- [ ] ì ‘ê·¼ ì œì–´ ê°ì‚¬\n"

    return content


# ============================================================================
# SVG ì´ë¯¸ì§€ ìƒì„± - ê³ í’ˆì§ˆ ì¹´ë“œ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ
# ============================================================================

# ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë¼ë””ì–¸íŠ¸ ë° ì•„ì´ì½˜ ì„¤ì •
CATEGORY_SVG_CONFIG = {
    "security": {
        "gradient": ("dc2626", "991b1b"),  # red
        "label": "SECURITY",
        "icon": "!",
        "icon_color": "#dc2626",
    },
    "cloud": {
        "gradient": ("10b981", "059669"),  # green
        "label": "CLOUD",
        "icon": "AWS",
        "icon_color": "#10b981",
    },
    "devops": {
        "gradient": ("f59e0b", "d97706"),  # orange
        "label": "DEVOPS",
        "icon": "DEV",
        "icon_color": "#f59e0b",
    },
    "tech": {
        "gradient": ("3b82f6", "1d4ed8"),  # blue
        "label": "TECH",
        "icon": "AI",
        "icon_color": "#3b82f6",
    },
    "devsecops": {
        "gradient": ("8b5cf6", "6d28d9"),  # purple
        "label": "DEVSECOPS",
        "icon": "SEC",
        "icon_color": "#8b5cf6",
    },
    "ai": {
        "gradient": ("6366f1", "4f46e5"),  # indigo
        "label": "AI/ML",
        "icon": "AI",
        "icon_color": "#6366f1",
    },
    "blockchain": {
        "gradient": ("f97316", "ea580c"),  # orange
        "label": "BLOCKCHAIN",
        "icon": "BC",
        "icon_color": "#f97316",
    },
}


def _escape_svg_text(text: str) -> str:
    """SVG í…ìŠ¤íŠ¸ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬"""
    return (
        text.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&#39;")
    )


def _to_english_svg_text(text: str) -> str:
    """SVG í…ìŠ¤íŠ¸ì—ì„œ ë¹„ì˜ë¬¸ ë¬¸ì ì œê±° (SVGëŠ” ì˜ë¬¸ë§Œ í—ˆìš©)"""
    result = []
    for char in text:
        if ord(char) < 128:  # ASCII
            result.append(char)
        elif unicodedata.category(char).startswith('L'):
            # Non-ASCII letter - skip (Korean, etc.)
            continue
        else:
            result.append(' ')
    # Clean up multiple spaces
    cleaned = ' '.join(''.join(result).split())
    if not cleaned.strip():
        return "Security News Update"
    return cleaned.strip()


def _truncate_text(text: str, max_len: int) -> str:
    """í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ì˜ë¬¸ ê¸°ì¤€)"""
    if len(text) <= max_len:
        return text
    return text[: max_len - 3] + "..."


def _extract_key_topics(news_items: List[Dict]) -> List[str]:
    """ë‰´ìŠ¤ì—ì„œ í•µì‹¬ í† í”½ ì¶”ì¶œ"""
    topics = []
    keywords = [
        "Zero-Day",
        "CVE",
        "Vulnerability",
        "Patch",
        "Update",
        "AI",
        "ML",
        "Cloud",
        "Kubernetes",
        "Docker",
        "AWS",
        "Azure",
        "GCP",
        "Security",
        "Threat",
        "Malware",
        "Ransomware",
        "Botnet",
        "Bitcoin",
        "Ethereum",
        "DeFi",
        "Web3",
        "Blockchain",
        "LLM",
        "GPT",
        "Agent",
        "Data",
        "Palantir",
        "Tesla",
        "Apple",
        "Rust",
        "Go",
        "Open-Source",
        "API",
    ]

    for item in news_items[:6]:
        title = item.get("title", "")
        for kw in keywords:
            if kw.lower() in title.lower() and kw not in topics:
                topics.append(kw)
                if len(topics) >= 4:
                    return topics
    return topics[:4] if topics else ["Security", "Cloud", "DevOps", "AI"]


def generate_svg_image(
    date: datetime, categorized: Dict[str, List[Dict]], news_items: List[Dict]
) -> str:
    """ê³ í’ˆì§ˆ SVG ì´ë¯¸ì§€ ìƒì„± - ì¹´ë“œ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ"""

    date_display = date.strftime("%B %d, %Y")
    date_short = date.strftime("%Y.%m.%d")

    # í†µê³„ ê³„ì‚°
    total = sum(len(items) for items in categorized.values())
    stats = {cat: len(items) for cat, items in categorized.items()}

    # í•µì‹¬ í† í”½ ì¶”ì¶œ
    topics = _extract_key_topics(news_items)
    subtitle_topics = " | ".join(_to_english_svg_text(t) for t in topics)

    # ìƒìœ„ ë‰´ìŠ¤ 6ê°œ ì„ íƒ (ì¹´ë“œìš©)
    top_items = news_items[:6]

    # SVG í—¤ë” ë° ì •ì˜
    svg = f'''<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1200 630">
  <defs>
    <!-- Background Gradient -->
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#0f0f23"/>
      <stop offset="50%" style="stop-color:#1a1a3e"/>
      <stop offset="100%" style="stop-color:#0d1117"/>
    </linearGradient>

    <!-- Card Gradient -->
    <linearGradient id="cardGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#1e293b"/>
      <stop offset="100%" style="stop-color:#0f172a"/>
    </linearGradient>

    <!-- Category Gradients -->
    <linearGradient id="redGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#dc2626"/>
      <stop offset="100%" style="stop-color:#991b1b"/>
    </linearGradient>
    <linearGradient id="blueGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#3b82f6"/>
      <stop offset="100%" style="stop-color:#1d4ed8"/>
    </linearGradient>
    <linearGradient id="purpleGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#8b5cf6"/>
      <stop offset="100%" style="stop-color:#6d28d9"/>
    </linearGradient>
    <linearGradient id="greenGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#10b981"/>
      <stop offset="100%" style="stop-color:#059669"/>
    </linearGradient>
    <linearGradient id="orangeGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f59e0b"/>
      <stop offset="100%" style="stop-color:#d97706"/>
    </linearGradient>
    <linearGradient id="indigoGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#6366f1"/>
      <stop offset="100%" style="stop-color:#4f46e5"/>
    </linearGradient>

    <!-- Glow Filter -->
    <filter id="glow" x="-50%" y="-50%" width="200%" height="200%">
      <feGaussianBlur stdDeviation="3" result="blur"/>
      <feMerge>
        <feMergeNode in="blur"/>
        <feMergeNode in="SourceGraphic"/>
      </feMerge>
    </filter>

    <!-- Shadow Filter -->
    <filter id="shadow" x="-20%" y="-20%" width="140%" height="140%">
      <feDropShadow dx="0" dy="4" stdDeviation="8" flood-color="#000" flood-opacity="0.3"/>
    </filter>
    <pattern id="grid" width="30" height="30" patternUnits="userSpaceOnUse">
      <path d="M 30 0 L 0 0 0 30" fill="none" stroke="#334155" stroke-width="0.3" opacity="0.4"/>
    </pattern>
    <pattern id="dots" width="20" height="20" patternUnits="userSpaceOnUse">
      <circle cx="2" cy="2" r="0.8" fill="#475569" opacity="0.3"/>
    </pattern>
  </defs>

  <!-- Background -->
  <rect width="1200" height="630" fill="url(#bgGradient)"/>

  <!-- Grid Pattern -->
  <pattern id="grid" width="40" height="40" patternUnits="userSpaceOnUse">
    <path d="M 40 0 L 0 0 0 40" fill="none" stroke="#ffffff" stroke-opacity="0.03" stroke-width="1"/>
  </pattern>
  <rect width="1200" height="630" fill="url(#grid)"/>

  <!-- Decorative Circles -->
  <circle cx="100" cy="100" r="200" fill="#3b82f6" fill-opacity="0.05"/>
  <circle cx="1100" cy="530" r="250" fill="#8b5cf6" fill-opacity="0.05"/>
  <circle cx="600" cy="315" r="300" fill="#dc2626" fill-opacity="0.03"/>

  <!-- Header Section -->
  <rect x="40" y="30" width="200" height="36" rx="18" fill="url(#redGradient)" filter="url(#shadow)"/>
  <text x="140" y="54" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">WEEKLY DIGEST</text>

  <!-- Date Badge -->
  <rect x="960" y="30" width="200" height="36" rx="18" fill="url(#blueGradient)" filter="url(#shadow)"/>
  <text x="1060" y="54" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">{date_display}</text>

  <!-- Main Title -->
  <text x="600" y="110" font-family="Arial, sans-serif" font-size="42" font-weight="bold" fill="white" text-anchor="middle" filter="url(#glow)">Tech &amp; Security Weekly Digest</text>
  <text x="600" y="155" font-family="Arial, sans-serif" font-size="20" fill="#94a3b8" text-anchor="middle">{_escape_svg_text(subtitle_topics)}</text>
'''

    # ì¹´ë“œ ë ˆì´ì•„ì›ƒ ìƒì„± (ìµœëŒ€ 6ê°œ ì¹´ë“œ, 3x2 ê·¸ë¦¬ë“œ)
    card_positions = [
        (50, 190, 340, 180),  # Row 1, Card 1
        (430, 190, 340, 180),  # Row 1, Card 2
        (810, 190, 340, 180),  # Row 1, Card 3
        (50, 400, 340, 160),  # Row 2, Card 1
        (430, 400, 340, 160),  # Row 2, Card 2
        (810, 400, 340, 160),  # Row 2, Card 3
    ]

    gradient_map = {
        "security": "redGradient",
        "devsecops": "purpleGradient",
        "ai": "indigoGradient",
        "cloud": "greenGradient",
        "devops": "orangeGradient",
        "blockchain": "orangeGradient",
        "tech": "blueGradient",
    }

    for idx, item in enumerate(top_items):
        if idx >= len(card_positions):
            break

        x, y, width, height = card_positions[idx]
        category = item.get("category", "tech")
        if category in ("security", "devsecops"):
            category_display = "security"
        elif category in ("devops", "kubernetes"):
            category_display = "devops"
        elif category == "ai":
            category_display = "ai"
        elif category == "blockchain":
            category_display = "blockchain"
        else:
            category_display = category

        config = CATEGORY_SVG_CONFIG.get(category_display, CATEGORY_SVG_CONFIG["tech"])
        gradient = gradient_map.get(category_display, "blueGradient")

        title = _escape_svg_text(_truncate_text(_to_english_svg_text(item.get("title", "News Update")), 35))
        source = _escape_svg_text(
            _truncate_text(_to_english_svg_text(item.get("source_name", item.get("source", "Source"))), 15)
        )

        # ìš”ì•½ ë˜ëŠ” ì»¨í…ì¸ ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
        summary = item.get("summary", item.get("content", ""))
        summary_lines = []
        if summary:
            words = summary.split()
            line = ""
            for word in words:
                if len(line + " " + word) > 40:
                    summary_lines.append(line.strip())
                    line = word
                    if len(summary_lines) >= 2:
                        break
                else:
                    line = line + " " + word if line else word
            if line and len(summary_lines) < 2:
                summary_lines.append(line.strip())

        svg += f'''
  <!-- Card {idx + 1}: {config["label"]} -->
  <g transform="translate({x}, {y})">
    <rect width="{width}" height="{height}" rx="16" fill="url(#cardGradient)" filter="url(#shadow)"/>
    <rect x="0" y="0" width="{width}" height="6" rx="3" fill="url(#{gradient})"/>

    <!-- Icon -->
    <circle cx="40" cy="50" r="24" fill="url(#{gradient})" fill-opacity="0.2"/>
    <text x="40" y="58" font-family="Arial, sans-serif" font-size="16" fill="{config["icon_color"]}" text-anchor="middle">{config["icon"]}</text>

    <text x="80" y="45" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="{config["icon_color"]}">{config["label"]}</text>
    <text x="80" y="65" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">{title}</text>
'''

        # ìš”ì•½ ë¼ì¸ ì¶”ê°€
        for line_idx, line in enumerate(summary_lines[:2]):
            y_offset = 95 + line_idx * 18
            svg += f'    <text x="20" y="{y_offset}" font-family="Arial, sans-serif" font-size="12" fill="#94a3b8">{_escape_svg_text(_to_english_svg_text(line))}</text>\n'

        # ì†ŒìŠ¤ ë°°ì§€
        badge_y = height - 25 if height > 160 else height - 20
        svg += f'''
    <rect x="20" y="{badge_y}" width="100" height="18" rx="9" fill="url(#{gradient})" fill-opacity="0.2"/>
    <text x="70" y="{badge_y + 13}" font-family="Arial, sans-serif" font-size="10" fill="{config["icon_color"]}" text-anchor="middle">{source}</text>
  </g>
'''

    # Footer ì„¹ì…˜
    svg += f'''
  <!-- Footer -->
  <line x1="50" y1="585" x2="1150" y2="585" stroke="#334155" stroke-width="1"/>

  <!-- Stats -->
  <g transform="translate(50, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{total} News Collected</text>
  </g>
  <g transform="translate(250, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("security", 0)} Security</text>
  </g>
  <g transform="translate(400, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("cloud", 0)} Cloud</text>
  </g>
  <g transform="translate(520, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("devops", 0)} DevOps</text>
  </g>
  <g transform="translate(650, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("ai", 0)} AI/ML</text>
  </g>

  <!-- Blog Info -->
  <text x="1150" y="612" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#94a3b8" text-anchor="end">tech.2twodragon.com</text>
</svg>'''

    return svg


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================


def main():
    parser = argparse.ArgumentParser(description="Auto publish news to _posts")
    parser.add_argument(
        "--dry-run", action="store_true", help="Preview without publishing"
    )
    parser.add_argument("--hours", type=int, default=24, help="Hours to look back")
    parser.add_argument("--max-news", type=int, default=15, help="Maximum news items")
    parser.add_argument(
        "--mode",
        choices=["security", "tech-blog"],
        default="security",
        help="Post mode: security (default) or tech-blog digest",
    )
    parser.add_argument(
        "--force", action="store_true", help="Force publish even if same-day post exists"
    )
    args = parser.parse_args()

    print(f"ğŸ“° Auto Publish News (mode: {args.mode})")
    print("=" * 50)

    # Load news
    news_data = load_collected_news()
    print(f"âœ… Loaded {news_data.get('total_items', 0)} news items")

    # Data freshness check
    collected_at_str = news_data.get("collected_at", "")
    if collected_at_str:
        try:
            collected_at = datetime.fromisoformat(
                collected_at_str.replace("Z", "+00:00")
            )
            data_age_hours = (
                datetime.now(timezone.utc) - collected_at
            ).total_seconds() / 3600
            if data_age_hours > 24:
                print(f"âš ï¸ Data is {data_age_hours:.1f}h old. Time filter will be relaxed automatically.")
        except (ValueError, TypeError):
            pass

    # Filter and categorize
    filtered = filter_and_prioritize_news(news_data, hours=args.hours)
    if len(filtered) < MIN_NEWS_COUNT:
        print(f"âš ï¸ Not enough news ({len(filtered)} < {MIN_NEWS_COUNT}). Skipping.")
        return

    categorized = categorize_news(filtered)

    # Date setup
    now = datetime.now(timezone(timedelta(hours=9)))  # KST
    date_str = now.strftime("%Y-%m-%d")

    # Duplicate check - detect both auto-generated and manual post patterns
    if not args.force:
        existing = list(POSTS_DIR.glob(f"{date_str}-*.md"))
        if args.mode == "security":
            # Keep only security-related digest posts (exclude tech-only posts)
            existing = [p for p in existing if "Tech_Blog_Weekly" not in p.name
                        and "Weekly_Tech" not in p.name
                        and ("Security" in p.name or "Digest" in p.name)]
        else:
            # Keep only tech-blog-related digest posts (exclude security-only posts)
            existing = [p for p in existing if "Tech_Security_Weekly" not in p.name
                        and "Weekly_Security" not in p.name
                        and ("Tech" in p.name or "Digest" in p.name)]
        if existing:
            print(f"â­ï¸ Same-day {args.mode} post already exists: {existing[0].name}")
            print("   Use --force to override.")
            return

    if args.mode == "tech-blog":
        # Filter for tech blog content only
        tech_categorized = {
            k: v for k, v in categorized.items()
            if k in ("tech", "devops", "ai", "cloud")
        }
        if not tech_categorized:
            print("âš ï¸ No tech blog content found. Skipping.")
            return
        selected = select_top_news(tech_categorized, args.max_news)
        topics = _extract_key_topics(selected)
        topics_slug = "_".join(topics[:3]) if topics else "Tech"

        post_content = generate_tech_blog_content(selected, tech_categorized, now, topics_slug)
        post_filename = f"{date_str}-Tech_Blog_Weekly_Digest_{topics_slug}.md"
        svg_filename = f"{date_str}-Tech_Blog_Weekly_Digest_{topics_slug}.svg"
    else:
        selected = select_top_news(categorized, args.max_news)
        topics = _extract_key_topics(selected)
        topics_slug = "_".join(topics[:4]) if topics else "News"

        post_content = generate_post_content(selected, categorized, now, topics_slug)
        post_filename = f"{date_str}-Tech_Security_Weekly_Digest_{topics_slug}.md"
        svg_filename = f"{date_str}-Tech_Security_Weekly_Digest_{topics_slug}.svg"

    post_path = POSTS_DIR / post_filename
    svg_path = IMAGES_DIR / svg_filename

    print(f"âœ… Selected {len(selected)} top news items")
    for cat, items in categorized.items():
        print(f"   - {cat}: {len(items)} items")

    # Generate SVG
    svg_content = generate_svg_image(now, categorized, selected)

    # Existing post protection
    if post_path.exists():
        existing_size = post_path.stat().st_size
        new_size = len(post_content.encode("utf-8"))
        if existing_size > new_size and not args.force:
            print(f"â­ï¸ Existing post is larger ({existing_size}B > {new_size}B). Skipping to preserve manual post.")
            print(f"   File: {post_path}")
            return
        else:
            print(f"ğŸ“ Overwriting existing post ({existing_size}B â†’ {new_size}B)")

    if args.dry_run:
        print(f"\nğŸ“ [DRY RUN] Would create:")
        print(f"   - Post: {post_path}")
        print(f"   - Image: {svg_path}")
        print(f"\n--- Post Preview (first 500 chars) ---")
        print(post_content[:500])
        return

    # Save files
    POSTS_DIR.mkdir(parents=True, exist_ok=True)
    IMAGES_DIR.mkdir(parents=True, exist_ok=True)

    with open(post_path, "w", encoding="utf-8") as f:
        f.write(post_content)
    print(f"âœ… Created post: {post_path}")

    with open(svg_path, "w", encoding="utf-8") as f:
        f.write(svg_content)
    print(f"âœ… Created image: {svg_path}")

    print(f"\nğŸ‰ Auto publish completed! (mode: {args.mode})")


if __name__ == "__main__":
    main()
