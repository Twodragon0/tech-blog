#!/usr/bin/env python3
"""
Auto Publish News - ìë™ ë‰´ìŠ¤ í¬ìŠ¤íŠ¸ ë°œí–‰ ìŠ¤í¬ë¦½íŠ¸

RSSì—ì„œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ í’ˆì§ˆ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìë™ ìƒì„±í•˜ê³ 
_posts í´ë”ì— ì§ì ‘ ë°œí–‰í•©ë‹ˆë‹¤.

Features:
- AI ìš”ì•½ ì¹´ë“œ ìë™ ìƒì„±
- SVG ì´ë¯¸ì§€ ìë™ ìƒì„±
- ê¸°ì¡´ í¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ê³¼ ì¼ê´€ì„± ìœ ì§€
- ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ë° ë¶„ì„
- ë³´ì•ˆ ë‹¤ì´ì œìŠ¤íŠ¸ / í…Œí¬ ë¸”ë¡œê·¸ ë‹¤ì´ì œìŠ¤íŠ¸ ëª¨ë“œ ì§€ì›

Usage:
    python3 scripts/auto_publish_news.py
    python3 scripts/auto_publish_news.py --dry-run
    python3 scripts/auto_publish_news.py --hours 48
    python3 scripts/auto_publish_news.py --mode tech-blog
    python3 scripts/auto_publish_news.py --mode security --force
"""

import argparse
import html
import json
import logging
import os
import re
import subprocess
import sys
import unicodedata
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import defaultdict

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

# ============================================================================
# ì„¤ì •
# ============================================================================

POSTS_DIR = Path("_posts")
IMAGES_DIR = Path("assets/images")
DATA_DIR = Path("_data")  # ì‹¤ì œ ë°ì´í„° ë””ë ‰í† ë¦¬
KOREAN_SUMMARY_CACHE: Dict[str, str] = {}
KOREAN_TITLE_CACHE: Dict[str, str] = {}

CATEGORY_PRIORITY = {
    "security": 1,
    "devsecops": 2,
    "ai": 3,
    "cloud": 4,
    "devops": 5,
    "blockchain": 6,
    "tech": 7,
}

CATEGORY_EMOJI = {
    "security": "ğŸ”’",
    "devsecops": "ğŸ›¡ï¸",
    "ai": "ğŸ¤–",
    "cloud": "â˜ï¸",
    "devops": "âš™ï¸",
    "tech": "ğŸ’»",
    "kubernetes": "ğŸš€",
    "blockchain": "â›“ï¸",
    "finops": "ğŸ’°",
}

CATEGORY_COLOR = {
    "security": "#ef4444",
    "devsecops": "#8b5cf6",
    "ai": "#6366f1",
    "cloud": "#22c55e",
    "devops": "#f59e0b",
    "blockchain": "#f97316",
    "tech": "#3b82f6",
}

SOURCE_PRIORITY = {
    "thehackernews": 1,
    "microsoft_security": 1,
    "aws_security": 1,
    "gcp": 2,
    "hashicorp": 2,
    "cncf": 2,
    "geeknews": 2,
    "hackernews": 3,
    "skshieldus": 2,
    "skshieldus_report": 2,
    "palantir": 1,
    "openai": 1,
    "google_ai": 1,
    "meta_engineering": 1,
    "huggingface": 2,
    "google_research": 1,
    "netflix_tech": 2,
    "bitcoin_magazine": 1,
    "cointelegraph": 2,
    "vitalik": 1,
    "chainalysis": 1,
    "microsoft_devblogs": 1,
    "microsoft_dotnet": 2,
    "tesla": 1,
    "electrek": 2,
    "github_blog": 1,
    "stripe": 2,
    "slack_engineering": 2,
    "x_engineering": 1,
    "apple_ml": 1,
    "spotify_engineering": 2,
    "discord": 2,
    "docker": 1,
    "google_developers": 1,
    "rust_lang": 2,
    "golang": 2,
    "apple_developer": 1,
    "apple_newsroom": 2,
    "webkit": 2,
}

# Tech blog sources (non-security, non-blockchain)
TECH_BLOG_SOURCES = {
    "geeknews",
    "hackernews",
    "palantir",
    "openai",
    "google_ai",
    "meta_engineering",
    "huggingface",
    "google_research",
    "netflix_tech",
    "microsoft_devblogs",
    "microsoft_dotnet",
    "tesla",
    "electrek",
    "github_blog",
    "stripe",
    "slack_engineering",
    "x_engineering",
    "apple_ml",
    "spotify_engineering",
    "discord",
    "docker",
    "google_developers",
    "rust_lang",
    "golang",
    "apple_developer",
    "apple_newsroom",
    "webkit",
    "hashicorp",
    "cncf",
    "gcp",
}

MIN_NEWS_COUNT = 5  # ìµœì†Œ ë‰´ìŠ¤ ìˆ˜
MAX_NEWS_PER_CATEGORY = 5  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜


# ============================================================================
# ë‰´ìŠ¤ ë¡œë“œ ë° í•„í„°ë§
# ============================================================================


def load_collected_news() -> Dict:
    """ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¡œë“œ"""
    news_file = DATA_DIR / "collected_news.json"
    if not news_file.exists():
        print("âŒ No collected news found. Run collect_tech_news.py first.")
        sys.exit(1)

    with open(news_file, "r", encoding="utf-8") as f:
        return json.load(f)


def filter_and_prioritize_news(news_data: Dict, hours: int = 24) -> List[Dict]:
    """ë‰´ìŠ¤ í•„í„°ë§ ë° ìš°ì„ ìˆœìœ„ ì •ë ¬ (í”„ë¡œê·¸ë ˆì‹œë¸Œ ì™„í™” í¬í•¨)"""
    items = news_data.get("items", [])
    if not items:
        return []

    # collected_at ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì‹ ì„ ë„ í™•ì¸
    collected_at_str = news_data.get("collected_at", "")
    data_age_hours = 0
    if collected_at_str:
        try:
            collected_at = datetime.fromisoformat(
                collected_at_str.replace("Z", "+00:00")
            )
            data_age_hours = (
                datetime.now(timezone.utc) - collected_at
            ).total_seconds() / 3600
            print(
                f"  ğŸ“… Data age: {data_age_hours:.1f}h (collected at {collected_at_str})"
            )
        except (ValueError, TypeError):
            pass

    # ë°ì´í„°ê°€ ì˜¤ë˜ëœ ê²½ìš° ì‹œê°„ ìœˆë„ìš°ë¥¼ ìë™ í™•ì¥
    effective_hours = hours + data_age_hours

    # í”„ë¡œê·¸ë ˆì‹œë¸Œ ì™„í™”: hours â†’ hours*2 â†’ hours*3 â†’ ì „ì²´
    time_windows = [hours, effective_hours, hours * 2, hours * 3]

    for window in time_windows:
        cutoff = datetime.now(timezone.utc) - timedelta(hours=window)
        filtered = _filter_by_cutoff(items, cutoff)
        if len(filtered) >= MIN_NEWS_COUNT:
            if window > hours:
                print(
                    f"  â° Time window relaxed: {hours}h â†’ {window:.0f}h ({len(filtered)} items)"
                )
            break
    else:
        # ëª¨ë“  ìœˆë„ìš°ì—ì„œ ë¶€ì¡±í•˜ë©´ ì „ì²´ ì•„ì´í…œì„ ë‚ ì§œìˆœ ì •ë ¬ í›„ ì‚¬ìš©
        print(
            f"  âš ï¸ All time windows insufficient. Using all {len(items)} items sorted by date."
        )
        filtered = sorted(
            items,
            key=lambda x: x.get("published", ""),
            reverse=True,
        )

    # Deprioritize items with empty summary AND empty content
    for item in filtered:
        summary = item.get("summary", "").strip()
        content_text = item.get("content", "").strip()
        if not summary and not content_text:
            item["_empty_content"] = True

    # Group related Bitcoin/crypto crash stories - deduplicate
    filtered = _deduplicate_crypto_stories(filtered)

    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    def get_priority(item):
        source_priority = SOURCE_PRIORITY.get(item.get("source", ""), 5)
        category_priority = CATEGORY_PRIORITY.get(item.get("category", "tech"), 5)
        # Items with empty content get deprioritized
        empty_penalty = 10 if item.get("_empty_content") else 0
        return (empty_penalty, source_priority, category_priority)

    filtered.sort(key=get_priority)
    return filtered


def _deduplicate_crypto_stories(items: List[Dict]) -> List[Dict]:
    """Group related Bitcoin/crypto crash stories and keep only the 2 most substantive"""
    crypto_keywords = ["bitcoin", "btc", "crypto", "cryptocurrency"]
    price_keywords = [
        "crash",
        "drop",
        "fall",
        "plunge",
        "dump",
        "price",
        "surge",
        "rally",
    ]

    crypto_price_items = []
    other_items = []

    for item in items:
        text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
        is_crypto = any(kw in text for kw in crypto_keywords)
        is_price = any(kw in text for kw in price_keywords)
        category = item.get("category", "")

        if category == "blockchain" and is_crypto and is_price:
            crypto_price_items.append(item)
        else:
            other_items.append(item)

    if len(crypto_price_items) >= 3:
        # Keep the 2 most substantive (longest summary + content)
        crypto_price_items.sort(
            key=lambda x: len(x.get("summary", "")) + len(x.get("content", "")),
            reverse=True,
        )
        other_items.extend(crypto_price_items[:2])
    else:
        other_items.extend(crypto_price_items)

    return other_items


def _filter_by_cutoff(items: List[Dict], cutoff: datetime) -> List[Dict]:
    """cutoff ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë‰´ìŠ¤ í•„í„°ë§"""
    filtered = []
    for item in items:
        try:
            pub_date = datetime.fromisoformat(
                item.get("published", "").replace("Z", "+00:00")
            )
            if pub_date >= cutoff:
                filtered.append(item)
        except (ValueError, TypeError):
            # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í¬í•¨
            filtered.append(item)
    return filtered


def categorize_news(items: List[Dict]) -> Dict[str, List[Dict]]:
    """ë‰´ìŠ¤ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    categorized = defaultdict(list)

    for item in items:
        category = item.get("category", "tech")
        # security, devsecopsëŠ” securityë¡œ í†µí•©
        if category in ("security", "devsecops"):
            category = "security"
        elif category == "kubernetes":
            category = "devops"
        # ai, blockchainì€ ë…ë¦½ ì¹´í…Œê³ ë¦¬ë¡œ ìœ ì§€
        # cloud, devops, techë„ ê·¸ëŒ€ë¡œ ìœ ì§€

        if len(categorized[category]) < MAX_NEWS_PER_CATEGORY:
            # Filter out stale items for non-security categories
            if category not in ("security", "devsecops"):
                # Check URL for old year indicators (e.g., /2023/ or /2024/)
                url = item.get("url", "")
                current_year = datetime.now(timezone.utc).year
                url_year_match = re.search(r"/(\d{4})/", url)
                if url_year_match:
                    url_year = int(url_year_match.group(1))
                    if 2000 <= url_year < current_year - 1:
                        continue
                # Also check published date
                try:
                    pub_date = datetime.fromisoformat(
                        item.get("published", "").replace("Z", "+00:00")
                    )
                    if (datetime.now(timezone.utc) - pub_date).days > 90:
                        continue
                except (ValueError, TypeError):
                    pass
            categorized[category].append(item)

    return dict(categorized)


def select_top_news(
    categorized: Dict[str, List[Dict]], max_total: int = 15
) -> List[Dict]:
    """ìƒìœ„ ë‰´ìŠ¤ ì„ íƒ"""
    selected = []

    # ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì„ íƒ
    for category in sorted(
        categorized.keys(), key=lambda c: CATEGORY_PRIORITY.get(c, 5)
    ):
        for item in categorized[category]:
            if len(selected) >= max_total:
                break
            selected.append(item)

    return selected


# ============================================================================
# AI ê°•í™” ì‹œìŠ¤í…œ (Gemini CLI + DeepSeek API í´ë°± ì²´ì¸)
# ============================================================================


def check_gemini_available() -> bool:
    """Gemini CLI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        result = subprocess.run(["gemini", "--version"], capture_output=True, timeout=5)
        return result.returncode == 0
    except (subprocess.TimeoutExpired, FileNotFoundError):
        return False


def enhance_with_gemini(item: Dict, max_retries: int = 2) -> str:
    """Gemini CLIë¡œ ë‰´ìŠ¤ ì‹¬ì¸µ ë¶„ì„ (ë¬´ë£Œ)

    Args:
        item: ë‰´ìŠ¤ ì•„ì´í…œ ë”•ì…”ë„ˆë¦¬ (title, summary, url í•„ìˆ˜)
        max_retries: ì¬ì‹œë„ íšŸìˆ˜

    Returns:
        Geminiê°€ ìƒì„±í•œ ì‹¬ì¸µ ë¶„ì„ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´)
    """
    title = item.get("title", "")
    summary = item.get("summary", "")
    url = item.get("url", "")

    if not title:
        logging.warning("enhance_with_gemini: No title found, skipping")
        return ""

    prompt = f"""ë‹¤ìŒ ë³´ì•ˆ/ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ DevSecOps ì‹¤ë¬´ì ê´€ì ì—ì„œ ë¶„ì„:
ì œëª©: {title}
ìš”ì•½: {summary}
ì¶œì²˜: {url}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„± (500-800ì):
1. ê¸°ìˆ ì  ë°°ê²½ ë° ìœ„í˜‘ ë¶„ì„ (3-5ë¬¸ì¥)
2. ì‹¤ë¬´ ì˜í–¥ ë¶„ì„ (êµ¬ì²´ì  ì‹œìŠ¤í…œ/ë„êµ¬ ëª…ì‹œ)
3. ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ (- [ ] í˜•ì‹, 3-5ê°œ)
4. MITRE ATT&CK ë§¤í•‘ (í•´ë‹¹ ì‹œ)

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±."""

    for attempt in range(max_retries):
        try:
            result = subprocess.run(
                ["gemini", "-p", prompt], capture_output=True, text=True, timeout=60
            )

            if result.returncode == 0 and len(result.stdout.strip()) > 100:
                enhanced = result.stdout.strip()
                logging.info(f"Gemini enhanced content for: {title[:50]}...")
                return enhanced
            else:
                logging.warning(
                    f"Gemini returned insufficient content (attempt {attempt + 1}/{max_retries}): "
                    f"returncode={result.returncode}, length={len(result.stdout)}"
                )

        except subprocess.TimeoutExpired:
            logging.warning(f"Gemini CLI timeout (attempt {attempt + 1}/{max_retries})")
        except Exception as e:
            logging.warning(
                f"Gemini CLI error (attempt {attempt + 1}/{max_retries}): {e}"
            )

    logging.info(
        f"Gemini enhancement failed after {max_retries} retries, falling back to template"
    )
    return ""


def enhance_with_deepseek(item: Dict) -> str:
    """DeepSeek API í´ë°± (off-peak í• ì¸ í™œìš©)

    Args:
        item: ë‰´ìŠ¤ ì•„ì´í…œ ë”•ì…”ë„ˆë¦¬

    Returns:
        DeepSeek API ìƒì„± ë¶„ì„ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´)
    """
    api_key = os.getenv("DEEPSEEK_API_KEY", "")
    if not api_key:
        logging.debug("DeepSeek API key not found, skipping")
        return ""

    title = item.get("title", "")
    summary = item.get("summary", "")
    url = item.get("url", "")

    if not title:
        return ""

    try:
        # DeepSeek API í˜¸ì¶œ ì¤€ë¹„
        import requests

        prompt = f"""ë‹¤ìŒ ë³´ì•ˆ/ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ DevSecOps ì‹¤ë¬´ì ê´€ì ì—ì„œ ë¶„ì„:
ì œëª©: {title}
ìš”ì•½: {summary}
ì¶œì²˜: {url}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„± (500-800ì):
1. ê¸°ìˆ ì  ë°°ê²½ ë° ìœ„í˜‘ ë¶„ì„
2. ì‹¤ë¬´ ì˜í–¥ ë¶„ì„
3. ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ (- [ ] í˜•ì‹, 3-5ê°œ)

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±."""

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": 1000,
        }

        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30,
        )

        if response.status_code == 200:
            result = response.json()
            content = (
                result.get("choices", [{}])[0].get("message", {}).get("content", "")
            )
            if len(content) > 100:
                logging.info(f"DeepSeek API enhanced: {title[:50]}...")
                return content.strip()
        else:
            logging.warning(f"DeepSeek API returned status {response.status_code}")

    except ImportError:
        logging.warning("requests library not available for DeepSeek API")
    except Exception as e:
        logging.warning(f"DeepSeek API error: {e}")

    return ""


def enhance_content_with_fallback(item: Dict) -> str:
    """3ë‹¨ê³„ í´ë°± ì²´ì¸: Gemini CLI â†’ DeepSeek API â†’ Template

    Args:
        item: ë‰´ìŠ¤ ì•„ì´í…œ ë”•ì…”ë„ˆë¦¬

    Returns:
        ê°•í™”ëœ ì»¨í…ì¸  (ë¹ˆ ë¬¸ìì—´ì´ë©´ í…œí”Œë¦¿ ì‚¬ìš©)
    """
    # 1ìˆœìœ„: Gemini CLI (ë¬´ë£Œ)
    if check_gemini_available():
        content = enhance_with_gemini(item)
        if content:
            logging.info(f"âœ“ Gemini CLI: {item.get('title', '')[:50]}")
            return content

    # 2ìˆœìœ„: DeepSeek API (off-peak í• ì¸)
    content = enhance_with_deepseek(item)
    if content:
        logging.info(f"âœ“ DeepSeek API: {item.get('title', '')[:50]}")
        return content

    # 3ìˆœìœ„: ê¸°ë³¸ í…œí”Œë¦¿
    logging.info(f"âœ“ Template fallback: {item.get('title', '')[:50]}")
    return ""


# ============================================================================
# Executive Summary ê°•í™” ë„êµ¬
# ============================================================================


def generate_risk_scorecard(
    news_items: List[Dict], report_date: Optional[datetime] = None
) -> str:
    """ìœ„í—˜ ìŠ¤ì½”ì–´ì¹´ë“œ ASCII art ìƒì„±

    Args:
        news_items: ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ìœ„í—˜ ìŠ¤ì½”ì–´ì¹´ë“œ ë¬¸ìì—´
    """
    report_date = report_date or datetime.now(timezone.utc)
    scorecard = f"""```
+================================================================+
|          {report_date.strftime("%Y-%m-%d")} ì£¼ê°„ ë³´ì•ˆ ìœ„í—˜ ìŠ¤ì½”ì–´ì¹´ë“œ                      |
+================================================================+
|                                                                |
|  í•­ëª©                    ìœ„í—˜ë„   ì ìˆ˜    ì¡°ì¹˜ ì‹œê¸‰ë„             |
|  ----------------------------------------------------------   |
"""

    # Critical/High ë‰´ìŠ¤ë§Œ ìŠ¤ì½”ì–´ì¹´ë“œì— í¬í•¨
    critical_news = [
        n for n in news_items if _determine_severity(n) in ["Critical", "High"]
    ]

    for news in critical_news[:5]:  # ìµœëŒ€ 5ê°œ
        title = news.get("title", "")[:30]
        severity = _determine_severity(news)
        score = 9 if severity == "Critical" else 7
        bars = "â–ˆ" * score + "â–‘" * (10 - score)
        priority = "[ì¦‰ì‹œ]" if severity == "Critical" else "[7ì¼ ì´ë‚´]"

        scorecard += f"|  {title:<24} {bars}  {score}/10   {priority:<15}     |\n"

    # ì¢…í•© ìœ„í—˜ ìˆ˜ì¤€
    if critical_news:
        avg_score = sum(
            9 if _determine_severity(n) == "Critical" else 7 for n in critical_news
        ) / len(critical_news)
    else:
        avg_score = 5

    level = "HIGH" if avg_score >= 7 else "MEDIUM" if avg_score >= 5 else "LOW"
    bars = "â–ˆ" * int(avg_score) + "â–‘" * (10 - int(avg_score))

    scorecard += f"""|  ----------------------------------------------------------   |
|  ì¢…í•© ìœ„í—˜ ìˆ˜ì¤€: {bars} {level} ({avg_score:.1f}/10)                         |
|                                                                |
+================================================================+
```
"""
    return scorecard


def generate_executive_dashboard(
    news_items: List[Dict], report_date: Optional[datetime] = None
) -> str:
    """ê²½ì˜ì§„ ëŒ€ì‹œë³´ë“œ ASCII art

    Args:
        news_items: ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ëŒ€ì‹œë³´ë“œ ë¬¸ìì—´
    """
    critical_count = len(
        [n for n in news_items if _determine_severity(n) == "Critical"]
    )
    high_count = len([n for n in news_items if _determine_severity(n) == "High"])
    medium_count = len([n for n in news_items if _determine_severity(n) == "Medium"])

    report_date = report_date or datetime.now(timezone.utc)
    return f"""```
+================================================================+
|        ë³´ì•ˆ í˜„í™© ëŒ€ì‹œë³´ë“œ - {report_date.strftime("%Yë…„ %mì›” %dì¼")}                         |
+================================================================+
|                                                                |
|  [ìœ„í˜‘ í˜„í™©]              [íŒ¨ì¹˜ í˜„í™©]         [ì»´í”Œë¼ì´ì–¸ìŠ¤]       |
|  +-----------+           +-----------+      +-----------+      |
|  | Critical {critical_count}|           | ì ìš©í•„ìš” {critical_count}|      | ì í•©   3  |      |
|  | High     {high_count}|           | í‰ê°€ì¤‘  {high_count} |      | ê²€í† ì¤‘  2 |      |
|  | Medium   {medium_count}|           | ì •ë³´ì°¸ê³  1|      | ë¯¸ëŒ€ì‘  0 |      |
|  +-----------+           +-----------+      +-----------+      |
|                                                                |
|  [MTTR ëª©í‘œ]              [ê¸ˆì£¼ KPI]                            |
|  Critical: < 4ì‹œê°„        íƒì§€ìœ¨: 90%                           |
|  High:     < 24ì‹œê°„       ì˜¤íƒë¥ : 8%                            |
|  Medium:   < 7ì¼          íŒ¨ì¹˜ ì ìš©ë¥ : 50%                      |
|                           SIEM ë£° ì»¤ë²„ë¦¬ì§€: 85%                 |
|                                                                |
+================================================================+
```"""


def extract_cve_id(title: str, summary: str) -> Optional[str]:
    """CVE ID ì¶”ì¶œ

    Args:
        title: ì œëª©
        summary: ìš”ì•½

    Returns:
        CVE ID (ì—†ìœ¼ë©´ None)
    """
    pattern = r"CVE-\d{4}-\d{4,7}"
    for text in [title, summary]:
        match = re.search(pattern, text)
        if match:
            return match.group(0)
    return None


def generate_mitre_mapping(cve_id: str, item: Dict) -> str:
    """MITRE ATT&CK ë§¤í•‘ ìƒì„±

    Args:
        cve_id: CVE ID
        item: ë‰´ìŠ¤ ì•„ì´í…œ (ì»¨í…ìŠ¤íŠ¸ìš©)

    Returns:
        MITRE ë§¤í•‘ YAML ë¬¸ìì—´
    """
    text = f"{item.get('title', '')} {item.get('summary', '')}".lower()

    # í…ìŠ¤íŠ¸ ê¸°ë°˜ MITRE ë§¤í•‘
    techniques = []

    if any(kw in text for kw in ["rce", "remote code execution", "exploit"]):
        techniques.append("T1203  # Exploitation for Client Execution")

    if any(kw in text for kw in ["authentication", "credential", "bypass"]):
        techniques.append("T1078  # Valid Accounts")

    if any(kw in text for kw in ["injection", "sql", "xss"]):
        techniques.append("T1190  # Exploit Public-Facing Application")

    if any(kw in text for kw in ["privilege", "ê¶Œí•œ ìƒìŠ¹"]):
        techniques.append("T1068  # Exploitation for Privilege Escalation")

    if not techniques:
        techniques.append("T1190  # Exploit Public-Facing Application")

    techniques_yaml = "\n    - ".join(techniques)

    return f"""
#### MITRE ATT&CK ë§¤í•‘

```yaml
mitre_attack:
  tactics:
    - {techniques_yaml}
```
"""


# ============================================================================
# í¬ìŠ¤íŠ¸ ìƒì„±
# ============================================================================


def _extract_meaningful_topics(news_items: List[Dict], mode: str = "security") -> str:
    """Extract 2-3 meaningful topic keywords from news items for title generation.

    For security mode: extract threat names, tools, companies mentioned.
    For tech-blog mode: extract tech topics like AI Agent, Claude Code, Open Source etc.
    Cap at 80 chars.
    """
    if mode == "tech-blog":
        tech_patterns = [
            (r"\b(AI Agent|Claude Code|Cursor|Copilot|ChatGPT|Gemini|LLM)\b", None),
            (r"\b(Open Source|Open-Source|OSS)\b", "Open Source"),
            (r"\b(Kubernetes|K8s)\b", "Kubernetes"),
            (r"\b(Docker|Container)\b", "Docker"),
            (r"\b(Rust|Golang|Go\s+\d|TypeScript)\b", None),
            (r"\b(React|Next\.?js|Vue|Svelte)\b", None),
            (r"\b(AWS|Azure|GCP|Cloud)\b", None),
            (r"\b(GitHub|GitLab)\b", None),
            (r"\b(Apple|Google|Microsoft|Meta|Tesla|Spotify)\b", None),
            (r"\b(WebAssembly|WASM|gRPC|GraphQL)\b", None),
            (r"\b(DevOps|CI/CD|Platform Engineering)\b", None),
        ]
    else:
        tech_patterns = [
            (r"(CVE-\d{4}-\d+)", None),
            (r"\b(ransomware|Ransomware|ëœì„¬ì›¨ì–´)\b", "Ransomware"),
            (r"\b(zero-day|Zero-Day|0-day|ì œë¡œë°ì´)\b", "Zero-Day"),
            (r"\b(Fortinet|Cisco|Palo Alto|CrowdStrike|SonicWall|Ivanti)\b", None),
            (r"\b(Chrome|Firefox|Windows|Linux|macOS|Android|iOS)\b", None),
            (r"\b(APT\d+|Lazarus|APT28|APT29|Kimsuky)\b", None),
            (r"\b(phishing|Phishing|í”¼ì‹±)\b", "Phishing"),
            (r"\b(supply chain|Supply Chain|ê³µê¸‰ë§)\b", "Supply Chain"),
            (r"\b(botnet|Botnet|ë´‡ë„·)\b", "Botnet"),
            (r"\b(malware|Malware|ì•…ì„±ì½”ë“œ)\b", "Malware"),
            (r"\b(authentication|MFA|SSO|ì¸ì¦)\b", "Authentication"),
            (r"\b(RCE|remote code execution)\b", "RCE"),
            (r"\b(AWS|Azure|GCP|Cloud)\b", None),
            (r"\b(Kubernetes|K8s|Docker)\b", None),
        ]

    found_topics = []
    seen_lower = set()

    for item in news_items:
        text = f"{item.get('title', '')} {item.get('summary', '')}"
        for pattern, canonical in tech_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                topic = canonical if canonical else match.group(1)
                if topic.lower() not in seen_lower:
                    seen_lower.add(topic.lower())
                    found_topics.append(topic)
                    if len(found_topics) >= 4:
                        break
        if len(found_topics) >= 4:
            break

    if not found_topics:
        if mode == "tech-blog":
            found_topics = ["Tech", "DevOps"]
        else:
            found_topics = ["DevSecOps News"]

    title_keywords = ", ".join(found_topics[:3])
    if len(title_keywords) > 80:
        title_keywords = title_keywords[:77] + "..."
    return title_keywords


def generate_post_content(
    news_items: List[Dict],
    categorized: Dict[str, List[Dict]],
    date: datetime,
    topics_slug: str = "",
) -> str:
    """ê³ í’ˆì§ˆ í¬ìŠ¤íŠ¸ ì»¨í…ì¸  ìƒì„±"""

    date_str = date.strftime("%Yë…„ %mì›” %dì¼")
    date_file = date.strftime("%Y-%m-%d")
    image_filename = (
        f"{date_file}-Tech_Security_Weekly_Digest_{topics_slug}.svg"
        if topics_slug
        else f"{date_file}-Tech_Security_Weekly_Digest.svg"
    )

    stats = {cat: len(items) for cat, items in categorized.items()}
    total = sum(stats.values())

    # í•µì‹¬ ë‰´ìŠ¤ ì¶”ì¶œ
    security_news = categorized.get("security", [])[:3]
    ai_news = categorized.get("ai", [])[:3]
    cloud_news = categorized.get("cloud", [])[:3]
    devops_news = categorized.get("devops", [])[:3]
    blockchain_news = categorized.get("blockchain", [])[:2]
    tech_news = categorized.get("tech", [])[:2]

    # í•µì‹¬ í•˜ì´ë¼ì´íŠ¸ ìƒì„±
    highlights = []
    for item in (security_news + cloud_news)[:4]:
        source = item.get("source_name", item.get("source", "Unknown"))
        title = _korean_display_title(item)
        if len(title) > 60:
            # Truncate at word boundary
            title = title[:57].rsplit(" ", 1)[0] + "..."
        source = html.escape(source)
        title = html.escape(title)
        highlights.append(f"<li><strong>{source}</strong>: {title}</li>")

    highlights_html = (
        "\n      ".join(highlights)
        if highlights
        else "<li>ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”</li>"
    )

    topics = _extract_key_topics(news_items)

    # Better title generation: extract meaningful topics from content
    title_keywords = _extract_meaningful_topics(news_items, mode="security")

    base_tags = [
        "Security-Weekly",
        "DevSecOps",
        "Cloud-Security",
        "Weekly-Digest",
        str(date.year),
    ]
    topic_tags = [t for t in topics if t not in base_tags]
    tags = base_tags + topic_tags[:5]

    top_sources = list(
        {item.get("source_name", ""): True for item in news_items[:5]}.keys()
    )[:3]
    source_list = ", ".join(top_sources)

    # Generate Jekyll include tag for AI summary card
    categories_html = '<span class="category-tag security">ë³´ì•ˆ</span> <span class="category-tag devsecops">DevSecOps</span>'
    tags_html = f"""<span class="tag">Security-Weekly</span>
      <span class="tag">DevSecOps</span>
      <span class="tag">Cloud-Security</span>
      <span class="tag">AI-Security</span>
      <span class="tag">Zero-Trust</span>
      <span class="tag">{date.year}</span>"""

    content = f'''---
layout: post
title: "ê¸°ìˆ Â·ë³´ì•ˆ ì£¼ê°„ ë‹¤ì´ì œìŠ¤íŠ¸: {title_keywords}"
date: {date.strftime("%Y-%m-%d %H:%M:%S")} +0900
categories: [security, devsecops]
tags: [{", ".join(tags)}]
excerpt: "{date_str} ì£¼ìš” ë³´ì•ˆ/ê¸°ìˆ  ë‰´ìŠ¤ {total}ê±´ - {", ".join(topics[:3])}"
description: "{date_str} ë³´ì•ˆ ë‰´ìŠ¤: {source_list} ë“± {total}ê±´. {", ".join(topics[:4])} ê´€ë ¨ DevSecOps ì‹¤ë¬´ ìœ„í˜‘ ë¶„ì„ ë° ëŒ€ì‘ ê°€ì´ë“œ."
keywords: [{", ".join(tags[:8])}]
author: Twodragon
comments: true
image: /assets/images/{image_filename}
image_alt: "Tech Security Weekly Digest {date.strftime("%B %d %Y")} {" ".join(topics[:3])}"
toc: true
---

{{% include ai-summary-card.html
  title='ê¸°ìˆ Â·ë³´ì•ˆ ì£¼ê°„ ë‹¤ì´ì œìŠ¤íŠ¸ ({date_str})'
  categories_html='{categories_html}'
  tags_html='{tags_html}'
  highlights_html='{highlights_html}'
  period='{date_str} (24ì‹œê°„)'
  audience='ë³´ì•ˆ ë‹´ë‹¹ì, DevSecOps ì—”ì§€ë‹ˆì–´, SRE, í´ë¼ìš°ë“œ ì•„í‚¤í…íŠ¸'
%}}

## Executive Summary

{date_str} ê¸°ì¤€ ë³´ì•ˆ í˜„í™© ë° ìœ„í˜‘ ë¶„ì„ì…ë‹ˆë‹¤.

### ìœ„í—˜ ìŠ¤ì½”ì–´ì¹´ë“œ

{generate_risk_scorecard(news_items, date)}

### ê²½ì˜ì§„ ëŒ€ì‹œë³´ë“œ

{generate_executive_dashboard(news_items, date)}

### ì´ì‚¬íšŒ ë³´ê³  í¬ì¸íŠ¸

| í•­ëª© | ë‚´ìš© | ì¡°ì¹˜ ìƒíƒœ |
|------|------|----------|
| **ì£¼ìš” ìœ„í˜‘** | Critical: {len([n for n in news_items if _determine_severity(n) == "Critical"])}ê±´, High: {len([n for n in news_items if _determine_severity(n) == "High"])}ê±´ | ëŒ€ì‘ ì§„í–‰ ì¤‘ |
| **íŒ¨ì¹˜ ì ìš©** | ê¸´ê¸‰ íŒ¨ì¹˜ ëŒ€ìƒ ì‹œìŠ¤í…œ ì‹ë³„ ì™„ë£Œ | ê²€í†  í•„ìš” |
| **ê·œì œ ëŒ€ì‘** | ë³´ì•ˆ ì •ì±… ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ê²€ | ì •ìƒ |

---

## ì„œë¡ 

ì•ˆë…•í•˜ì„¸ìš”, **Twodragon**ì…ë‹ˆë‹¤.

{date_str} ê¸°ì¤€, ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ ë°œí‘œëœ ì£¼ìš” ê¸°ìˆ  ë° ë³´ì•ˆ ë‰´ìŠ¤ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

**ìˆ˜ì§‘ í†µê³„:**
- **ì´ ë‰´ìŠ¤ ìˆ˜**: {total}ê°œ
- **ë³´ì•ˆ ë‰´ìŠ¤**: {stats.get("security", 0)}ê°œ
- **AI/ML ë‰´ìŠ¤**: {stats.get("ai", 0)}ê°œ
- **í´ë¼ìš°ë“œ ë‰´ìŠ¤**: {stats.get("cloud", 0)}ê°œ
- **DevOps ë‰´ìŠ¤**: {stats.get("devops", 0)}ê°œ
- **ë¸”ë¡ì²´ì¸ ë‰´ìŠ¤**: {stats.get("blockchain", 0)}ê°œ

---

## ğŸ“Š ë¹ ë¥¸ ì°¸ì¡°

### ì´ë²ˆ ì£¼ í•˜ì´ë¼ì´íŠ¸

| ë¶„ì•¼ | ì†ŒìŠ¤ | í•µì‹¬ ë‚´ìš© | ì˜í–¥ë„ |
|------|------|----------|--------|
'''

    # í•˜ì´ë¼ì´íŠ¸ í…Œì´ë¸” ìƒì„±
    for item in news_items[:5]:
        source = item.get("source_name", item.get("source", "Unknown"))[:15]
        title = _korean_display_title(item, max_len=50)
        category = item.get("category", "tech")
        emoji = CATEGORY_EMOJI.get(category, "ğŸ“°")
        severity = _determine_severity(item)
        severity_emoji = {"Critical": "ğŸ”´", "High": "ğŸŸ ", "Medium": "ğŸŸ¡"}.get(
            severity, "ğŸŸ¡"
        )
        content += f"| {emoji} **{category.title()}** | {source} | {title}... | {severity_emoji} {severity} |\n"

    content += "\n---\n\n"

    section_num = 1

    # ë³´ì•ˆ ë‰´ìŠ¤ ì„¹ì…˜ - SK Shieldus ê·¸ë£¹í•‘ í¬í•¨
    if security_news:
        content += f"## {section_num}. ë³´ì•ˆ ë‰´ìŠ¤\n\n"

        # Separate SK Shieldus reports from regular security news
        skshieldus_reports = [
            item for item in security_news if item.get("source") == "skshieldus_report"
        ]
        regular_security = [
            item for item in security_news if item.get("source") != "skshieldus_report"
        ]

        for i, item in enumerate(regular_security, 1):
            is_critical = i == 1  # ì²« ë²ˆì§¸ ë‰´ìŠ¤ëŠ” ìƒì„¸ ë¶„ì„
            content += generate_news_section(
                item, f"{section_num}.{i}", is_critical=is_critical
            )

        # SK Shieldus reports grouped into a single subsection
        if skshieldus_reports:
            sub_idx = len(regular_security) + 1
            month_str = (
                date.strftime("%-mì›”")
                if sys.platform != "win32"
                else date.strftime("%mì›”").lstrip("0")
            )
            content += (
                f"### {section_num}.{sub_idx} SKì‰´ë”ìŠ¤ {month_str} ë³´ì•ˆ ë¦¬í¬íŠ¸\n\n"
            )
            content += "SKì‰´ë”ìŠ¤ì—ì„œ ë°œí–‰í•œ ìµœì‹  ë³´ì•ˆ ë¦¬í¬íŠ¸ ëª¨ìŒì…ë‹ˆë‹¤.\n\n"
            for report in skshieldus_reports:
                report_title = report.get("title", "ë³´ì•ˆ ë¦¬í¬íŠ¸")
                report_url = report.get("url", "")
                report_summary = report.get("summary", "")
                content += f"- **[{report_title}]({report_url})**"
                if report_summary:
                    short_summary = report_summary[:100].rstrip(".")
                    content += f": {short_summary}"
                content += "\n"
            content += "\n> SKì‰´ë”ìŠ¤ ë³´ì•ˆ ë¦¬í¬íŠ¸ëŠ” êµ­ë‚´ ë³´ì•ˆ í™˜ê²½ì— íŠ¹í™”ëœ ìœ„í˜‘ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì›ë¬¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n"
            content += "---\n\n"

        section_num += 1

    # AI/ML ë‰´ìŠ¤ ì„¹ì…˜
    if ai_news:
        content += f"## {section_num}. AI/ML ë‰´ìŠ¤\n\n"
        for i, item in enumerate(ai_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # í´ë¼ìš°ë“œ ë‰´ìŠ¤ ì„¹ì…˜
    if cloud_news:
        content += f"## {section_num}. í´ë¼ìš°ë“œ & ì¸í”„ë¼ ë‰´ìŠ¤\n\n"
        for i, item in enumerate(cloud_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # DevOps ë‰´ìŠ¤ ì„¹ì…˜
    if devops_news:
        content += f"## {section_num}. DevOps & ê°œë°œ ë‰´ìŠ¤\n\n"
        for i, item in enumerate(devops_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # ë¸”ë¡ì²´ì¸ ë‰´ìŠ¤ ì„¹ì…˜
    if blockchain_news:
        content += f"## {section_num}. ë¸”ë¡ì²´ì¸ ë‰´ìŠ¤\n\n"
        for i, item in enumerate(blockchain_news, 1):
            content += generate_news_section(item, f"{section_num}.{i}")
        section_num += 1

    # ê¸°íƒ€ ë‰´ìŠ¤
    if tech_news:
        content += f"## {section_num}. ê¸°íƒ€ ì£¼ëª©í•  ë‰´ìŠ¤\n\n"
        content += "| ì œëª© | ì¶œì²˜ | í•µì‹¬ ë‚´ìš© |\n"
        content += "|------|------|----------|\n"
        for item in tech_news[:5]:
            title = _korean_display_title(item, max_len=50)
            source = item.get("source_name", "")
            url = item.get("url", "")
            summary = _korean_brief_summary(item).replace("\n", " ")[:80]
            content += f"| [{title}...]({url}) | {source} | {summary}... |\n"
        content += "\n"
        section_num += 1

    # íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜
    content += _generate_trend_analysis(news_items, section_num)
    section_num += 1

    # ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸
    content += _generate_news_specific_checklist(news_items)

    content += """
---

## ì°¸ê³  ìë£Œ

| ë¦¬ì†ŒìŠ¤ | ë§í¬ |
|--------|------|
| CISA KEV | [cisa.gov/known-exploited-vulnerabilities-catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog) |
| MITRE ATT&CK | [attack.mitre.org](https://attack.mitre.org/) |
| FIRST EPSS | [first.org/epss](https://www.first.org/epss/) |

---

**ì‘ì„±ì**: Twodragon
"""

    return content


def generate_tech_blog_content(
    news_items: List[Dict],
    categorized: Dict[str, List[Dict]],
    date: datetime,
    topics_slug: str = "",
) -> str:
    """Tech Blog Weekly Digest ì»¨í…ì¸  ìƒì„±.

    Filters for geeknews, hackernews, and tech blog sources (NOT security/blockchain).
    Groups by topic: AI/ML, DevOps/Cloud, Open Source, General.
    Uses GeekNews Korean summaries prominently.
    """
    date_str = date.strftime("%Yë…„ %mì›” %dì¼")
    date_file = date.strftime("%Y-%m-%d")
    image_filename = (
        f"{date_file}-Tech_Blog_Weekly_Digest_{topics_slug}.svg"
        if topics_slug
        else f"{date_file}-Tech_Blog_Weekly_Digest.svg"
    )

    total = len(news_items)

    # Group items by topic
    topic_groups = {
        "AI/ML": [],
        "DevOps/Cloud": [],
        "Open Source": [],
        "General": [],
    }

    ai_keywords = [
        "ai",
        "ml",
        "llm",
        "gpt",
        "claude",
        "gemini",
        "chatgpt",
        "copilot",
        "machine learning",
        "deep learning",
        "neural",
        "transformer",
        "agent",
    ]
    devops_keywords = [
        "kubernetes",
        "k8s",
        "docker",
        "cloud",
        "aws",
        "azure",
        "gcp",
        "terraform",
        "ci/cd",
        "devops",
        "sre",
        "infrastructure",
        "helm",
        "container",
        "serverless",
        "microservice",
    ]
    oss_keywords = [
        "open source",
        "open-source",
        "oss",
        "github",
        "rust",
        "golang",
        "go ",
        "python",
        "typescript",
        "linux",
        "apache",
        "mit license",
        "cncf",
    ]

    for item in news_items:
        text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}".lower()
        category = item.get("category", "tech")

        if any(kw in text for kw in ai_keywords) or category == "ai":
            topic_groups["AI/ML"].append(item)
        elif any(kw in text for kw in devops_keywords) or category in (
            "devops",
            "cloud",
        ):
            topic_groups["DevOps/Cloud"].append(item)
        elif any(kw in text for kw in oss_keywords):
            topic_groups["Open Source"].append(item)
        else:
            topic_groups["General"].append(item)

    # Title generation for tech-blog mode
    title_keywords = _extract_meaningful_topics(news_items, mode="tech-blog")

    topics = _extract_key_topics(news_items)
    base_tags = ["Tech-Blog", "Weekly-Digest", "Developer", str(date.year)]
    topic_tags = [t for t in topics if t not in base_tags]
    tags = base_tags + topic_tags[:5]

    # GeekNews items for prominent display
    geeknews_items = [item for item in news_items if item.get("source") == "geeknews"]

    top_sources = list(
        {item.get("source_name", ""): True for item in news_items[:5]}.keys()
    )[:3]
    source_list = ", ".join(top_sources)

    # Build highlights from top items
    highlights = []
    for item in news_items[:4]:
        source = html.escape(item.get("source_name", item.get("source", "Unknown")))
        title = _korean_display_title(item)
        if len(title) > 60:
            title = title[:57].rsplit(" ", 1)[0] + "..."
        title = html.escape(title)
        highlights.append(f"<li><strong>{source}</strong>: {title}</li>")

    highlights_html = (
        "\n      ".join(highlights)
        if highlights
        else "<li>ì´ë²ˆ ì£¼ ì£¼ìš” ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”</li>"
    )

    # Generate Jekyll include tag for AI summary card
    categories_html = '<span class="category-tag tech">ê¸°ìˆ </span> <span class="category-tag devops">DevOps</span>'
    tags_html = f"""<span class="tag">Tech-Blog</span>
      <span class="tag">Weekly-Digest</span>
      <span class="tag">Developer</span>
      <span class="tag">Open-Source</span>
      <span class="tag">AI/ML</span>
      <span class="tag">{date.year}</span>"""

    content = f'''---
layout: post
title: "ê¸°ìˆ  ë¸”ë¡œê·¸ ì£¼ê°„ ë‹¤ì´ì œìŠ¤íŠ¸: {title_keywords}"
date: {date.strftime("%Y-%m-%d %H:%M:%S")} +0900
categories: [tech, devops]
tags: [{", ".join(tags)}]
excerpt: "{date_str} ì£¼ìš” ê¸°ìˆ  ë¸”ë¡œê·¸ ë‰´ìŠ¤ {total}ê±´ - {", ".join(topics[:3])}"
description: "{date_str} í…Œí¬ ë¸”ë¡œê·¸ ë‹¤ì´ì œìŠ¤íŠ¸: {source_list} ë“± {total}ê±´. {", ".join(topics[:4])} ê´€ë ¨ ê°œë°œì ë‰´ìŠ¤ ë° íŠ¸ë Œë“œ ë¶„ì„."
keywords: [{", ".join(tags[:8])}]
author: Twodragon
comments: true
image: /assets/images/{image_filename}
image_alt: "Tech Blog Weekly Digest {date.strftime("%B %d %Y")} {" ".join(topics[:3])}"
toc: true
---

{{% include ai-summary-card.html
  title='ê¸°ìˆ  ë¸”ë¡œê·¸ ì£¼ê°„ ë‹¤ì´ì œìŠ¤íŠ¸ ({date_str})'
  categories_html='{categories_html}'
  tags_html='{tags_html}'
  highlights_html='{highlights_html}'
  period='{date_str} (24ì‹œê°„)'
  audience='ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì, DevOps ì—”ì§€ë‹ˆì–´, í…Œí¬ ë¦¬ë“œ, CTO'
%}}

## ì„œë¡ 

ì•ˆë…•í•˜ì„¸ìš”, **Twodragon**ì…ë‹ˆë‹¤.

{date_str} ê¸°ì¤€, ì£¼ìš” ê¸°ìˆ  ë¸”ë¡œê·¸ì™€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë°œí‘œëœ ê°œë°œì ë‰´ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

**ìˆ˜ì§‘ í†µê³„:**
- **ì´ ë‰´ìŠ¤ ìˆ˜**: {total}ê°œ
- **AI/ML**: {len(topic_groups["AI/ML"])}ê°œ
- **DevOps/Cloud**: {len(topic_groups["DevOps/Cloud"])}ê°œ
- **Open Source**: {len(topic_groups["Open Source"])}ê°œ
- **General**: {len(topic_groups["General"])}ê°œ

---

'''

    section_num = 1

    # GeekNews í•˜ì´ë¼ì´íŠ¸ (Korean summaries prominently displayed)
    if geeknews_items:
        content += f"## {section_num}. GeekNews í•˜ì´ë¼ì´íŠ¸\n\n"
        content += "GeekNewsì—ì„œ ì£¼ëª©ë°›ì€ ê¸°ìˆ  ë‰´ìŠ¤ì…ë‹ˆë‹¤.\n\n"
        for item in geeknews_items[:5]:
            title = _korean_display_title(item)
            url = item.get("url", "")
            source_name = item.get("source_name", "GeekNews")
            ko_summary = _korean_brief_summary(item)

            content += f"### {title}\n\n"
            if ko_summary:
                content += f"{ko_summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source_name}]({url})\n\n"
        section_num += 1

    # AI/ML ì„¹ì…˜
    if topic_groups["AI/ML"]:
        content += f"## {section_num}. AI/ML íŠ¸ë Œë“œ\n\n"
        for i, item in enumerate(topic_groups["AI/ML"][:5], 1):
            title = _korean_display_title(item)
            url = item.get("url", "")
            source = item.get("source_name", item.get("source", "Unknown"))
            ko_summary = _korean_brief_summary(item)

            content += f"### {section_num}.{i} {title}\n\n"
            if ko_summary:
                content += f"{ko_summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source}]({url})\n\n"

            # Key points
            key_points = _generate_key_points(item)
            if key_points:
                content += "**í•µì‹¬ í¬ì¸íŠ¸:**\n\n"
                content += key_points + "\n"
        section_num += 1

    # DevOps/Cloud ì„¹ì…˜
    if topic_groups["DevOps/Cloud"]:
        content += f"## {section_num}. DevOps & Cloud\n\n"
        for i, item in enumerate(topic_groups["DevOps/Cloud"][:5], 1):
            title = _korean_display_title(item)
            url = item.get("url", "")
            source = item.get("source_name", item.get("source", "Unknown"))
            ko_summary = _korean_brief_summary(item)

            content += f"### {section_num}.{i} {title}\n\n"
            if ko_summary:
                content += f"{ko_summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source}]({url})\n\n"
        section_num += 1

    # Open Source ì„¹ì…˜
    if topic_groups["Open Source"]:
        content += f"## {section_num}. Open Source\n\n"
        for i, item in enumerate(topic_groups["Open Source"][:5], 1):
            title = _korean_display_title(item)
            url = item.get("url", "")
            source = item.get("source_name", item.get("source", "Unknown"))
            ko_summary = _korean_brief_summary(item)

            content += f"### {section_num}.{i} {title}\n\n"
            if ko_summary:
                content += f"{ko_summary}\n\n"
            content += f"> **ì¶œì²˜**: [{source}]({url})\n\n"
        section_num += 1

    # General ì„¹ì…˜
    if topic_groups["General"]:
        content += f"## {section_num}. ê¸°íƒ€ ì£¼ëª©í•  ë‰´ìŠ¤\n\n"
        content += "| ì œëª© | ì¶œì²˜ | í•µì‹¬ ë‚´ìš© |\n"
        content += "|------|------|----------|\n"
        for item in topic_groups["General"][:5]:
            title = _korean_display_title(item, max_len=50)
            source = item.get("source_name", "")
            url = item.get("url", "")
            ko_summary = _korean_brief_summary(item).replace("\n", " ")[:80]
            content += f"| [{title}...]({url}) | {source} | {ko_summary}... |\n"
        content += "\n"
        section_num += 1

    # íŠ¸ë Œë“œ ë¶„ì„
    content += _generate_tech_trend_analysis(news_items, section_num)

    content += """
---

**ì‘ì„±ì**: Twodragon
"""

    return content


def _generate_tech_trend_analysis(news_items: List[Dict], section_num: int) -> str:
    """ê¸°ìˆ  ë¸”ë¡œê·¸ íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
    content = f"\n---\n\n## {section_num}. íŠ¸ë Œë“œ ë¶„ì„\n\n"

    trend_defs = {
        "AI/LLM": [
            "ai",
            "llm",
            "gpt",
            "claude",
            "gemini",
            "machine learning",
            "ì¸ê³µì§€ëŠ¥",
            "ìƒì„±í˜•",
        ],
        "Cloud Native": ["cloud", "aws", "azure", "gcp", "serverless", "í´ë¼ìš°ë“œ"],
        "Container/K8s": ["kubernetes", "k8s", "container", "docker", "ì»¨í…Œì´ë„ˆ"],
        "Developer Tools": [
            "ide",
            "editor",
            "cli",
            "developer experience",
            "dx",
            "cursor",
            "copilot",
        ],
        "Open Source": ["open source", "open-source", "oss", "github", "cncf"],
        "Programming Languages": [
            "rust",
            "golang",
            "typescript",
            "python",
            "java",
            "swift",
        ],
        "Platform Engineering": [
            "platform",
            "internal developer",
            "golden path",
            "backstage",
        ],
    }

    trend_results = []
    for trend_name, keywords in trend_defs.items():
        count = 0
        matched_kws = set()
        for item in news_items:
            text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
            for kw in keywords:
                if kw in text:
                    count += 1
                    matched_kws.add(kw)
                    break
        if count > 0:
            trend_results.append((trend_name, count, ", ".join(list(matched_kws)[:3])))

    trend_results.sort(key=lambda x: x[1], reverse=True)

    if trend_results:
        content += "| íŠ¸ë Œë“œ | ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ | ì£¼ìš” í‚¤ì›Œë“œ |\n"
        content += "|--------|-------------|------------|\n"
        for name, count, kws in trend_results[:7]:
            content += f"| **{name}** | {count}ê±´ | {kws} |\n"
        content += "\n"

        top = trend_results[0]
        content += (
            f"ì´ë²ˆ ì£¼ê¸°ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ íŠ¸ë Œë“œëŠ” **{top[0]}** ({top[1]}ê±´)ì…ë‹ˆë‹¤. "
        )
        if len(trend_results) > 1:
            second = trend_results[1]
            content += (
                f"ê·¸ ë‹¤ìŒìœ¼ë¡œ **{second[0]}** ({second[1]}ê±´)ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. "
            )
        content += (
            "ê´€ë ¨ ê¸°ìˆ  ë™í–¥ì„ íŒŒì•…í•˜ê³  íŒ€ ë‚´ ê¸°ìˆ  ê³µìœ ì— í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n"
        )
    else:
        content += "ì´ë²ˆ ì£¼ê¸°ì—ëŠ” ë‘ë“œëŸ¬ì§„ íŠ¸ë Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"

    return content


def _determine_severity(item: Dict) -> str:
    """ë‰´ìŠ¤ ì‹¬ê°ë„ ê²°ì •"""
    text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
    critical_keywords = [
        "critical",
        "rce",
        "zero-day",
        "ì œë¡œë°ì´",
        "0-day",
        "cvss 9",
        "cvss 10",
        "unauthenticated",
        "actively exploited",
    ]
    high_keywords = [
        "high",
        "ê¶Œí•œ ìƒìŠ¹",
        "privilege escalation",
        "authentication bypass",
        "ì¸ì¦ ìš°íšŒ",
        "ssrf",
        "injection",
    ]

    for kw in critical_keywords:
        if kw in text:
            return "Critical"
    for kw in high_keywords:
        if kw in text:
            return "High"
    return "Medium"


def _extract_cve_ids(item: Dict) -> List[str]:
    """ë‰´ìŠ¤ ì•„ì´í…œì—ì„œ ëª¨ë“  CVE ID ì¶”ì¶œ"""
    text = (
        f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}"
    )
    cves = re.findall(r"CVE-\d{4}-\d+", text)
    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
    seen = set()
    unique = []
    for cve in cves:
        if cve not in seen:
            seen.add(cve)
            unique.append(cve)
    return unique


def _generate_key_points(item: Dict) -> str:
    """ë‰´ìŠ¤ ì•„ì´í…œì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ"""
    summary = _korean_brief_summary(item)
    if not summary:
        return ""

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ í•µì‹¬ í¬ì¸íŠ¸ ìƒì„±
    sentences = re.split(r"(?<=[.!?ã€‚ë‹¤])\s+", summary)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 15]

    if not sentences:
        return ""

    points = ""
    for s in sentences[:4]:
        # ë§ˆì¹¨í‘œ ì œê±° í›„ í¬ì¸íŠ¸ë¡œ
        s = s.rstrip(".")
        points += f"- {s}\n"
    return points


def _korean_display_title(item: Dict, max_len: int = 72) -> str:
    raw_title = (item.get("title", "") or "").strip()
    if not raw_title:
        return "ì œëª© ì—†ìŒ"

    if re.search(r"[ê°€-í£]", raw_title):
        return raw_title

    cache_key = item.get("id") or item.get("url") or raw_title
    if cache_key in KOREAN_TITLE_CACHE:
        return KOREAN_TITLE_CACHE[cache_key]

    translated = ""
    if check_gemini_available():
        prompt = (
            "ë‹¤ìŒ ê¸°ìˆ  ë‰´ìŠ¤ ì œëª©ì„ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ ì£¼ì„¸ìš”. "
            "ê³ ìœ ëª…ì‚¬(íšŒì‚¬ëª…/ì œí’ˆëª…)ëŠ” ì›ë¬¸ í‘œê¸°ë¥¼ ìœ ì§€í•˜ê³ , ë‹µë³€ì€ í•œ ì¤„ ì œëª©ë§Œ ì¶œë ¥í•˜ì„¸ìš”. "
            "ë”°ì˜´í‘œ/ë²ˆí˜¸/ë¶ˆë¦¿/ì„¤ëª…ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.\n\n"
            f"ì›ë¬¸ ì œëª©: {raw_title}\n"
            "ë²ˆì—­ ì œëª©:"
        )
        try:
            result = subprocess.run(
                ["gemini", "-p", prompt],
                capture_output=True,
                text=True,
                timeout=25,
            )
            if result.returncode == 0:
                candidate = re.sub(r"\s+", " ", result.stdout.strip()).strip("\"'")
                if candidate and re.search(r"[ê°€-í£]", candidate):
                    translated = candidate
        except Exception:
            pass

    if translated:
        KOREAN_TITLE_CACHE[cache_key] = translated
        return translated

    source_name = (
        item.get("source_name", "") or item.get("source", "í•´ì™¸ ê¸°ìˆ  ë§¤ì²´")
    ).strip()
    if not source_name:
        source_name = "í•´ì™¸ ê¸°ìˆ  ë§¤ì²´"
    fallback = f"{source_name} ê¸°ìˆ  ì—…ë°ì´íŠ¸"
    KOREAN_TITLE_CACHE[cache_key] = fallback
    return fallback


def _korean_brief_summary(item: Dict, max_sentences: int = 2) -> str:
    summary = (item.get("summary", "") or "").strip()
    content_text = (item.get("content", "") or "").strip()
    text = summary or content_text
    if not text:
        return ""

    text = re.sub(r"\s+", " ", text)
    sentences = re.split(r"(?<=[.!?])\s+", text)
    sentences = [s.strip() for s in sentences if s.strip()]
    selected = sentences[:max_sentences] if sentences else [text[:220]]

    has_korean = bool(re.search(r"[ê°€-í£]", text))
    if has_korean:
        return " ".join(selected)

    cache_key = item.get("id") or item.get("url") or item.get("title") or text[:80]
    if cache_key in KOREAN_SUMMARY_CACHE:
        return KOREAN_SUMMARY_CACHE[cache_key]

    if check_gemini_available():
        prompt = (
            "ë‹¤ìŒ ê¸°ìˆ  ë‰´ìŠ¤ ìš”ì•½ì„ í•œêµ­ì–´ 2ë¬¸ì¥ìœ¼ë¡œë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”. "
            "ë§ˆí¬ë‹¤ìš´/ë¶ˆë¦¿/ë²ˆí˜¸ ì—†ì´ ìˆœìˆ˜ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\n"
            f"ì œëª©: {item.get('title', '')}\n"
            f"ìš”ì•½: {text[:800]}\n"
            "ì‘ë‹µ:"
        )
        try:
            result = subprocess.run(
                ["gemini", "-p", prompt],
                capture_output=True,
                text=True,
                timeout=25,
            )
            if result.returncode == 0:
                generated = re.sub(r"\s+", " ", result.stdout.strip())
                if (
                    generated
                    and len(generated) >= 30
                    and bool(re.search(r"[ê°€-í£]", generated))
                ):
                    KOREAN_SUMMARY_CACHE[cache_key] = generated
                    return generated
        except Exception:
            pass

    category = item.get("category", "tech")
    category_context = {
        "security": "ë³´ì•ˆ ê´€ì ì—ì„œ ì·¨ì•½ì  ì˜í–¥ë„ì™€ ìš°ì„  ëŒ€ì‘ ëŒ€ìƒì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.",
        "devsecops": "DevSecOps ê´€ì ì—ì„œ ë°°í¬ íŒŒì´í”„ë¼ì¸ê³¼ ë³´ì•ˆ í†µì œë¥¼ í•¨ê»˜ ì ê²€í•´ì•¼ í•©ë‹ˆë‹¤.",
        "cloud": "í´ë¼ìš°ë“œ ê´€ì ì—ì„œ ì„œë¹„ìŠ¤ ì˜í–¥ ë²”ìœ„ì™€ ì„¤ì • ë³€ê²½ í¬ì¸íŠ¸ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.",
        "devops": "DevOps ê´€ì ì—ì„œ ìš´ì˜ ìë™í™”ì™€ ë¡¤ë°± ì „ëµì„ í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.",
        "kubernetes": "ì¿ ë²„ë„¤í‹°ìŠ¤ ê´€ì ì—ì„œ í´ëŸ¬ìŠ¤í„° ìš´ì˜ ë° ë³´ì•ˆ ì •ì±… ì˜í–¥ì„ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.",
        "ai": "AI ê´€ì ì—ì„œ ëª¨ë¸/ë°ì´í„°/í”Œë«í¼ ë³€í™”ê°€ ì‹¤ë¬´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.",
    }
    context_line = category_context.get(
        category, "ì‹¤ë¬´ ì ìš© ì „ì— ì„œë¹„ìŠ¤ ì˜í–¥ë„ì™€ ìš´ì˜ ë³€ê²½ì ì„ í•¨ê»˜ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤."
    )
    title_ko = _korean_display_title(item)
    fallback = (
        f"{title_ko} ê´€ë ¨ ì†Œì‹ì…ë‹ˆë‹¤. í•µì‹¬ ë³€ê²½ì‚¬í•­ê³¼ ì˜í–¥ ë²”ìœ„ë¥¼ ìš°ì„  íŒŒì•…í•˜ì„¸ìš”.\n\n"
        f"ì‹¤ë¬´ í•´ì„: {context_line}"
    )
    KOREAN_SUMMARY_CACHE[cache_key] = fallback
    return fallback


def generate_news_section(
    item: Dict, section_num: str, is_critical: bool = False
) -> str:
    """ê°œë³„ ë‰´ìŠ¤ ì„¹ì…˜ ìƒì„± - ê³ í’ˆì§ˆ ë¶„ì„ í¬í•¨"""
    title = _korean_display_title(item)
    url = item.get("url", "")
    source = item.get("source_name", item.get("source", "Unknown"))
    summary = item.get("summary", "")
    content_text = item.get("content", "")
    category = item.get("category", "tech")

    severity = _determine_severity(item)
    cve_ids = _extract_cve_ids(item)

    section = f"### {section_num} {title}\n\n"

    # ì‹¬ê°ë„ ë° CVE ë±ƒì§€
    if cve_ids or severity == "Critical":
        severity_emoji = {"Critical": "ğŸ”´", "High": "ğŸŸ ", "Medium": "ğŸŸ¡"}.get(
            severity, "ğŸŸ¡"
        )
        section += f"> {severity_emoji} **ì‹¬ê°ë„**: {severity}"
        if cve_ids:
            section += f" | **CVE**: {', '.join(cve_ids[:5])}"
        section += "\n\n"

    # AI ê°•í™” ì‹œë„ (Critical/High ë³´ì•ˆ ë‰´ìŠ¤ë§Œ) - 3ë‹¨ê³„ í´ë°± ì²´ì¸ ì‚¬ìš©
    if is_critical and category in ("security", "devsecops"):
        enhanced = enhance_content_with_fallback(item)
        if enhanced:
            section += enhanced + "\n\n"
            section += f"> **ì¶œì²˜**: [{source}]({url})\n\n"

            # CVEê°€ ìˆìœ¼ë©´ MITRE ë§¤í•‘ ì¶”ê°€
            if cve_ids:
                section += generate_mitre_mapping(cve_ids[0], item)

            section += "\n---\n\n"
            return section

    # í´ë°±: ê¸°ì¡´ í…œí”Œë¦¿
    section += "#### ê°œìš”\n\n"
    ko_summary = _korean_brief_summary(item)
    if ko_summary:
        section += f"{ko_summary}\n\n"
    elif content_text:
        section += f"{content_text[:800]}...\n\n"

    section += f"> **ì¶œì²˜**: [{source}]({url})\n\n"

    # í•µì‹¬ í¬ì¸íŠ¸
    key_points = _generate_key_points(item)
    if key_points:
        section += "#### í•µì‹¬ í¬ì¸íŠ¸\n\n"
        section += key_points + "\n"

    # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë¶„ì„ í…œí”Œë¦¿
    if category in ("security", "devsecops") and is_critical:
        section += _generate_security_analysis_template(item)
    elif category in ("security", "devsecops"):
        section += _generate_security_brief_template(item)
    elif category == "ai":
        section += _generate_ai_analysis_template(item)
    elif category in ("cloud", "devops", "kubernetes"):
        section += _generate_devops_template()

    section += "\n---\n\n"
    return section


def _generate_security_analysis_template(item: Dict) -> str:
    """ë³´ì•ˆ ë‰´ìŠ¤ ìƒì„¸ ë¶„ì„ í…œí”Œë¦¿ - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜"""
    cve_ids = _extract_cve_ids(item)
    severity = _determine_severity(item)
    text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}".lower()

    # ëŒ€ì‘ ìš°ì„ ìˆœìœ„ ê²°ì •
    priority = "P0 - ì¦‰ì‹œ ëŒ€ì‘" if severity == "Critical" else "P1 - 7ì¼ ì´ë‚´ ê²€í†  ê¶Œì¥"

    template = "\n#### ìœ„í˜‘ ë¶„ì„\n\n"
    template += "| í•­ëª© | ë‚´ìš© |\n"
    template += "|------|------|\n"

    if cve_ids:
        template += f"| **CVE ID** | {', '.join(cve_ids[:5])} |\n"
    else:
        template += "| **CVE ID** | ë¯¸ê³µê°œ ë˜ëŠ” í•´ë‹¹ ì—†ìŒ |\n"

    template += f"| **ì‹¬ê°ë„** | {severity} |\n"
    template += f"| **ëŒ€ì‘ ìš°ì„ ìˆœìœ„** | {priority} |\n"
    template += "\n"

    # SIEM íƒì§€ íŒíŠ¸ (ì·¨ì•½ì  ìœ í˜• ê¸°ë°˜)
    siem_hints = []
    mitre_techniques = []

    if "rce" in text or "remote code execution" in text:
        siem_hints.append(
            '```splunk\nindex=security sourcetype=syslog ("exploit" OR "remote code execution" OR "shell")\n| stats count by src_ip, dest_ip, action\n| where count > 3\n```'
        )
        mitre_techniques.append("T1203 (Exploitation for Client Execution)")
    if "authentication" in text or "ì¸ì¦" in text or "auth bypass" in text:
        siem_hints.append(
            '```splunk\nindex=security sourcetype=auth ("bypass" OR "unauthorized" OR "failed_login")\n| stats count by user, src_ip\n| where count > 10\n```'
        )
        mitre_techniques.append("T1078 (Valid Accounts)")
    if "injection" in text or "sql" in text or "xss" in text:
        siem_hints.append(
            '```splunk\nindex=web sourcetype=access_combined (SELECT OR UNION OR script OR "\\x" OR "%27")\n| stats count by uri, src_ip\n| where count > 5\n```'
        )
        mitre_techniques.append("T1190 (Exploit Public-Facing Application)")
    if "supply chain" in text or "ê³µê¸‰ë§" in text:
        mitre_techniques.append("T1195 (Supply Chain Compromise)")
    if "zero-day" in text or "ì œë¡œë°ì´" in text or "0-day" in text:
        mitre_techniques.append("T1068 (Exploitation for Privilege Escalation)")
    if "privilege" in text or "ê¶Œí•œ ìƒìŠ¹" in text:
        mitre_techniques.append("T1068 (Exploitation for Privilege Escalation)")

    if siem_hints:
        template += "#### SIEM íƒì§€ ì¿¼ë¦¬ (ì°¸ê³ ìš©)\n\n"
        template += siem_hints[0] + "\n\n"

    if mitre_techniques:
        template += "#### MITRE ATT&CK ë§¤í•‘\n\n"
        for tech in mitre_techniques[:3]:
            template += f"- **{tech}**\n"
        template += "\n"

    template += """#### ê¶Œì¥ ì¡°ì¹˜

- [ ] ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œ/ì†Œí”„íŠ¸ì›¨ì–´ ì¸ë²¤í† ë¦¬ í™•ì¸
- [ ] ë²¤ë” íŒ¨ì¹˜ ë° ë³´ì•ˆ ê¶Œê³  í™•ì¸
- [ ] SIEM/EDR íƒì§€ ë£° ì—…ë°ì´íŠ¸ ê²€í† 
- [ ] í•„ìš”ì‹œ ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ ë˜ëŠ” ì„ì‹œ ì™„í™” ì¡°ì¹˜ ì ìš©
- [ ] ë³´ì•ˆíŒ€ ë‚´ ê³µìœ  ë° ëª¨ë‹ˆí„°ë§ ê°•í™”

"""
    return template


def _generate_security_brief_template(item: Optional[Dict] = None) -> str:
    """ë³´ì•ˆ ë‰´ìŠ¤ ê°„ëµ ë¶„ì„ í…œí”Œë¦¿ - í† í”½ë³„ ë§ì¶¤ ì¡°ì–¸ ì œê³µ"""
    if item is None:
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ê´€ë ¨ ì‹œìŠ¤í…œ ëª©ë¡ í™•ì¸
- ë³´ì•ˆ ë‹´ë‹¹ìëŠ” ì›ë¬¸ì„ ê²€í† í•˜ì—¬ ìì‚¬ í™˜ê²½ í•´ë‹¹ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
- ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œì´ ìˆëŠ” ê²½ìš° ë²¤ë” ê¶Œê³ ì— ë”°ë¼ íŒ¨ì¹˜ ë˜ëŠ” ì™„í™” ì¡°ì¹˜ë¥¼ ì ìš©í•˜ì„¸ìš”
- SIEM íƒì§€ ë£°ì— ê´€ë ¨ IOCë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤

"""

    text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('content', '')}".lower()

    # Ransomware-related advice
    if any(kw in text for kw in ["ransomware", "ëœì„¬ì›¨ì–´", "ransom", "encrypt"]):
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ë°±ì—… ì‹œìŠ¤í…œ ì •ìƒ ë™ì‘ ì—¬ë¶€ ì¦‰ì‹œ ê²€ì¦ (ì˜¤í”„ë¼ì¸ ë°±ì—… í¬í•¨)
- ì¸ì‹œë˜íŠ¸ ëŒ€ì‘ í”Œë ˆì´ë¶ ì ê²€ ë° ëœì„¬ì›¨ì–´ ì‹œë‚˜ë¦¬ì˜¤ í™•ì¸
- ë„¤íŠ¸ì›Œí¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìƒíƒœ í™•ì¸ ë° íš¡ì  ì´ë™ ì°¨ë‹¨ ê²€í† 
- EDR/XDR ì†”ë£¨ì…˜ì˜ ëœì„¬ì›¨ì–´ íƒì§€ ì •ì±… ìµœì‹  ìƒíƒœ í™•ì¸

"""

    # Authentication-related advice
    if any(
        kw in text
        for kw in [
            "authentication",
            "ì¸ì¦",
            "credential",
            "password",
            "mfa",
            "sso",
            "auth bypass",
            "ì¸ì¦ ìš°íšŒ",
            "login",
        ]
    ):
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ê´€ë ¨ ì‹œìŠ¤í…œì˜ ì¸ì¦ ì •ë³´(Credential) ì¦‰ì‹œ ë¡œí…Œì´ì…˜ ê²€í† 
- MFA(ë‹¤ì¤‘ ì¸ì¦) ì ìš© í˜„í™© ì ê²€ ë° ë¯¸ì ìš© ì‹œìŠ¤í…œ ì‹ë³„
- SSO/IdP ë¡œê·¸ì—ì„œ ë¹„ì •ìƒ ì¸ì¦ ì‹œë„ ëª¨ë‹ˆí„°ë§ ê°•í™”
- ì„œë¹„ìŠ¤ ê³„ì • ë° API í‚¤ ì‚¬ìš© í˜„í™© ê°ì‚¬

"""

    # Supply chain-related advice
    if any(
        kw in text
        for kw in [
            "supply chain",
            "ê³µê¸‰ë§",
            "dependency",
            "package",
            "npm",
            "pypi",
            "maven",
            "sbom",
        ]
    ):
        return """
#### ì‹¤ë¬´ ì˜í–¥

- ì˜ì¡´ì„± ê°ì‚¬(dependency audit) ì¦‰ì‹œ ì‹¤í–‰: `npm audit`, `pip audit`, `bundle audit`
- SBOM(Software Bill of Materials) ìµœì‹  ìƒíƒœ í™•ì¸
- ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ê³ ì • ë° ë¬´ê²°ì„± ê²€ì¦(checksum/signature)
- CI/CD íŒŒì´í”„ë¼ì¸ì˜ ì˜ì¡´ì„± ìŠ¤ìº” ì •ì±… ì ê²€

"""

    # Default: improved generic with "ê´€ë ¨ ì‹œìŠ¤í…œ ëª©ë¡ í™•ì¸" as first item
    return """
#### ì‹¤ë¬´ ì˜í–¥

- ê´€ë ¨ ì‹œìŠ¤í…œ ëª©ë¡ í™•ì¸
- ë³´ì•ˆ ë‹´ë‹¹ìëŠ” ì›ë¬¸ì„ ê²€í† í•˜ì—¬ ìì‚¬ í™˜ê²½ í•´ë‹¹ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
- ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œì´ ìˆëŠ” ê²½ìš° ë²¤ë” ê¶Œê³ ì— ë”°ë¼ íŒ¨ì¹˜ ë˜ëŠ” ì™„í™” ì¡°ì¹˜ë¥¼ ì ìš©í•˜ì„¸ìš”
- SIEM íƒì§€ ë£°ì— ê´€ë ¨ IOCë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤

"""


def _generate_ai_analysis_template(item: Dict) -> str:
    """AI/ML ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„ í…œí”Œë¦¿"""
    title = item.get("title", "")
    summary = item.get("summary", "")

    template = """
#### AI/ML ë³´ì•ˆ ì˜í–¥ ë¶„ì„

- **ëª¨ë¸ ë³´ì•ˆ**: AI ëª¨ë¸ ë¬´ê²°ì„± ë° ì ëŒ€ì  ê³µê²© ëŒ€ì‘ í˜„í™© ì ê²€
- **ë°ì´í„° ë³´ì•ˆ**: í•™ìŠµ ë°ì´í„° ë° ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ê²€í†  í•„ìš”
- **ê±°ë²„ë„ŒìŠ¤**: AI ëª¨ë¸ ë°°í¬ ì „ ë³´ì•ˆ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸

#### ì‹¤ë¬´ ì ìš©

- AI/ML íŒŒì´í”„ë¼ì¸ ë³´ì•ˆ ì ê²€ í•­ëª© ê²€í† 
- ëª¨ë¸ ì…ì¶œë ¥ ê²€ì¦ ë¡œì§ ì¶”ê°€ ê²€í† 
- AI ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬ ëŒ€ë¹„ í˜„í™© ì ê²€

"""
    return template


def _generate_devops_template() -> str:
    return """
#### ì‹¤ë¬´ ì ìš© í¬ì¸íŠ¸

- ê¸°ì¡´ ì¸í”„ë¼/ìš´ì˜ í™˜ê²½ê³¼ì˜ í˜¸í™˜ì„± ë° ì˜í–¥ë„ ê²€í† 
- í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ë¨¼ì € ê²€ì¦ í›„ í”„ë¡œë•ì…˜ ì ìš© ê³„íš ìˆ˜ë¦½
- íŒ€ ë‚´ ê¸°ìˆ  ê³µìœ  ë° ë„ì… ë¡œë“œë§µ ë…¼ì˜

"""


def _generate_trend_analysis(news_items: List[Dict], section_num: int) -> str:
    """ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
    content = f"\n---\n\n## {section_num}. íŠ¸ë Œë“œ ë¶„ì„\n\n"

    # íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
    trend_defs = {
        "AI/ML": ["ai", "ml", "llm", "gpt", "machine learning", "ì¸ê³µì§€ëŠ¥", "ìƒì„±í˜•"],
        "Zero-Day": ["zero-day", "0-day", "ì œë¡œë°ì´"],
        "Cloud Security": ["cloud", "aws", "azure", "gcp", "í´ë¼ìš°ë“œ"],
        "Supply Chain": ["supply chain", "ê³µê¸‰ë§", "dependency", "package"],
        "Ransomware": ["ransomware", "ëœì„¬ì›¨ì–´"],
        "Container/K8s": ["kubernetes", "k8s", "container", "docker", "ì»¨í…Œì´ë„ˆ"],
        "Authentication": ["authentication", "ì¸ì¦", "credential", "identity", "sso"],
    }

    trend_results = []
    for trend_name, keywords in trend_defs.items():
        count = 0
        matched_kws = set()
        for item in news_items:
            text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
            for kw in keywords:
                if kw in text:
                    count += 1
                    matched_kws.add(kw)
                    break  # ë‰´ìŠ¤ë‹¹ 1ë²ˆë§Œ ì¹´ìš´íŠ¸
        if count > 0:
            trend_results.append((trend_name, count, ", ".join(list(matched_kws)[:3])))

    trend_results.sort(key=lambda x: x[1], reverse=True)

    if trend_results:
        content += "| íŠ¸ë Œë“œ | ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ | ì£¼ìš” í‚¤ì›Œë“œ |\n"
        content += "|--------|-------------|------------|\n"
        for name, count, kws in trend_results[:7]:
            content += f"| **{name}** | {count}ê±´ | {kws} |\n"
        content += "\n"

        # íŠ¸ë Œë“œ ë¶„ì„ ì½”ë©˜íŠ¸
        top = trend_results[0]
        content += (
            f"ì´ë²ˆ ì£¼ê¸°ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ íŠ¸ë Œë“œëŠ” **{top[0]}** ({top[1]}ê±´)ì…ë‹ˆë‹¤. "
        )
        if len(trend_results) > 1:
            second = trend_results[1]
            content += (
                f"ê·¸ ë‹¤ìŒìœ¼ë¡œ **{second[0]}** ({second[1]}ê±´)ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. "
            )
        content += "ì‹¤ë¬´ì—ì„œëŠ” í•´ë‹¹ íŠ¸ë Œë“œì™€ ê´€ë ¨ëœ ë³´ì•ˆ ì •ì±… ë° ëª¨ë‹ˆí„°ë§ ì²´ê³„ë¥¼ ì ê²€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n"
    else:
        content += "ì´ë²ˆ ì£¼ê¸°ì—ëŠ” ë‘ë“œëŸ¬ì§„ íŠ¸ë Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"

    return content


def _generate_news_specific_checklist(news_items: List[Dict]) -> str:
    """ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    content = "---\n\n## ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"

    p0_items = []
    p1_items = []

    for item in news_items:
        severity = _determine_severity(item)
        title = _korean_display_title(item, max_len=60)
        cve_ids = _extract_cve_ids(item)
        cve_str = f" ({', '.join(cve_ids[:2])})" if cve_ids else ""

        if severity == "Critical":
            p0_items.append(f"- [ ] **{title}**{cve_str} ê´€ë ¨ ê¸´ê¸‰ íŒ¨ì¹˜ ë° ì˜í–¥ë„ í™•ì¸")
        elif severity == "High":
            p1_items.append(f"- [ ] **{title}**{cve_str} ê´€ë ¨ ë³´ì•ˆ ê²€í†  ë° ëª¨ë‹ˆí„°ë§")

    content += "### P0 (ì¦‰ì‹œ)\n\n"
    if p0_items:
        content += "\n".join(p0_items[:5]) + "\n"
    else:
        content += "- [ ] ê¸´ê¸‰ ë³´ì•ˆ íŒ¨ì¹˜ ì ìš©\n"
        content += "- [ ] ì·¨ì•½ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê°•í™”\n"

    content += "\n### P1 (7ì¼ ë‚´)\n\n"
    if p1_items:
        content += "\n".join(p1_items[:5]) + "\n"
    else:
        content += "- [ ] SIEM íƒì§€ ë£° ì—…ë°ì´íŠ¸\n"
        content += "- [ ] ë³´ì•ˆ ì •ì±… ê²€í† \n"

    content += "\n### P2 (30ì¼ ë‚´)\n\n"
    content += "- [ ] ê³µê²© í‘œë©´ ì¸ë²¤í† ë¦¬ ê°±ì‹ \n"
    content += "- [ ] ì ‘ê·¼ ì œì–´ ê°ì‚¬\n"

    return content


# ============================================================================
# SVG ì´ë¯¸ì§€ ìƒì„± - ê³ í’ˆì§ˆ ì¹´ë“œ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ
# ============================================================================

# ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë¼ë””ì–¸íŠ¸ ë° ì•„ì´ì½˜ ì„¤ì •
CATEGORY_SVG_CONFIG = {
    "security": {
        "gradient": ("dc2626", "991b1b"),  # red
        "label": "SECURITY",
        "icon": "!",
        "icon_color": "#dc2626",
    },
    "cloud": {
        "gradient": ("10b981", "059669"),  # green
        "label": "CLOUD",
        "icon": "AWS",
        "icon_color": "#10b981",
    },
    "devops": {
        "gradient": ("f59e0b", "d97706"),  # orange
        "label": "DEVOPS",
        "icon": "DEV",
        "icon_color": "#f59e0b",
    },
    "tech": {
        "gradient": ("3b82f6", "1d4ed8"),  # blue
        "label": "TECH",
        "icon": "AI",
        "icon_color": "#3b82f6",
    },
    "devsecops": {
        "gradient": ("8b5cf6", "6d28d9"),  # purple
        "label": "DEVSECOPS",
        "icon": "SEC",
        "icon_color": "#8b5cf6",
    },
    "ai": {
        "gradient": ("6366f1", "4f46e5"),  # indigo
        "label": "AI/ML",
        "icon": "AI",
        "icon_color": "#6366f1",
    },
    "blockchain": {
        "gradient": ("f97316", "ea580c"),  # orange
        "label": "BLOCKCHAIN",
        "icon": "BC",
        "icon_color": "#f97316",
    },
}


def _escape_svg_text(text: str) -> str:
    """SVG í…ìŠ¤íŠ¸ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬"""
    return (
        text.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&#39;")
    )


def _to_english_svg_text(text: str) -> str:
    """SVG í…ìŠ¤íŠ¸ì—ì„œ ë¹„ì˜ë¬¸ ë¬¸ì ì œê±° (SVGëŠ” ì˜ë¬¸ë§Œ í—ˆìš©)"""
    result = []
    for char in text:
        if ord(char) < 128:  # ASCII
            result.append(char)
        elif unicodedata.category(char).startswith("L"):
            # Non-ASCII letter - skip (Korean, etc.)
            continue
        else:
            result.append(" ")
    # Clean up multiple spaces
    cleaned = " ".join("".join(result).split())
    if not cleaned.strip():
        return "Security News Update"
    return cleaned.strip()


def _truncate_text(text: str, max_len: int) -> str:
    """í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ì˜ë¬¸ ê¸°ì¤€)"""
    if len(text) <= max_len:
        return text
    return text[: max_len - 3] + "..."


def _extract_key_topics(news_items: List[Dict]) -> List[str]:
    """ë‰´ìŠ¤ì—ì„œ í•µì‹¬ í† í”½ ì¶”ì¶œ"""
    topics = []
    keywords = [
        "Zero-Day",
        "CVE",
        "Vulnerability",
        "Patch",
        "Update",
        "AI",
        "ML",
        "Cloud",
        "Kubernetes",
        "Docker",
        "AWS",
        "Azure",
        "GCP",
        "Security",
        "Threat",
        "Malware",
        "Ransomware",
        "Botnet",
        "Bitcoin",
        "Ethereum",
        "DeFi",
        "Web3",
        "Blockchain",
        "LLM",
        "GPT",
        "Agent",
        "Data",
        "Palantir",
        "Tesla",
        "Apple",
        "Rust",
        "Go",
        "Open-Source",
        "API",
    ]

    for item in news_items[:6]:
        title = item.get("title", "")
        for kw in keywords:
            if kw.lower() in title.lower() and kw not in topics:
                topics.append(kw)
                if len(topics) >= 4:
                    return topics
    return topics[:4] if topics else ["Security", "Cloud", "DevOps", "AI"]


def generate_svg_image(
    date: datetime, categorized: Dict[str, List[Dict]], news_items: List[Dict]
) -> str:
    """ê³ í’ˆì§ˆ SVG ì´ë¯¸ì§€ ìƒì„± - ì¹´ë“œ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ"""

    date_display = date.strftime("%B %d, %Y")
    date_short = date.strftime("%Y.%m.%d")

    # í†µê³„ ê³„ì‚°
    total = sum(len(items) for items in categorized.values())
    stats = {cat: len(items) for cat, items in categorized.items()}

    # í•µì‹¬ í† í”½ ì¶”ì¶œ
    topics = _extract_key_topics(news_items)
    subtitle_topics = " | ".join(_to_english_svg_text(t) for t in topics)

    # ìƒìœ„ ë‰´ìŠ¤ 6ê°œ ì„ íƒ (ì¹´ë“œìš©)
    top_items = news_items[:6]

    # SVG í—¤ë” ë° ì •ì˜
    svg = f"""<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1200 630">
  <defs>
    <!-- Background Gradient -->
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#0f0f23"/>
      <stop offset="50%" style="stop-color:#1a1a3e"/>
      <stop offset="100%" style="stop-color:#0d1117"/>
    </linearGradient>

    <!-- Card Gradient -->
    <linearGradient id="cardGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#1e293b"/>
      <stop offset="100%" style="stop-color:#0f172a"/>
    </linearGradient>

    <!-- Category Gradients -->
    <linearGradient id="redGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#dc2626"/>
      <stop offset="100%" style="stop-color:#991b1b"/>
    </linearGradient>
    <linearGradient id="blueGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#3b82f6"/>
      <stop offset="100%" style="stop-color:#1d4ed8"/>
    </linearGradient>
    <linearGradient id="purpleGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#8b5cf6"/>
      <stop offset="100%" style="stop-color:#6d28d9"/>
    </linearGradient>
    <linearGradient id="greenGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#10b981"/>
      <stop offset="100%" style="stop-color:#059669"/>
    </linearGradient>
    <linearGradient id="orangeGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f59e0b"/>
      <stop offset="100%" style="stop-color:#d97706"/>
    </linearGradient>
    <linearGradient id="indigoGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#6366f1"/>
      <stop offset="100%" style="stop-color:#4f46e5"/>
    </linearGradient>

    <!-- Glow Filter -->
    <filter id="glow" x="-50%" y="-50%" width="200%" height="200%">
      <feGaussianBlur stdDeviation="3" result="blur"/>
      <feMerge>
        <feMergeNode in="blur"/>
        <feMergeNode in="SourceGraphic"/>
      </feMerge>
    </filter>

    <!-- Shadow Filter -->
    <filter id="shadow" x="-20%" y="-20%" width="140%" height="140%">
      <feDropShadow dx="0" dy="4" stdDeviation="8" flood-color="#000" flood-opacity="0.3"/>
    </filter>
    <pattern id="grid" width="30" height="30" patternUnits="userSpaceOnUse">
      <path d="M 30 0 L 0 0 0 30" fill="none" stroke="#334155" stroke-width="0.3" opacity="0.4"/>
    </pattern>
    <pattern id="dots" width="20" height="20" patternUnits="userSpaceOnUse">
      <circle cx="2" cy="2" r="0.8" fill="#475569" opacity="0.3"/>
    </pattern>
  </defs>

  <!-- Background -->
  <rect width="1200" height="630" fill="url(#bgGradient)"/>

  <!-- Grid Pattern -->
  <pattern id="grid" width="40" height="40" patternUnits="userSpaceOnUse">
    <path d="M 40 0 L 0 0 0 40" fill="none" stroke="#ffffff" stroke-opacity="0.03" stroke-width="1"/>
  </pattern>
  <rect width="1200" height="630" fill="url(#grid)"/>

  <!-- Decorative Circles -->
  <circle cx="100" cy="100" r="200" fill="#3b82f6" fill-opacity="0.05"/>
  <circle cx="1100" cy="530" r="250" fill="#8b5cf6" fill-opacity="0.05"/>
  <circle cx="600" cy="315" r="300" fill="#dc2626" fill-opacity="0.03"/>

  <!-- Header Section -->
  <rect x="40" y="30" width="200" height="36" rx="18" fill="url(#redGradient)" filter="url(#shadow)"/>
  <text x="140" y="54" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">WEEKLY DIGEST</text>

  <!-- Date Badge -->
  <rect x="960" y="30" width="200" height="36" rx="18" fill="url(#blueGradient)" filter="url(#shadow)"/>
  <text x="1060" y="54" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">{date_display}</text>

  <!-- Main Title -->
  <text x="600" y="110" font-family="Arial, sans-serif" font-size="42" font-weight="bold" fill="white" text-anchor="middle" filter="url(#glow)">Tech &amp; Security Weekly Digest</text>
  <text x="600" y="155" font-family="Arial, sans-serif" font-size="20" fill="#94a3b8" text-anchor="middle">{_escape_svg_text(subtitle_topics)}</text>
"""

    # ì¹´ë“œ ë ˆì´ì•„ì›ƒ ìƒì„± (ìµœëŒ€ 6ê°œ ì¹´ë“œ, 3x2 ê·¸ë¦¬ë“œ)
    card_positions = [
        (50, 190, 340, 180),  # Row 1, Card 1
        (430, 190, 340, 180),  # Row 1, Card 2
        (810, 190, 340, 180),  # Row 1, Card 3
        (50, 400, 340, 160),  # Row 2, Card 1
        (430, 400, 340, 160),  # Row 2, Card 2
        (810, 400, 340, 160),  # Row 2, Card 3
    ]

    gradient_map = {
        "security": "redGradient",
        "devsecops": "purpleGradient",
        "ai": "indigoGradient",
        "cloud": "greenGradient",
        "devops": "orangeGradient",
        "blockchain": "orangeGradient",
        "tech": "blueGradient",
    }

    for idx, item in enumerate(top_items):
        if idx >= len(card_positions):
            break

        x, y, width, height = card_positions[idx]
        category = item.get("category", "tech")
        if category in ("security", "devsecops"):
            category_display = "security"
        elif category in ("devops", "kubernetes"):
            category_display = "devops"
        elif category == "ai":
            category_display = "ai"
        elif category == "blockchain":
            category_display = "blockchain"
        else:
            category_display = category

        config = CATEGORY_SVG_CONFIG.get(category_display, CATEGORY_SVG_CONFIG["tech"])
        gradient = gradient_map.get(category_display, "blueGradient")

        title = _escape_svg_text(
            _truncate_text(_to_english_svg_text(item.get("title", "News Update")), 35)
        )
        source = _escape_svg_text(
            _truncate_text(
                _to_english_svg_text(
                    item.get("source_name", item.get("source", "Source"))
                ),
                15,
            )
        )

        # ìš”ì•½ ë˜ëŠ” ì»¨í…ì¸ ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
        summary = item.get("summary", item.get("content", ""))
        summary_lines = []
        if summary:
            words = summary.split()
            line = ""
            for word in words:
                if len(line + " " + word) > 40:
                    summary_lines.append(line.strip())
                    line = word
                    if len(summary_lines) >= 2:
                        break
                else:
                    line = line + " " + word if line else word
            if line and len(summary_lines) < 2:
                summary_lines.append(line.strip())

        svg += f'''
  <!-- Card {idx + 1}: {config["label"]} -->
  <g transform="translate({x}, {y})">
    <rect width="{width}" height="{height}" rx="16" fill="url(#cardGradient)" filter="url(#shadow)"/>
    <rect x="0" y="0" width="{width}" height="6" rx="3" fill="url(#{gradient})"/>

    <!-- Icon -->
    <circle cx="40" cy="50" r="24" fill="url(#{gradient})" fill-opacity="0.2"/>
    <text x="40" y="58" font-family="Arial, sans-serif" font-size="16" fill="{config["icon_color"]}" text-anchor="middle">{config["icon"]}</text>

    <text x="80" y="45" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="{config["icon_color"]}">{config["label"]}</text>
    <text x="80" y="65" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">{title}</text>
'''

        # ìš”ì•½ ë¼ì¸ ì¶”ê°€
        for line_idx, line in enumerate(summary_lines[:2]):
            y_offset = 95 + line_idx * 18
            svg += f'    <text x="20" y="{y_offset}" font-family="Arial, sans-serif" font-size="12" fill="#94a3b8">{_escape_svg_text(_to_english_svg_text(line))}</text>\n'

        # ì†ŒìŠ¤ ë°°ì§€
        badge_y = height - 25 if height > 160 else height - 20
        svg += f'''
    <rect x="20" y="{badge_y}" width="100" height="18" rx="9" fill="url(#{gradient})" fill-opacity="0.2"/>
    <text x="70" y="{badge_y + 13}" font-family="Arial, sans-serif" font-size="10" fill="{config["icon_color"]}" text-anchor="middle">{source}</text>
  </g>
'''

    # Footer ì„¹ì…˜
    svg += f"""
  <!-- Footer -->
  <line x1="50" y1="585" x2="1150" y2="585" stroke="#334155" stroke-width="1"/>

  <!-- Stats -->
  <g transform="translate(50, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{total} News Collected</text>
  </g>
  <g transform="translate(250, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("security", 0)} Security</text>
  </g>
  <g transform="translate(400, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("cloud", 0)} Cloud</text>
  </g>
  <g transform="translate(520, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("devops", 0)} DevOps</text>
  </g>
  <g transform="translate(650, 600)">
    <text font-family="Arial, sans-serif" font-size="13" fill="#64748b">{stats.get("ai", 0)} AI/ML</text>
  </g>

  <!-- Blog Info -->
  <text x="1150" y="612" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#94a3b8" text-anchor="end">tech.2twodragon.com</text>
</svg>"""

    return svg


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================


def main():
    parser = argparse.ArgumentParser(description="Auto publish news to _posts")
    parser.add_argument(
        "--dry-run", action="store_true", help="Preview without publishing"
    )
    parser.add_argument("--hours", type=int, default=24, help="Hours to look back")
    parser.add_argument("--max-news", type=int, default=15, help="Maximum news items")
    parser.add_argument(
        "--mode",
        choices=["security", "tech-blog"],
        default="security",
        help="Post mode: security (default) or tech-blog digest",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force publish even if same-day post exists",
    )
    parser.add_argument(
        "--date",
        type=str,
        default="",
        help="Target publish date in YYYY-MM-DD (default: today KST)",
    )
    parser.add_argument(
        "--post-filename",
        type=str,
        default="",
        help="Override output post filename (e.g., 2026-02-21-...md)",
    )
    parser.add_argument(
        "--image-filename",
        type=str,
        default="",
        help="Override output image filename (e.g., 2026-02-21-...svg)",
    )
    args = parser.parse_args()

    print(f"ğŸ“° Auto Publish News (mode: {args.mode})")
    print("=" * 50)

    # Load news
    news_data = load_collected_news()
    print(f"âœ… Loaded {news_data.get('total_items', 0)} news items")

    # Data freshness check
    collected_at_str = news_data.get("collected_at", "")
    if collected_at_str:
        try:
            collected_at = datetime.fromisoformat(
                collected_at_str.replace("Z", "+00:00")
            )
            data_age_hours = (
                datetime.now(timezone.utc) - collected_at
            ).total_seconds() / 3600
            if data_age_hours > 24:
                print(
                    f"âš ï¸ Data is {data_age_hours:.1f}h old. Time filter will be relaxed automatically."
                )
        except (ValueError, TypeError):
            pass

    # Filter and categorize
    filtered = filter_and_prioritize_news(news_data, hours=args.hours)
    if len(filtered) < MIN_NEWS_COUNT:
        print(f"âš ï¸ Not enough news ({len(filtered)} < {MIN_NEWS_COUNT}). Skipping.")
        return

    categorized = categorize_news(filtered)

    # Date setup
    now = datetime.now(timezone(timedelta(hours=9)))  # KST
    if args.date:
        try:
            forced_date = datetime.strptime(args.date, "%Y-%m-%d")
            now = now.replace(
                year=forced_date.year,
                month=forced_date.month,
                day=forced_date.day,
            )
        except ValueError:
            print(f"âŒ Invalid --date format: {args.date} (expected YYYY-MM-DD)")
            return
    date_str = now.strftime("%Y-%m-%d")

    # Duplicate check - only ONE post per day (any pattern)
    if not args.force:
        existing = list(POSTS_DIR.glob(f"{date_str}-*Digest*.md"))
        existing += list(POSTS_DIR.glob(f"{date_str}-*Weekly*.md"))
        # Deduplicate by filename
        existing = list({p.name: p for p in existing}.values())
        if existing:
            print(
                f"â­ï¸ Same-day post already exists ({len(existing)} found): {existing[0].name}"
            )
            print("   Only 1 post per day is allowed. Use --force to override.")
            return

    if args.mode == "tech-blog":
        # Filter for tech blog content only
        tech_categorized = {
            k: v
            for k, v in categorized.items()
            if k in ("tech", "devops", "ai", "cloud")
        }
        if not tech_categorized:
            print("âš ï¸ No tech blog content found. Skipping.")
            return
        selected = select_top_news(tech_categorized, args.max_news)
        topics = _extract_key_topics(selected)
        topics_slug = "_".join(topics[:3]) if topics else "Tech"

        post_content = generate_tech_blog_content(
            selected, tech_categorized, now, topics_slug
        )
        post_filename = f"{date_str}-Tech_Blog_Weekly_Digest_{topics_slug}.md"
        svg_filename = f"{date_str}-Tech_Blog_Weekly_Digest_{topics_slug}.svg"
    else:
        selected = select_top_news(categorized, args.max_news)
        topics = _extract_key_topics(selected)
        topics_slug = "_".join(topics[:4]) if topics else "News"

        post_content = generate_post_content(selected, categorized, now, topics_slug)
        post_filename = f"{date_str}-Tech_Security_Weekly_Digest_{topics_slug}.md"
        svg_filename = f"{date_str}-Tech_Security_Weekly_Digest_{topics_slug}.svg"

    if args.post_filename:
        post_filename = Path(args.post_filename).name
    if args.image_filename:
        svg_filename = Path(args.image_filename).name
        post_content = re.sub(
            r"^image:\s+.+$",
            f"image: /assets/images/{svg_filename}",
            post_content,
            flags=re.MULTILINE,
        )

    post_path = POSTS_DIR / post_filename
    svg_path = IMAGES_DIR / svg_filename

    print(f"âœ… Selected {len(selected)} top news items")
    for cat, items in categorized.items():
        print(f"   - {cat}: {len(items)} items")

    # Generate SVG
    svg_content = generate_svg_image(now, categorized, selected)

    # Existing post protection
    if post_path.exists():
        existing_size = post_path.stat().st_size
        new_size = len(post_content.encode("utf-8"))
        if existing_size > new_size and not args.force:
            print(
                f"â­ï¸ Existing post is larger ({existing_size}B > {new_size}B). Skipping to preserve manual post."
            )
            print(f"   File: {post_path}")
            return
        else:
            print(f"ğŸ“ Overwriting existing post ({existing_size}B â†’ {new_size}B)")

    if args.dry_run:
        print(f"\nğŸ“ [DRY RUN] Would create:")
        print(f"   - Post: {post_path}")
        print(f"   - Image: {svg_path}")
        print(f"\n--- Post Preview (first 500 chars) ---")
        print(post_content[:500])
        return

    # Save files
    POSTS_DIR.mkdir(parents=True, exist_ok=True)
    IMAGES_DIR.mkdir(parents=True, exist_ok=True)

    with open(post_path, "w", encoding="utf-8") as f:
        f.write(post_content)
    print(f"âœ… Created post: {post_path}")

    with open(svg_path, "w", encoding="utf-8") as f:
        f.write(svg_content)
    print(f"âœ… Created image: {svg_path}")

    print(f"\nğŸ‰ Auto publish completed! (mode: {args.mode})")


if __name__ == "__main__":
    main()
